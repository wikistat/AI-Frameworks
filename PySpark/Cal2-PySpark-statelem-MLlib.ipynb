{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>\n",
    "<a href=\"http://www.insa-toulouse.fr/\" ><img src=\"http://www.math.univ-toulouse.fr/~besse/Wikistat/Images/logo-insa.jpg\" style=\"float:left; max-width: 120px; display: inline\" alt=\"INSA\"/></a> \n",
    "<a href=\"http://wikistat.fr/\" ><img src=\"http://www.math.univ-toulouse.fr/~besse/Wikistat/Images/wikistat.jpg\" style=\"max-width: 250px; display: inline\"  alt=\"Wikistat\"/></a>\n",
    "<a href=\"http://www.math.univ-toulouse.fr/\" ><img src=\"http://www.math.univ-toulouse.fr/~besse/Wikistat/Images/logo_imt.jpg\" style=\"float:right; max-width: 200px; display: inline\" alt=\"IMT\"/> </a>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IA Framework.\n",
    "## Lab 1  - Introduction to Pyspark.\n",
    "#### Part 2 Basic Statistics and Logistic Regression with <a href=\"http://spark.apache.org/\"><img src=\"http://spark.apache.org/images/spark-logo-trademark.png\" style=\"max-width: 100px; display: inline\" alt=\"Spark\"/> </a> and  [MLlib](https://spark.apache.org/mllib/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Resume**: This notebook continues the introduction to [Spark](https://spark.apache.org/) trough  [`PySpark`](http://spark.apache.org/docs/latest/api/python/) API. We will see how to sample RDD, an introduction to the MlLib library, descriptive statistics and basic uni and multi dimensional(s) statistics."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Context and Dataset\n",
    "\n",
    "This notebook will continue to used  [KDD Cup 1999](http://kdd.ics.uci.edu/databases/kddcup99/kddcup99.html) dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH=\"\" \n",
    "data_file = DATA_PATH+\"kddcup.data_10_percent.gz\"\n",
    "raw_data = sc.textFile(data_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RDD's sampling\n",
    "They are two  `functions` available for sampling a RDD in spark.* `sample` and `takeSample`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data_sample = raw_data.takeSample(False, 4000, seed=1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data_sample = raw_data.sample(False, 0.1, seed=1234)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question** What is the difference between these two functions? Are the sample identical?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The use of the `sample` function allows to quickly estimate some values on a subsample of a huge dataset.\n",
    "\n",
    "In the cells below, we estimate the rate of normal interaction on the sample and on the all dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "raw_data_sample_items = raw_data_sample.map(lambda x: x.split(\",\"))\n",
    "sample_size = raw_data_sample.count()\n",
    "sample_normal_tags = raw_data_sample_items.filter(lambda x: \"normal.\" in x)\n",
    "t0 = time.time()\n",
    "sample_normal_tags_count = sample_normal_tags.count()\n",
    "tt = time.time() - t0\n",
    "sample_normal_ratio = sample_normal_tags_count / float(sample_size)\n",
    "print(\"Normal interaction rate is {}\".format(round(sample_normal_ratio,3)))\n",
    "print(\"Running time: {} secondes\".format(round(tt,3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data_items = raw_data.map(lambda x: x.split(\",\"))\n",
    "total_size = raw_data.count()\n",
    "normal_tags = raw_data_items.filter(lambda x: \"normal.\" in x)\n",
    "t0 = time.time()\n",
    "normal_tags_count = normal_tags.count()\n",
    "tt = time.time() - t0\n",
    "normal_ratio = normal_tags_count / float(total_size)\n",
    "print(\"Normal interaction rate is {}\".format(round(sample_normal_ratio,3)))\n",
    "print(\"Running time: {} secondes\".format(round(tt,3)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Data munging\n",
    "As described in the python [tutoriel](https://github.com/wikistat/Intro-Python) dedicated to data munging with `pandas`, data preprocessing is an essential part before analysis and modelling the data. Extraction, filtering, sampling, data completion, correction, anomaly detection, normalisation, features selection, matching, etc.\n",
    "\n",
    "Most of these steps are unidimensional and can easily be distributed.\n",
    "\n",
    "\n",
    "### [MLlib](http://spark.apache.org/docs/latest/ml-guide.html)\n",
    "\n",
    "\n",
    "*MLlib* is a RDD-based library.  \n",
    "Another library, *SparkML* is developed by Spark and is based on DataFrame (see part 3).\n",
    "\n",
    "*SparkML* will soon completely replace *MlLib* library, but so far, some functionalities (especially for basic statistics) are available only on MLlib.\n",
    "This two libraries will coexist until spark 3 is released.\n",
    "\n",
    "The only up-to-date documentation is the official online [documentation](https://spark.apache.org/docs/latest/mllib-guide.html).\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We first build a RDD that contains only numerical values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def parse_interaction(line):\n",
    "    line_split = line.split(\",\")\n",
    "    # keep just numeric and logical values\n",
    "    symbolic_indexes = [1,2,3,41]\n",
    "    clean_line_split = [item for i,item in enumerate(line_split) if i not in symbolic_indexes]\n",
    "    return np.array([float(x) for x in clean_line_split])\n",
    "\n",
    "vector_data = raw_data.map(parse_interaction)\n",
    "vector_data.take(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic Statistics\n",
    "### Summary statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[`colStats`](https://spark.apache.org/docs/latest/api/python/pyspark.mllib.html#pyspark.mllib.stat.Statistics.colStats)' MLlib function enable to compute unidimensionals statistics for each columns of the `RDD[Vector]`. It returns a[`MultivariateStatisticalSummary`](https://spark.apache.org/docs/latest/api/python/pyspark.mllib.html#pyspark.mllib.stat.MultivariateStatisticalSummary) object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.mllib.stat import Statistics\n",
    "from math import sqrt \n",
    "\n",
    "# Compute column summary statistics.\n",
    "summary = Statistics.colStats(vector_data)\n",
    "\n",
    "print(\"Statistique des durées\")\n",
    "print(\" Moyenne: {}\".format(round(summary.mean()[0],3)))\n",
    "print(\" Ecart type: {}\".format(round(sqrt(summary.variance()[0]),3)))\n",
    "print(\" Valeur max: {}\".format(round(summary.max()[0],3)))\n",
    "print(\" Valeur min: {}\".format(round(summary.min()[0],3)))\n",
    "print(\" Nombre de valeurs: {}\".format(summary.count()))\n",
    "print(\" Nombre de valeurs non nulles: {}\".format(summary.numNonzeros()[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### By label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_interaction_with_key(line):\n",
    "    line_split = line.split(\",\")\n",
    "    # keep just numeric and logical values\n",
    "    symbolic_indexes = [1,2,3,41]\n",
    "    clean_line_split = [item for i,item in enumerate(line_split) if i not in symbolic_indexes]\n",
    "    return (line_split[41], np.array([float(x) for x in clean_line_split]))\n",
    "\n",
    "def summary_by_label(raw_data, label):\n",
    "    label_vector_data = raw_data.map(parse_interaction_with_key).filter(lambda x: x[0]==label)\n",
    "    return Statistics.colStats(label_vector_data.values())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normal_sum = summary_by_label(raw_data, \"normal.\")\n",
    "\n",
    "print(\"Duration Statistics for label: {}\".format(\"normal\"))\n",
    "print(\" Mean: {}\".format(normal_sum.mean()[0],3))\n",
    "print(\" St. deviation: {}\".format(round(sqrt(normal_sum.variance()[0]),3)))\n",
    "print(\" Max value: {}\".format(round(normal_sum.max()[0],3)))\n",
    "print(\" Min value: {}\".format(round(normal_sum.min()[0],3)))\n",
    "print(\" Total value count: {}\".format(normal_sum.count()))\n",
    "print(\" Number of non-zero values: {}\".format(normal_sum.numNonzeros()[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For all label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_list = [\"back.\",\"buffer_overflow.\",\"ftp_write.\",\"guess_passwd.\",\n",
    "              \"imap.\",\"ipsweep.\",\"land.\",\"loadmodule.\",\"multihop.\",\n",
    "              \"neptune.\",\"nmap.\",\"normal.\",\"perl.\",\"phf.\",\"pod.\",\"portsweep.\",\n",
    "              \"rootkit.\",\"satan.\",\"smurf.\",\"spy.\",\"teardrop.\",\"warezclient.\",\n",
    "              \"warezmaster.\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats_by_label =[(label, summary_by_label(raw_data, label)) for label in label_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "#Display results with `pandas`.\n",
    "def get_variable_stats_df(stats_by_label, column_i):\n",
    "    column_stats_by_label = [\n",
    "        (stat[0], np.array([float(stat[1].mean()[column_i]), float(sqrt(stat[1].variance()[column_i])), float(stat[1].min()[column_i]), float(stat[1].max()[column_i]), int(stat[1].count())])) \n",
    "        for stat in stats_by_label\n",
    "    ]\n",
    "    return pd.DataFrame.from_items(column_stats_by_label, columns=[\"Mean\", \"Std Dev\", \"Min\", \"Max\", \"Count\"], orient='index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Duration statistics, by label\")\n",
    "get_variable_stats_df(stats_by_label,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"src_bytes statistics, by label\")\n",
    "get_variable_stats_df(stats_by_label,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correlation\n",
    "`corr` applies Spearman (rangs) and Pearson correlation/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.mllib.stat import Statistics \n",
    "correlation_matrix = Statistics.corr(vector_data, method=\"pearson\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.set_option('display.max_columns', 50)\n",
    "col_names = [\"duration\",\"src_bytes\",\"dst_bytes\",\"land\",\"wrong_fragment\",\n",
    "             \"urgent\",\"hot\",\"num_failed_logins\",\"logged_in\",\"num_compromised\",\n",
    "             \"root_shell\",\"su_attempted\",\"num_root\",\"num_file_creations\",\n",
    "             \"num_shells\",\"num_access_files\",\"num_outbound_cmds\",\n",
    "             \"is_hot_login\",\"is_guest_login\",\"count\",\"srv_count\",\"serror_rate\",\n",
    "             \"srv_serror_rate\",\"rerror_rate\",\"srv_rerror_rate\",\"same_srv_rate\",\n",
    "             \"diff_srv_rate\",\"srv_diff_host_rate\",\"dst_host_count\",\"dst_host_srv_count\",\n",
    "             \"dst_host_same_srv_rate\",\"dst_host_diff_srv_rate\",\"dst_host_same_src_port_rate\",\n",
    "             \"dst_host_srv_diff_host_rate\",\"dst_host_serror_rate\",\"dst_host_srv_serror_rate\",\n",
    "             \"dst_host_rerror_rate\",\"dst_host_srv_rerror_rate\"]\n",
    "\n",
    "corr_df = pd.DataFrame(correlation_matrix, index=col_names, columns=col_names)\n",
    "corr_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most correlated features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Une variable bouléenne est True en cas de forte corrélation\n",
    "highly_correlated_df = (abs(corr_df) > .8) & (corr_df < 1.0)\n",
    "# Extraction des noms des variables\n",
    "correlated_vars_index = (highly_correlated_df==True).any()\n",
    "correlated_var_names = correlated_vars_index[correlated_vars_index==True].index\n",
    "highly_correlated_df.loc[correlated_var_names,correlated_var_names]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Warnings**: [J. A. Dianes](https://github.com/jadianes/spark-py-notebooks/blob/master/nb8-mllib-logit/nb8-mllib-logit.ipynb) uses the previous function to select the features according to their correlation before using them within logisticRegression.\n",
    "This procedure is not recommended in Machine learning. It's better to used step-by-step method (*forward, backward, both*) and select the variable according to AIC or BIC criteria or using Lasso penalisation. This is what is implemented in MLlib library."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read the data.\n",
    "\n",
    "We now use the complete [KDD cup 1999](http://kdd.ics.uci.edu/databases/kddcup99/kddcup99.html) dataset. If you have memory issue, restart the kernel and start from here. You can also sample the data to make it run on a smallest dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "train dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request\n",
    "ft = urllib.request.urlretrieve(\"http://kdd.ics.uci.edu/databases/kddcup99/kddcup.data.gz\", DATA_PATH+\"data.gz\")\n",
    "train_data_file = DATA_PATH+\"data.gz\"\n",
    "train_raw_data = sc.textFile(train_data_file)\n",
    "\n",
    "print(\"Train data size is {}\".format(train_raw_data.count()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ft = urllib.request.urlretrieve(\"http://kdd.ics.uci.edu/databases/kddcup99/corrected.gz\", DATA_PATH+\"corrected.gz\")\n",
    "test_data_file = DATA_PATH+\"corrected.gz\"\n",
    "test_raw_data = sc.textFile(test_data_file)\n",
    "\n",
    "print(\"Test data size is {}\".format(test_raw_data.count()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Labeled Point"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to perform learning, you have to convert the data in the **Labeled Points** format.\n",
    "This object takes the label and the features as inputs.\n",
    "We define a function to convert the raw line to a LabeledPoint object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.mllib.regression import LabeledPoint\n",
    "from numpy import array\n",
    "\n",
    "def parse_interaction(line):\n",
    "    line_split = line.split(\",\")\n",
    "    clean_line_split = line_split[0:1]+line_split[4:41]\n",
    "    attack = 1.0\n",
    "    if line_split[41]=='normal.':\n",
    "        attack = 0.0\n",
    "    return LabeledPoint(attack, array([float(x) for x in clean_line_split]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = test_data.map(parse_interaction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = test_raw_data.map(parse_interaction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Learning the model\n",
    "Training the model is basically the same than with scikit learn.\n",
    "Mllib proposes two optimisation [algorithms](https://spark.apache.org/docs/latest/mllib-linear-methods.html#logistic-regression):  *mini-batch gradient descent* and L-BFGS (L-BFGS which is supposed to run faster).\n",
    "\n",
    "As in  *Scikit-learn*, *l2* (ridge) and *l1* (lasso) are available.\n",
    "\n",
    "See full doc [here](https://spark.apache.org/docs/2.0.0/api/python/pyspark.mllib.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.mllib.classification import LogisticRegressionWithLBFGS\n",
    "t0 = time()\n",
    "logit_model = LogisticRegressionWithLBFGS.train(training_data)\n",
    "tt = time() - t0\n",
    "print(\"Apprentissage en {} seconds\".format(round(tt,3)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Error Estimation\n",
    "The `map` function enables to predict the attack for each entry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_and_preds = test_data.map(lambda p: (p.label, logit_model.predict(p.features)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can then compute the error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t0 = time()\n",
    "test_accuracy = labels_and_preds.filter(lambda x: x[0] == x[1]).count() / float(test_data.count())\n",
    "erreur=1-test_accuracy\n",
    "tt = time() - t0\n",
    "print(\"Calcul en {} secondes. Le taux d'erreur est {}\".format(round(tt,3), round(erreur,4)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercices**\n",
    "\n",
    "- Qualitative variable such as `protocol` or `service` has been removed for simplicity. Add them as indicatrices and re-train the model.(*dummy variables*)\n",
    "- Try to [optimize](https://spark.apache.org/docs/latest/ml-tuning.html) the model with cross validation by trying various parameters.\n",
    "- Use other algorithm such as  [RandomForest](https://spark.apache.org/docs/latest/mllib-ensembles.html#random-forests) on this problem."
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "nav_menu": {
    "height": "457px",
    "width": "252px"
   },
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
