{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/wikistat/AI-Frameworks/blob/master/Text/1_cleaning_vectorization.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [IA Frameworks](https://github.com/wikistat/AI-Frameworks) - Natural Language Processing (NLP)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>\n",
    "<a href=\"http://www.insa-toulouse.fr/\" ><img src=\"https://www.insa-toulouse.fr/skins/Insa-v2/resources/img/logo-insa.jpg\" style=\"float:left; max-width: 320px; display: inline\" alt=\"INSA\"/></a> \n",
    "<a href=\"https://github.com/wikistat\" ><img src=\"https://avatars0.githubusercontent.com/u/20927455?s=200&v=4\" width=400, style=\"max-width: 100px; display: inline\"  alt=\"Wikistat\"/></a>\n",
    "<a href=\"http://www.math.univ-toulouse.fr/\" ><img src=\"https://perso.math.univ-toulouse.fr/riscope/files/2017/06/IMT.jpg\" width=300,  style=\"float:right;  display: inline\" alt=\"IMT\"/> </a>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data : Cdiscount's product description.\n",
    "\n",
    "This dataset has been released from Cdiscount for a data competition (type kaggle) on the french website [datascience.net](https://www.datascience.net/fr/challenge). <br>\n",
    "The test dataset of this competition has not been released, so we used a subset of 1M producted of the original train dataset(+15M rows) all along with the **Text Processing** lab.<br>\n",
    "The objective of this competition was to classify the text description of various product into various categories that compose the navigation tree of Cdiscount website. It is composed of 4,733 categories organized within 44 meta categories. <br>\n",
    "\n",
    "The objective of this lab is not wining the competition so we will only used the meta-categories.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1 : Cleaning Text data and Vectorization for text classification.\n",
    "\n",
    "In this first notebook, we study different methods to perform classification of text data.\n",
    "\n",
    "* **Cleaning** : It consists on removing characters that may not be relevant to solve your problem (punctuation symbol, number, etc.) or replace it (uppercase to lowercase, characters with accent, etc.). It is also possible to remove entire words (**stopwords**) or to replace them with their stem (**stemming**) .\n",
    "* **Vectorization** : Vectorization is the step that consists of converting the text data (raw or cleaned) to numerical data. This methods can be based on statistics (**One Hot Encoding**, **TF-IDF**) or based on learning algorithms (**Word2Vec, Glove, Gensim**) that we will see on the next part).\n",
    "* **Classification**: Once converted into numerical data, any classical machine or deep learning algorithms can be used to solved your problem.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Files & Data (Google Colab)\n",
    "\n",
    "If you're running this notebook on Google colab, you do not have access to the `data` or `solutions` folder you get by cloning the repository locally. \n",
    "\n",
    "The following lines will allow you to build the folders and the files you need for this TP.\n",
    "\n",
    "**WARNING 1** Do not run this line localy.\n",
    "**WARNING 2** The magic command `%load` does not work work on google colab, you will have to copy-paste the solution on the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! mkdir data\n",
    "! wget -P data https://github.com/wikistat/AI-Frameworks/raw/master/Text/data/cdiscount_test.csv.zip\n",
    "! wget -P data https://github.com/wikistat/AI-Frameworks/raw/master/Text/data/cdiscount_train.csv.zip\n",
    "! mkdir data/metadata\n",
    "! wget -P data/metadata https://github.com/wikistat/AI-Frameworks/raw/master/Text/data/metadata/metadata_1.pkl\n",
    "! mkdir solution\n",
    "! wget -P solution https://github.com/wikistat/AI-Frameworks/raw/master/Text/solution/clean_dataframe_1.py\n",
    "! wget -P solution https://github.com/wikistat/AI-Frameworks/raw/master/Text/solution/clean_dataframe_2.py\n",
    "! wget -P solution https://github.com/wikistat/AI-Frameworks/raw/master/Text/solution/get_vocabulary_size.py\n",
    "! wget -P solution https://github.com/wikistat/AI-Frameworks/raw/master/Text/solution/wordcloud_categorie.py\n",
    "! wget -P solution https://github.com/wikistat/AI-Frameworks/raw/master/Text/solution/get_example_OHE_description.py\n",
    "! wget -P solution https://github.com/wikistat/AI-Frameworks/raw/master/Text/solution/get_example_TFIDF_description.py\n",
    "! wget -P solution https://github.com/wikistat/AI-Frameworks/raw/master/Text/solution/get_example_TFIDF_description_valid.py\n",
    "! wget -P solution https://github.com/wikistat/AI-Frameworks/raw/master/Text/solution/clean.py\n",
    "\n",
    "! wget -P . https://github.com/wikistat/AI-Frameworks/raw/master/Text/clean.py\n",
    "! wget -P . https://github.com/wikistat/AI-Frameworks/raw/master/Text/vectorizer.py\n",
    "! wget -P . https://github.com/wikistat/AI-Frameworks/raw/master/Text/ml_model.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "import unicodedata \n",
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import nltk\n",
    "import re \n",
    "import collections\n",
    "import itertools\n",
    "import pickle\n",
    "import warnings\n",
    "from tqdm import tqdm\n",
    "import plotly.offline as pof\n",
    "import plotly.graph_objects as go\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import sklearn.metrics as smet\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sb\n",
    "from scipy import sparse\n",
    "sb.set_style(\"whitegrid\")\n",
    "\n",
    "import sklearn.model_selection as sms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**nltk**\n",
    "\n",
    "If you're using the `nltk` library for the first time, you have to first download the data you may need. For our problem, we need to download the nltk dataset of common stopwords."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "nltk.download(\"stopwords\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Exploration\n",
    "\n",
    "in the *NatualLangageProcessing/data* folder you'll find these two files :\n",
    "\n",
    "* `cdiscount_test.csv.zip`: training dataset composed of 1,000,000 lines\n",
    "* `cdisount_test`: test dataset composed of 50,000 lines\n",
    "\n",
    "We first read the train dataset.  To facilitate the exploration we first load only 100.000 rows. You can later go back and switch to do the study on the complete dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"data/cdiscount_train.csv.zip\",sep=\",\", nrows=100000)\n",
    "print(\"The train dataset is composed of %d lines\" %data.shape[0])\n",
    "data.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and the test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_test = pd.read_csv(\"data/cdiscount_test.csv.zip\",sep=\",\")\n",
    "print(\"The train dataset is composed of %d lines\" %data_test.shape[0])\n",
    "data_test.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "code_folding": []
   },
   "source": [
    "The dataset is composed of 6 columns:\n",
    "\n",
    "* Categorie1: Level 1 Category \n",
    "* Categorie2: Level 2 Category \n",
    "* Categorie3: Level 2 Category \n",
    "* Description: The complete description of the product\n",
    "* Libelle: A shorter description of the product.\n",
    "* Marque: The mark of the product. \n",
    "\n",
    "As described in the introduction, our objective will be to classify the products within one of the the 44 categories of level 1 using the text. \n",
    "\n",
    "The following command enables to display a description example for each of the 44 categories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(data.groupby(\"Categorie1\").first()[\"Description\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Class distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_count = data[\"Categorie1\"].value_counts()\n",
    "\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Bar(x=data_count.index,\n",
    "                y=data_count.values,\n",
    "                marker_color='rgb(55, 83, 109)'\n",
    "                ))\n",
    "\n",
    "fig.update_layout(\n",
    "    title='Distribution of products within categories',\n",
    "    xaxis_tickfont_size=12,\n",
    "    xaxis_tickangle=70,\n",
    "    yaxis=dict(\n",
    "        title='Number of products',\n",
    "        titlefont_size=16,\n",
    "        tickfont_size=14,\n",
    "    ),\n",
    "    paper_bgcolor='rgba(0,0,0,0)',\n",
    "    barmode='group',\n",
    "    bargap=0.15, # gap between bars of adjacent location coordinates.\n",
    "    bargroupgap=0.1 # gap between bars of the same location coordinate.\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q** What can you say about the distribution of the products within categories?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vocabulary size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocabulary_size = {categorie : len(set(\" \".join(data[data[\"Categorie1\"]==categorie][\"Description\"].values).split(\" \"))) for categorie in set(data[\"Categorie1\"].values)}\n",
    "\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Bar(x=data_count.index,\n",
    "                y=[vocabulary_size[c] for c in data_count.index],\n",
    "                marker_color='rgb(55, 83, 109)'\n",
    "                ))\n",
    "\n",
    "fig.update_layout(\n",
    "    title='Size of vocabulary per categories',\n",
    "    xaxis_tickfont_size=12,\n",
    "    xaxis_tickangle=70,\n",
    "    yaxis=dict(\n",
    "        title='Size of vocabulary',\n",
    "        titlefont_size=16,\n",
    "        tickfont_size=14,\n",
    "    ),\n",
    "    paper_bgcolor='rgba(0,0,0,0)',\n",
    "    barmode='group',\n",
    "    bargap=0.15, # gap between bars of adjacent location coordinates.\n",
    "    bargroupgap=0.1 # gap between bars of the same location coordinate.\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Cleaning\n",
    "\n",
    "The main advantage of text cleaning is to reduce the features space without losing information.\n",
    "\n",
    "In the end, the features that resume a description will be the different string of characters separated by a blank space. Hence string like *hand*, *Hand*, *hand,* etc. will be considered as a different feature if the text is not cleaning. Cleaning text allows to re-group together similar words or part of words that are the same but would have been considered different without cleaning.\n",
    "\n",
    "Here are the different steps that will be applied to the product's descriptions.\n",
    "\n",
    "\n",
    "* Remove HTML code. \n",
    "* Convert text to lowercase.\n",
    "* Remove punctuation, number, and other non characters-symbols.\n",
    "* Remove **stopwords**\n",
    "* Apply **stemming** on each word.\n",
    "\n",
    "\n",
    "Let us see the effect of each of this transformation on a line example."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning Text Example \n",
    "\n",
    "**Original line**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 47\n",
    "description = data.Description.values[i]\n",
    "print(\"Original Description : \" + description)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Remove HTML code**\n",
    "\n",
    "Product description may come directly from the product's website. Hence some of these descriptions contain HTML code such as `<br>`, `<a>`, <h>`etc.\n",
    "The 'BeautifulSoup' library contains algorithm able to detect HTML code and remove it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup #Nettoyage d'HTML\n",
    "txt = BeautifulSoup(description,\"html.parser\",from_encoding='utf-8').get_text()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Conversion to lowercase**\n",
    "\n",
    "Some words are written with uppercase letters. In some cases, it can be useful for example in sentiment analysis. But here, the use of lowercase or uppercase does not provide additional information. Hence all words will be converted in lowercase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "txt = txt.lower()\n",
    "print(txt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Removing accent**\n",
    "\n",
    "Remove all accents by using ascii encoding. Not taking accents into account enables us to avoid some misspelling. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "txt = unicodedata.normalize('NFD', txt).encode('ascii', 'ignore').decode(\"utf-8\")\n",
    "print(txt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Removing characters that are not letters**\n",
    "\n",
    "This step consists on removing any non-letter information (i.e, punctuation, number, symbol, etc..).\n",
    "\n",
    "To accomplish this task we will use [Regular Expression](https://en.wikipedia.org/wiki/Regular_expression) through the [re python library](https://docs.python.org/2/library/re.html) <br>\n",
    "A regular expression is a sequence of character that enable to efficiently search for a sequence of character within a text. We won't have time to go more through it during this laboratory but keep in mind that it is an extremely usefull tool for information retrieval. \n",
    "\n",
    "The next code line enables us to detect all non-letter characters (with the syntax `[^a-z]`) and replace it with blank characters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "txt = re.sub('[^a-z_]', ' ', txt)\n",
    "print(txt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Removing Stopwords**\n",
    "\n",
    "One common step in text preprocessing is to remove stopwords. A stopword is a word that won't bring any information to solve our problem. <br>\n",
    "  It can be specific to the problem. For example, when classifying the type of clothes, the color of the t-shirt or the dress will often be in the description but won't help. It can also bring noise if most of the t-shirts are black in the training dataset for example.<br> \n",
    "  Also, some words can be unspecific to the problem and related to the language. For example words like le, la, lesetc... The nltk library contains a  list of stopwords for different languages. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "french_stopwords = nltk.corpus.stopwords.words('french') \n",
    "english_stopwords = nltk.corpus.stopwords.words('english') \n",
    "pd.DataFrame([french_stopwords[:30], english_stopwords[:30]], index=[\"French\", \"English\"]).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To remove these words from the description, we first  have to  clean it the same way the text has been cleaned so far (so that words like `même` will be removed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords = [unicodedata.normalize('NFD', sw).encode('ascii', 'ignore').decode(\"utf-8\") for sw in french_stopwords]\n",
    "tokens = [w for w in txt.split() if (w not in stopwords)]\n",
    "removed_words = [w for w in txt.split() if (len(w)<2) or (w in stopwords)]\n",
    "\n",
    "print(\"List of tokens: %s\" %str(tokens))\n",
    "print(\"List of removed words: %s\" %str(removed_words))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that we now deals with lists of string of characters that are called **tokens**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Stemming**\n",
    "\n",
    "Stemming a word consists of converting a word to it's **word stem** or their root. \n",
    "\n",
    "Hence words with the same root but that differ due to their agreement (gender, number, etc.) or their conjugation for example.\n",
    "This transformation is applied through a stemming algorithm that depends on the language.\n",
    "\n",
    "The **nltk** library uses the [Snowball stemming algorithm](https://snowballstem.org/algorithms/french/stemmer.html) to stem french word. It is based on several determinist rules.\n",
    "\n",
    "Play with the following line of code to see the effect of this algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmer=nltk.stem.SnowballStemmer('french')\n",
    "stemmer.stem(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now apply the stemming algorithm to the tokens of the descriptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens_stem = [stemmer.stem(token) for token in tokens]\n",
    "print(tokens_stem)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning The all DataFrame\n",
    "\n",
    "### Exercise\n",
    "\n",
    "On the `clean.py` file is defined a `CleanText`python class that contains all the functions defined above.\n",
    "Using this python class:\n",
    "\n",
    "1. Write a function called `apply_all_transformation`that apply all this transformation on a text description\n",
    "2. Write a function called `clean_df_column`that clean all the text lines of the columns of the dataframe and add a new columns on this dataframe that containing the cleaned line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load solution/clean_dataframe_1.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load solution/clean_dataframe_2.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_df_column(data, \"Description\", \"Description_cleaned\")\n",
    "data[[\"Description\", \"Description_cleaned\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's also clean the test dataset for later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_df_column(data_test, \"Description\", \"Description_cleaned\")\n",
    "data_test[[\"Description\", \"Description_cleaned\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Warning** For ease of practices and ease of iteration these functions are defined within the notebook. When the function is written, it is better to write it within the python class as it is written within the `solution/clean.py`file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vocabulary size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise**: compute the total size of the vocabulary (i.e.:Number of unique words in the dataset) before and after cleaning. What can you observe?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load solution/get_vocabulary_size.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wordcloud"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Wordcloud* representation allows displaying the main words within a corpus of documents. In this representation, the bigger the word is the most frequent it appears in the document.\n",
    "\n",
    "Below you can observe the Wordcloud of all the descriptions before cleaning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from wordcloud import WordCloud\n",
    "all_descr = \" \".join(data.Description.values)\n",
    "wordcloud_word = WordCloud(background_color=\"black\", collocations=False).generate_from_text(all_descr)\n",
    "\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.imshow(wordcloud_word,cmap=plt.cm.Paired)\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wordcloud after stemming and cleaning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_descr_clean_stem = \" \".join(data.Description_cleaned.values)\n",
    "wordcloud_word = WordCloud(background_color=\"black\", collocations=False).generate_from_text(all_descr_clean_stem)\n",
    "\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.imshow(wordcloud_word,cmap=plt.cm.Paired)\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q** What do you observe?\n",
    "\n",
    "Both words `voir` et `present` are the most seen words after cleaning. This due to the fact that most of the descriptions end with *voir la présentation*. It is a good example of **stopwords** that are specific to a given problem.\n",
    "\n",
    "**Exercise** Add the words`voir`e and `présentation` to the stopwords list and run the cleaning again.\n",
    "\n",
    "**Exercise** Generate the wordcloud for a category of your choice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load solution/wordcloud_categorie.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vectorization \n",
    "\n",
    "The vectorization step allows converting text data into numerical data. \n",
    "In this notebook we study vectorization algorithm based on statistic:\n",
    "\n",
    "* **One Hot Encoding**\n",
    "* **TF-IDF** \n",
    "\n",
    "One of the limitations of these methods is that they imply data with very high dimension since the number of features is the size of the vocabulary. To solved that issue, **hashing** method can be used"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train/Validation dataset.\n",
    "\n",
    "we now split the `data`dataframe into two dataframe to get a proper **train** and **validation** dataset with the `train_test_split` function from `scikit-learn` library. <br>\n",
    "The `random_state`argument, when it is set with an integer, allows retrieving the exact same split from one run to another. Otherwise the split is applied randomly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train, data_valid = sms.train_test_split(data, test_size=0.1, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## One-Hot-Encoding\n",
    "\n",
    "The **One-Hot-Encoding** is the simplest vectorization method. <br>\n",
    "It allows building a features matrix of size $N~X~~V$ where $N$ is the number of text descriptions and $V$ the size of the vocabulary. <br>\n",
    "For each description, the vector is equal to 1 if the word or token is within the description, and 0 otherwise. <br>\n",
    "\n",
    "They are various variations of this encoding. For example, if the vector is equal to the number of times the word or token appears within the description.\n",
    "\n",
    "\n",
    "This *One-Hot-Encoding* encoding and their variations. can be applied trough the `CountVectorizer` class of `scikit-learn` library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "extr_cv = CountVectorizer(binary=False, ngram_range=(1,1))\n",
    "data_train_OHE = extr_cv.fit_transform(data_train[\"Description_cleaned\"].values)\n",
    "data_train_OHE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q** What is the type of `data_train_OHE`? Why is it stored with this type?\n",
    "\n",
    "**Q** What is the effect of the `binary` argument? What if it is set to True?\n",
    "\n",
    "**Q** What is the effect of the `ngram_range`parameter? Play with it an see the effect on the umber of features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `get_feature_names` function allows to get the vocabulary list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocabulary = extr_cv.get_feature_names()\n",
    "N_vocabulary = len(vocabulary)\n",
    "print(\"Nombre de mots : %d\" %N_vocabulary )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise** Take a line of the training dataset. Retrieved all the words that constitute the line from the `data_train_OHE`object and the `vocabulary`object. Also, retrieve the number of occurrences of each word that composed this line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load solution/get_example_OHE_description.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply the same transformations on the validation dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_valid_OHE = extr_cv.transform(data_valid[\"Description_cleaned\"].values)\n",
    "data_valid_OHE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q** What happen to the words within the validation dataset that are not present in the training dataset ?\n",
    "\n",
    "**Q** Why don't we re-fit the `CountVectorizer`class on the validation dataset?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TF-IDF¶\n",
    "\n",
    "**TF-IDF** is a formula that represents how much a word $w$ is importance in a description $d$ regarding to a ensemble of document $D$. \n",
    "\n",
    "\n",
    "* The **TF(w,d)** function count how many time the word $w$ appear in the description $d$.\n",
    "\n",
    "* The **IDF(w,D)** evaluates the importance of the word in the corpus of document $D$. The most often the word $w$ appear in the document, the less important the IDF will be.  There are various formulas to compute the IDF, the simplest is: \n",
    "\n",
    "$$IDF(m,l)=\\log\\frac{|D|}{f(m)}$$\n",
    "\n",
    "where $|D|$ is the number of documents in the all corpus, and $f(w)$ the number of documents in which $w$ appears.\n",
    "\n",
    "** Finally **TF-IDF(w,d,D)** value of a word within a description will be computed as\n",
    "\n",
    "$$TF-IDF(w,d,D)=TF(w,d)\\times IDF(w,D)$$.\n",
    "\n",
    "\n",
    "This encoding can be applied through the `TfidfVectorizer` class of `scikit-learn` library. We first apply this function with the parameter `norm` set to True in order to make the result more easily interpretable. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "vec = TfidfVectorizer(ngram_range=(1,1), norm = False)\n",
    "data_train_TFIDF = vec.fit_transform(data_train[\"Description_cleaned\"].values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check that `data_train_TFIDF` has the same type that `data_train_OHE` and that the vocabulary size are the same"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocabulary = vec.get_feature_names()\n",
    "N_vocabulary = len(vocabulary)\n",
    "N_vocabulary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise** Take a line of the training dataset. Retrieved all the words that constitute the line from the `data_train_OHE`object and the `vocabulary`object. Also retrieve the value of the *idf*, the *tf* and the *tfidf* for each of the word of the line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load solution/get_example_TFIDF_description.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q** Comment the value of the idf parameter for each of the words.\n",
    "\n",
    "**Q** How does the value of the idf evolve when changing the parameters *smooth idf* and *sublinear_tf* of the`TfidfVectorizer` class?\n",
    "\n",
    "**Exercice** Change the value of the *ngram_range* parameter of the `TfidfVectorizer` class and display once again the result. What do you see?\n",
    "\n",
    "We now apply this `vectorizer` on the validation dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_valid_TFIDF = vec.transform(data_valid[\"Description_cleaned\"].values)\n",
    "data_valid_TFIDF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise** Take a line of the validation dataset. Retrieved all the words that constitute the line from the `data_train_OHE`object and the `vocabulary` object. Also retrieve the value of the *idf*, the *tf* and the *tfidf* for each of the word of the line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load solution/get_example_TFIDF_description_valid.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q** The tf is recomputed for each line of the validation TF. But the computation of the IDF does not change. It's the same value computed on the training dataset. Does it seem normal for you?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hashing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Hashing** is a method that enables to reduced features space (the dictionary) to a fixed and smaller size `n_hash` of features.\n",
    "\n",
    "It is based on the **hashing function**, $h$ that linked an index $j\\in \\mathbb{N}$  to another index $i \\in [1,...,N_{hash}]$ such that $i=h(j)$. For a description, the weight of the new feature at index $i$ is a combination of all the features $j$ of the original space such that $i=h(j)$. The weight are combined according to the method described by [Weinberger et al. (2009)](https://alex.smola.org/papers/2009/Weinbergeretal09.pdf).\n",
    "\n",
    "$h$ does not randomly generate links. So for a different dataset, train or validation, the result will be the same for a same *n_hash* parameter.\n",
    "\n",
    "\n",
    "The `FeatureHasher` takes the occurrence dictionary as an input (while `CountVectorizer` and `TfidfVectorizer` take the list of string on convert it to token. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dict_array  = list(map(lambda x : collections.Counter(x.split(\" \")), data_train[\"Description_cleaned\"].values))\n",
    "train_dict_array[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction import FeatureHasher\n",
    "nb_hash = 300\n",
    "feathash = FeatureHasher(nb_hash)\n",
    "data_train_hash = feathash.fit_transform(train_dict_array)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check that the type of  `data_train_hash`is the same that `data_train_OHE` or `data_train_TFIDF` and that its dimension has been reduced.\n",
    "\n",
    "The next cell enables to display the weight of all indexes in the new space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ir = 47\n",
    "rw = data_train_hash.getrow(ir)\n",
    "print(\"Liste des tokens racinisé de la première ligne : \" + data_train[\"Description_cleaned\"].values[47])\n",
    "pd.DataFrame([(v, k)  for k,v in zip(rw.data,rw.indices)], columns=[\"indices\",\"weight\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q** What can you say about the weights??\n",
    "\n",
    "The size of the matrix has been reduced compared to `TFIDF`or `OHE`vectorizer. However, there exists no inverse function of the hashing function  which can make the results hard to interpret.\n",
    "\n",
    "\n",
    "It is possible to combine the `FeatureHasher` with a vectorizer like the TFIDF through the `TFIDFTransformer` class. <br>\n",
    "The `TFIDFTransformer` does not take a string as an input but the `data_train_hash`dataframe. \n",
    "The words are the `nb_hash` indices selected and the tf, for each description, are the weight computed by the hash function. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "\n",
    "vec =  TfidfTransformer(norm = False)\n",
    "data_train_HTfidf = vec.fit_transform(data_train_hash)\n",
    "data_train_HTfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ir = 47\n",
    "rw = data_train_HTfidf.getrow(ir)\n",
    "print(data_train[\"Description_cleaned\"].values[47])\n",
    "pd.DataFrame([(ind, vec.idf_[ind], w/vec.idf_[ind], w)  for w,ind in zip(rw.data, rw.indices)], columns=[\"indices\",\"idf\",\"tf\",\"weight\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vectorize the dataframe\n",
    "\n",
    "\n",
    "in the `vectorizer.py`file, there is a Vectorizer class that allows to fit a Vectorizer on a column of a dataframe and apply it to other columns after that.\n",
    "\n",
    "The following code enables us to apply vectorizer on the `Description_cleaned`columns of the train and validation dataset for various vectorizer and with and without hashing. The Array of vectorized descriptions are saved in order to use it within the next step for classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from vectorizer import Vectorizer\n",
    "\n",
    "\n",
    "features_parameters = [[None, \"count\"],\n",
    "                      [1000, \"count\"],\n",
    "                      [None, \"tfidf\"],\n",
    "                      [1000, \"tfidf\"],]\n",
    "metadata = {}\n",
    "for nb_hash, vectorizer_type in features_parameters:\n",
    "    vect_method = Vectorizer(vectorizer_type = vectorizer_type, nb_hash = nb_hash )\n",
    "    ts = time.time()\n",
    "    vec, feathash, data_train_vec = vect_method.vectorizer_train(data_train, columns = \"Description_cleaned\")\n",
    "    data_valid_vec = vect_method.apply_vectorizer(data_valid, columns = \"Description_cleaned\", vec = vec, feathash = feathash)\n",
    "    data_test_vec = vect_method.apply_vectorizer(data_test, columns = \"Description_cleaned\", vec = vec, feathash = feathash)\n",
    "    te = time.time()\n",
    "    \n",
    "    metadata.update({(nb_hash, vectorizer_type):te-ts})\n",
    "    \n",
    "    print(\"nb_hash : \" + str(nb_hash) + \", vectorizer_type : \" + str(vectorizer_type))\n",
    "    print(\"Runing time for vectorization : %.1f seconds\" %( metadata[(nb_hash, vectorizer_type)]))\n",
    "    print(\"Train shape : \" + str(data_train_vec.shape))\n",
    "    print(\"Valid shape : \" + str(data_valid_vec.shape))\n",
    "\n",
    "    \n",
    "    vect_method.save_dataframe(data_train_vec, \"train\")\n",
    "    vect_method.save_dataframe(data_valid_vec, \"valid\")\n",
    "    vect_method.save_dataframe(data_test_vec, \"test\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Product Classification\n",
    "\n",
    "In this last part, we will try to classify the products' descriptions of the test dataset using different ML models.\n",
    "\n",
    "\n",
    "For each of the three models and for all of the vectorized array, let's follow this classical train-validation procedure.\n",
    "\n",
    "* Train the ML model on various the data and for different parameters. \n",
    "* Select the best configuration of parameters according to the results of the validation dataset. \n",
    "* For each best configuration, train the model on train + validation data and apply it to the test dataset. \n",
    "\n",
    "In this notebook we will only these three ML models:\n",
    "\n",
    "* Logistic Regression\n",
    "\n",
    "* Random Forest\n",
    "\n",
    "* Multi-Layer Perceptron\n",
    "\n",
    "**Exercise**: Using one of the [sklearn's classification's methods](https://scikit-learn.org/stable/supervised_learning.html), train one the model listed above on one of the vectorized data computes during this lab.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `MlModel`class is defined within the  `ml_model.py` files. \n",
    "It enables to fit a model for different parameters and returns the best one according to the accuracy of the validation dataset. \n",
    "\n",
    "The code below enables to run the training over various parameters of vectorizers and model. As it can take a lot of times and that the purpose of this course is not to find which is the best model, the learning has already been run, the next cells will display the results from the metadata list produced in this cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FORCE_TO_RUN = False\n",
    "\n",
    "from ml_model import MlModel\n",
    "\n",
    "features_parameters = [[None, \"count\"],\n",
    "                      [1000, \"count\"],\n",
    "                      [None, \"tfidf\"],\n",
    "                      [1000, \"tfidf\"],]\n",
    "\n",
    "model_parameters = [[\"lr\", {\"C\":[0.1, 1, 10]}],\n",
    "                     [\"rf\", {\"n_estimators\" : [100,500]}],\n",
    "                     [\"mlp\", {\"hidden_layer_sizes\" : [128, 256]}]\n",
    "                      ]\n",
    "\n",
    "if FORCE_TO_RUN:\n",
    "    metadata = {}\n",
    "    for nb_hash, vectorizer_type in features_parameters:\n",
    "        print(nb_hash, vectorizer_type)\n",
    "        vect_method = Vectorizer(vectorizer_type = vectorizer_type, nb_hash = nb_hash )\n",
    "        X_train = vect_method.load_dataframe(\"train\")\n",
    "        Y_train = data_train.Categorie1.values\n",
    "        X_valid = vect_method.load_dataframe(\"valid\")\n",
    "        Y_valid = data_valid.Categorie1.values\n",
    "        X_test = vect_method.load_dataframe(\"test\")\n",
    "        Y_test = data_test.Categorie1.values\n",
    "\n",
    "        for ml_model_name, param_grid in model_parameters:\n",
    "            ml_class = MlModel(ml_model_name=ml_model_name, param_grid=param_grid)\n",
    "            best_model, best_metadata = ml_class.train_all_parameters(X_train, Y_train, X_valid, Y_valid, save_metadata=True)\n",
    "            accuracy_test = best_model.score(X_test, Y_test)\n",
    "            f1_macro_score_test = smet.f1_score(best_model.predict(X_test),Y_test, average='macro')\n",
    "            balanced_accuracy_test = smet.balanced_accuracy_score(best_model.predict(X_test),Y_test)\n",
    "            best_metadata.update({\"balanced_accuracy_test\":balanced_accuracy_test,\"accuracy_test\": accuracy_test, \"f1_macro_score_test\":f1_macro_score_test})\n",
    "            metadata.update({(vectorizer_type, str(nb_hash), ml_model_name): best_metadata})\n",
    "    pickle.dump(metadata, open(\"data/metadata/metadata_1.pkl\",\"wb\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is an interactive plot where you can display various metric according to both vectorizer and the best model for each model type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata = pickle.load(open(\"data/metadata/metadata_1.pkl\",\"rb\"))\n",
    "\n",
    "# Create figure\n",
    "fig = go.Figure()\n",
    "\n",
    "# Add traces\n",
    "metrics = [\"accuracy_train\",'accuracy_valid', \"accuracy_test\", \"learning_time\", \"predict_time\",\"balanced_accuracy_test\",\"balanced_accuracy_valid\",\"balanced_accuracy_train\", \"f1_macro_score_test\", \"f1_macro_score_valid\", \"f1_macro_score_train\"]\n",
    "N_metrics = len(metrics)\n",
    "method_ml_names = ['lr','rf','mlp']\n",
    "N_method_ml_names = len(method_ml_names)\n",
    "\n",
    "buttons = []\n",
    "for i_metric, metric in enumerate(metrics):\n",
    "    for method_ml_name in method_ml_names:\n",
    "        fig.add_trace(\n",
    "            go.Scatter(\n",
    "                x=[k[0]+\"_\"+str(k[1]) for k,v in metadata.items() if v['name']==method_ml_name],\n",
    "                y=[v[metric] for v in metadata.values() if v['name']==method_ml_name],\n",
    "                mode=\"markers\",\n",
    "                marker=dict(size=10),\n",
    "                name = method_ml_name,\n",
    "            )\n",
    "        )\n",
    "    buttons.append(\n",
    "            dict(label=metric,\n",
    "                 method=\"update\",\n",
    "                 args=[{\"visible\": [True if i in [i_metric*N_method_ml_names + k for k in range(N_method_ml_names)] else False for i in range(N_method_ml_names * N_metrics)]},\n",
    "                       {\"title\": metric}]))\n",
    "    \n",
    "\n",
    "# Update remaining layout properties\n",
    "fig.update_layout(\n",
    "    title_text=metric,\n",
    "    updatemenus=[\n",
    "        dict(\n",
    "            active=1,\n",
    "            buttons=buttons\n",
    "        )]\n",
    ")\n",
    "\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q** What is the best model according to the different metrics (`accuracy`, `balanced_accuracy`, `f1_macro_score`)? \n",
    "      Why do you think the different models perform better without hashing?\n",
    "\n",
    "**Q** What can you say about the different learning computation time?\n",
    "\n",
    "**Q** which method would you select?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# To go further"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook we studied how to tackle text classification problems. \n",
    "\n",
    "In the previous plot, we made a comparison of various methods. But thousands of other combinations would have been possible playing with:\n",
    "* Cleaning parameters\n",
    "    * With or without stemming\n",
    "    * change stopword list\n",
    "    * With or without punctuation, number \n",
    "    * etc.\n",
    "* Vectorizer parameters:\n",
    "    * ngram\n",
    "    * binary count\n",
    "    * idf\n",
    "    * etc.\n",
    "* ML model and they parameters:\n",
    "    * Logistic regression (C,penalty etc..)\n",
    "    * Multi-layers perceptron (hidden layer size, activation layer, etc.)\n",
    "    * Random forest (More tree; criterion)\n",
    "    * SVM, DNN, Xgboost etc.\n",
    "We only played with the default argument of scikit learn method, there exists a lot more to play with.\n",
    "\n",
    "We have seen that the classes are highly unbalanced. There are various methods that you can apply to tackle this problem. \n",
    "* Augment or reduce the dataset(Oversample the smallest classes, Undersample the biggest classes). See the [Imbalanced learn python library](https://imbalanced-learn.readthedocs.io/en/stable/over_sampling.html)\n",
    "* according to the algorithm you're using you can add a weight to each class (see most of the sklearn algorithm)\n",
    "\n",
    "Cross Validation can also be used instead of a simple validation dataset for more robust data\n",
    "\n",
    "**Exercise**: Try any of the bits advices below to improve the results, either on cdiscount dataset or on the challenge dataset ;)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  },
  "toc": {
   "nav_menu": {
    "height": "279px",
    "width": "252px"
   },
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": true
  },
  "toc-autonumbering": false,
  "toc-showmarkdowntxt": true,
  "toc-showtags": true
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
