{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/wikistat/AI-Frameworks/blob/master/Text/3_recurrent_neural_network.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [IA Frameworks](https://github.com/wikistat/AI-Frameworks) - Natural Language Processing (NLP)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>\n",
    "<a href=\"http://www.insa-toulouse.fr/\" ><img src=\"http://www.math.univ-toulouse.fr/~besse/Wikistat/Images/logo-insa.jpg\" style=\"float:left; max-width: 120px; display: inline\" alt=\"INSA\"/></a> \n",
    "<a href=\"http://wikistat.fr/\" ><img src=\"http://www.math.univ-toulouse.fr/~besse/Wikistat/Images/wikistat.jpg\" width=400, style=\"max-width: 150px; display: inline\"  alt=\"Wikistat\"/></a>\n",
    "<a href=\"http://www.math.univ-toulouse.fr/\" ><img src=\"http://www.math.univ-toulouse.fr/~besse/Wikistat/Images/logo_imt.jpg\" width=400,  style=\"float:right;  display: inline\" alt=\"IMT\"/> </a>\n",
    "    \n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data : Cdiscount's product description.\n",
    "\n",
    "This dataset has been released from Cdiscount for a data competition (type kaggle) on the french website [datascience.net](https://www.datascience.net/fr/challenge). <br>\n",
    "The test dataset of this competition has not been released, so we used a subset of 1M of products of the original train dataset(+15M rows) all along the **Natural Language Processing** lab.<br>\n",
    "The objective of this competition was to classify the text description of various product into various categories that compose the navigation tree of Cdiscount website. It is composed of 4,733 categories organized within 44 meta categories. <br>\n",
    "\n",
    "The objective of this lab is not win the competition so we will only used the meta-categories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.5.1'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow\n",
    "tensorflow.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Files & Data (Google Colab)\n",
    "\n",
    "If you're running this notebook on Google colab, you do not have access to the `data` or `solutions` folder you get by cloning the repository locally. \n",
    "\n",
    "The following lines will allow you to build the folders and the files you need for this TP.\n",
    "\n",
    "**WARNING 1** Do not run this line localy.\n",
    "**WARNING 2** The magic command `%load` does not work work on google colab, you will have to copy-paste the solution on the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "! mkdir data\n",
    "! wget -P data https://github.com/wikistat/AI-Frameworks/raw/master/Text/data/cdiscount_test.csv.zip\n",
    "! wget -P data https://github.com/wikistat/AI-Frameworks/raw/master/Text/data/cdiscount_train.csv.zip\n",
    "! wget -P data https://github.com/wikistat/AI-Frameworks/raw/master/Text/data/description_coque.npy.zip\n",
    "! unzip data/description_coque.npy.zip -d data/\n",
    "! wget -P data https://github.com/wikistat/AI-Frameworks/raw/master/Text/data/char_to_int.pkl\n",
    "! wget -P data https://github.com/wikistat/AI-Frameworks/raw/master/Text/data/int_to_char.pkl\n",
    "! wget -P data https://github.com/wikistat/AI-Frameworks/raw/master/Text/data/generate_model.h5\n",
    "! mkdir solution\n",
    "! wget -P solution https://github.com/wikistat/AI-Frameworks/raw/master/Text/solution/many_to_one_toy_example.py\n",
    "! wget -P solution https://github.com/wikistat/AI-Frameworks/raw/master/Text/solution/simple_rnn_output.py\n",
    "! wget -P solution https://github.com/wikistat/AI-Frameworks/raw/master/Text/solution/many_to_many_toy_example.py\n",
    "! wget -P solution https://github.com/wikistat/AI-Frameworks/raw/master/Text/solution/simple_rnn_output_bis.py\n",
    "! wget -P solution https://github.com/wikistat/AI-Frameworks/raw/master/Text/solution/one_to_many_dataset.py\n",
    "! wget -P solution https://github.com/wikistat/AI-Frameworks/raw/master/Text/solution/one_to_many_model.py\n",
    "! wget -P solution https://github.com/wikistat/AI-Frameworks/raw/master/Text/solution/one_to_many_prediction.py\n",
    "! wget -P solution https://github.com/wikistat/AI-Frameworks/raw/master/Text/solution/encode_input_output_sequence.py\n",
    "! wget -P solution https://github.com/wikistat/AI-Frameworks/raw/master/Text/solution/train_model_text_generation.py\n",
    "! wget -P solution https://github.com/wikistat/AI-Frameworks/raw/master/Text/solution/text_generation_random_first_letter.py\n",
    "! wget -P solution https://github.com/wikistat/AI-Frameworks/raw/master/Text/solution/text_generation_multinomial.py\n",
    "! wget -P solution https://github.com/wikistat/AI-Frameworks/raw/master/Text/solution/token_to_embedding_sequence\n",
    "! wget -P solution https://github.com/wikistat/AI-Frameworks/raw/master/Text/solution/rnn_classifier_model.py\n",
    "! wget -P solution https://github.com/wikistat/AI-Frameworks/raw/master/Text/solution/clean.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 3 : Recurrent Neural Network.\n",
    "\n",
    "The objectives of these first notebook are the following:\n",
    "\n",
    "* Build various *RNN* architecture with `keras` on toy example. ( **Many to one**, **one to many**, **many to many**, **bidirectional layer**, **Deep NN**, etc.\n",
    "* Use *RNN* for **Text Generation**. Generate product description.\n",
    "* Use *RNN* for **Text classification**. As the two precedent notebook, we will use Recurrent Neural Network algorithm to predict product's category."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Librairies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import collections\n",
    "import numpy as np\n",
    "import pickle\n",
    "import functools\n",
    "from tqdm import tqdm\n",
    "\n",
    "import tensorflow.keras.models as km\n",
    "import tensorflow.keras.layers as kl\n",
    "\n",
    "import logging\n",
    "logging.getLogger('tensorflow').disabled = True\n",
    "\n",
    "from tqdm import tqdm\n",
    "import sklearn.model_selection as sms\n",
    "from solution.clean import CleanText\n",
    "import gensim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keras Tutorial\n",
    "\n",
    "This part aims to understand how to build the different types of RNN models (**one/many-to-one/many**) with `keras`.\n",
    "\n",
    "This part is strictly pedagogical and toy data will be used."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Many to one\n",
    "\n",
    "**Many-to-one** recurrent neural network takes a sequence as an input and return a scalar as an output :\n",
    "\n",
    "\n",
    "<img src=\"https://github.com/wikistat/AI-Frameworks/blob/master/Text/images/many_to_one.png?raw=true\" alt=\"drawing\" width=\"400\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Toy Example\n",
    "\n",
    "An **RNN**  model always take 3 dimensional tensors as  inputs AND outputs which are (in this order when using `Keras`):\n",
    "\n",
    "* The **Batch**. (Number of sequences in the dataset) \n",
    "* The **Timestep**. (The size of one sequence)\n",
    "* The **Features**. (How many features for each element of each sequence)\n",
    "\n",
    "Let's take an example where:\n",
    "\n",
    "* the *input* are sequences of 3 numbers \n",
    "* the *output* the sum of these 3 numbers.\n",
    "* The dataset contains 100 individuals.\n",
    "\n",
    "**Exercise**: What would be the dimension of the input `X` and output `Y` matrix ?\n",
    "Fill the cell below with correct dimensions. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-2-39405d1045e4>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-2-39405d1045e4>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    X = np.arange(??).reshape(?,?,?)\u001b[0m\n\u001b[0m                  ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "X = np.arange(??).reshape(?,?,?)\n",
    "print(\"Dimensions of input sequences: %d, Timestep: %d, Number of features: %d\" %X.shape)\n",
    "Y = X.sum(1).reshape(100,?,?)\n",
    "print(\"Dimensions of output sequences: %d, Timestep: %d, Number of features: %d\" %Y.shape)\n",
    "print(\"Input Example\")\n",
    "print(X[0])\n",
    "print(\"Output Example\")\n",
    "print(Y[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load solution/many_to_one_toy_example.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model\n",
    "\n",
    "The following lines enable to define a very simple model with one **many-to-one** *RNN* layer with:\n",
    "\n",
    "* 10 neurons (*units=10)\n",
    "* a *relu* activation layer\n",
    "\n",
    "This model take as an input sequences of size (3,1). Note that the *input_shape* argument does not take the batch size as an input. Only the *timestep* and the *feature sie*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "simple_rnn (SimpleRNN)       (None, 10)                120       \n",
      "=================================================================\n",
      "Total params: 120\n",
      "Trainable params: 120\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = km.Sequential()\n",
    "model.add(kl.SimpleRNN(units=10 ,activation=\"relu\", input_shape=(3, 1)))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q**: Do the shape of the output seems normal to you? What do the two dimensions represent? <br>\n",
    "**Exercise** : Send a sequence trough the model and check the output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 10)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# %load solution/simple_rnn_output.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now define the complete model. <br>\n",
    "The output of the RNN layer are vectors of size 10 for each individual. <br>.\n",
    "Let's add a Dense layer so that the final output is of size 1 for each individual, *i.e.* the dimension we want as an output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "simple_rnn_1 (SimpleRNN)     (None, 10)                120       \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 131\n",
      "Trainable params: 131\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = km.Sequential()\n",
    "model.add(kl.SimpleRNN(units=10 ,activation=\"relu\", input_shape=(3, 1)))\n",
    "model.add(kl.Dense(1))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now train the model with and *adam* optimizer and a *mse* as a loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f93a135a2e8>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epochs = 500\n",
    "batch_size=32\n",
    "model.compile(loss=\"mse\", optimizer=\"adam\")\n",
    "model.fit(X, Y, epochs=epochs, batch_size=batch_size, verbose=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check that the model can now correctly perform the sum:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[33.305088]]\n",
      "[[48.132835]]\n"
     ]
    }
   ],
   "source": [
    "x_test=np.array([10,11,12]).reshape(1,3,1)\n",
    "print(model.predict(x_test))\n",
    "x_test=np.array([10,25,12]).reshape(1,3,1)\n",
    "print(model.predict(x_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that if  input_shape = (1,1) we set a **one-to-one** recurrent neural network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### With no fix timestep\n",
    "\n",
    "Note that in the previous example, the timestep was fix to three. But it's possible to set the parameters to *None* so that the model can handle sequences of variable length."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "simple_rnn_2 (SimpleRNN)     (None, 10)                120       \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 131\n",
      "Trainable params: 131\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = km.Sequential()\n",
    "model.add(kl.SimpleRNN(units=10 ,activation=\"relu\", input_shape=(None, 1)))\n",
    "model.add(kl.Dense(1))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, if this model can handle sequence of variable **timestep** lengths, during training, all sequences should have the same **timestep** lengths.\n",
    "\n",
    "To handle this, we apply zero padding to the sequences of variables length so that it does not affect the results thanks to the `pad_sequences` function from `keras`.\n",
    "\n",
    "Let's first create a X list of sequences of different **timestep** size (3 or 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of sequences by timestep length\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Counter({3: 100, 2: 100})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = []\n",
    "for x in np.arange(0,300,3):\n",
    "    X.append([x,x+1,x+2])\n",
    "for x in np.arange(300,500,2):\n",
    "    X.append([x,x+1])\n",
    "print(\"Number of sequences by timestep length\")\n",
    "collections.Counter([len(x) for x in X])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now pad this sequence with zero values. <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape : (200,3)\n",
      "3 first sequences\n",
      "[[0 1 2]\n",
      " [3 4 5]]\n",
      "2 last sequences\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[  0, 494, 495],\n",
       "       [  0, 496, 497],\n",
       "       [  0, 498, 499]], dtype=int32)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "X = pad_sequences(X, value=0.0, padding = 'pre')\n",
    "print(\"X shape : (%d,%d)\" %X.shape)\n",
    "print(\"3 first sequences\")\n",
    "print(X[:2])\n",
    "print(\"2 last sequences\")\n",
    "X[-3:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some remarks about padding\n",
    "\n",
    "* Note that a good practices aims to pad value to the **left** of the sequences. \n",
    "* This can be not intuitive but the reason is that nothing is learn at the beginning of the sequence because all the values would be zeros, the real learning would start when first non zeros values appears. \n",
    "* If the sequences are padded to the right, the information learn on the beginning of the sequences could be lost passing through all zeros values at the end of the sequences.\n",
    "* Padding values depends of the objective. Here sequences are padded with zero value so that it doesn't change the values of the sum. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now train the model!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f93b0c246a0>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = X.reshape(200,3,1)\n",
    "Y = X.sum(1)\n",
    "\n",
    "epochs = 500\n",
    "batch_size=32\n",
    "model.compile(loss=\"mse\", optimizer=\"adam\")\n",
    "model.fit(X, Y, epochs=epochs, batch_size=batch_size, verbose=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now predict sum of sequences of different lenght (even bigger sequences, but results is not guaranted!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[7.5632176]]\n",
      "[[13.568249]]\n",
      "[[22.936216]]\n"
     ]
    }
   ],
   "source": [
    "x_test=np.array([3,4]).reshape(1,2,1)\n",
    "print(model.predict(x_test))\n",
    "x_test=np.array([3,4,5]).reshape(1,3,1)\n",
    "print(model.predict(x_test))\n",
    "x_test=np.array([3,4,5,6]).reshape(1,4,1)\n",
    "print(model.predict(x_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Many to Many\n",
    "\n",
    "**Many-to-many** recurrent neural network take a sequence as an input and return a sequence as an output :\n",
    "\n",
    "\n",
    "<img src=\"https://github.com/wikistat/AI-Frameworks/blob/master/Text/images/many_to_many.png?raw=true\" alt=\"drawing\" width=\"400\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Toy Example\n",
    "\n",
    "Let's take an example where the *input* are sequences of 3 number  and the output will be a sequences of cumulative sum, i.e.\n",
    "\n",
    "* input = [x1, x2, x3]\n",
    "* output = [x1, x1+x2, x1+x2+x3]\n",
    "\n",
    "**Exercise**: What would be the dimension of the input `X` and output `Y` matrix ?\n",
    "Fill the cell below with correct dimensions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-15-88b5f57c42a2>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-15-88b5f57c42a2>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    X = np.arange(??).reshape(100,??,??)\u001b[0m\n\u001b[0m                  ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "X = np.arange(??).reshape(100,??,??)\n",
    "print(\"Dimensions of input sequences: %d, Timestep: %d, Number of features: %d\" %X.shape)\n",
    "Y = X.cumsum(1).reshape(100,??,??)\n",
    "print(\"Dimensions of input sequences: %d, Timestep: %d, Number of features: %d\" %Y.shape)\n",
    "print(\"Input Example\")\n",
    "print(X[0])\n",
    "print(\"Output Example\")\n",
    "print(Y[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load solution/many_to_many_toy_example.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model\n",
    "\n",
    "The following lines enable to define a very simple model with one **many-tom-many** *RNN* layer with:\n",
    "\n",
    "* 10 neurons (*units=10)\n",
    "* a *relu* activation layer\n",
    "\n",
    "This model take as an input sequences of size (3,1) and return a sequence of the same size.<br>\n",
    "This is specified but the `return_sequences` argument which is set to True. (and set to False by default)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "simple_rnn_3 (SimpleRNN)     (None, 3, 10)             120       \n",
      "=================================================================\n",
      "Total params: 120\n",
      "Trainable params: 120\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = km.Sequential()\n",
    "model.add(kl.SimpleRNN(units=10 ,activation=\"relu\", input_shape=(3, 1), return_sequences=True))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q**: Do the shape of the output seems normal to you? What do the three dimensions represent? <br>\n",
    "**Exercise** : Send a sequence trough the model and check the output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load solution/simple_rnn_output_bis.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now define the complete model. <br>\n",
    "For each input sequences, the output of the RNN layer is a matrix of size 3 (number of **timestep**) per 10  (**features**). <br>\n",
    "The desired output would be a sequence of size 3  per 1.\n",
    "\n",
    "In order to obtain the correct dimension let's add a Dense layer at **each timestep** to get the desired output. <br>\n",
    "This can be done with the `TimeDistributed` layer of `keras`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "simple_rnn_4 (SimpleRNN)     (None, 3, 10)             120       \n",
      "_________________________________________________________________\n",
      "time_distributed (TimeDistri (None, 3, 1)              11        \n",
      "=================================================================\n",
      "Total params: 131\n",
      "Trainable params: 131\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = km.Sequential()\n",
    "model.add(kl.SimpleRNN(units=10 ,activation=\"relu\", input_shape=(3, 1), return_sequences=True))\n",
    "model.add(kl.TimeDistributed(kl.Dense(1)))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now train the model with and *adam* optimizer and a *mse* as a loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f93a13dc4e0>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epochs = 500\n",
    "batch_size=32\n",
    "model.compile(loss=\"mse\", optimizer=\"adam\")\n",
    "model.fit(X, Y, epochs=epochs, batch_size=batch_size, verbose=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check that the model can now correctly perform the cumulative sum:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[10.462094]\n",
      "  [21.83    ]\n",
      "  [34.010593]]]\n",
      "[[[10.462094]\n",
      "  [35.428288]\n",
      "  [47.843643]]]\n"
     ]
    }
   ],
   "source": [
    "x_test=np.array([10,11,12]).reshape(1,3,1)\n",
    "print(model.predict(x_test))\n",
    "x_test=np.array([10,25,12]).reshape(1,3,1)\n",
    "print(model.predict(x_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that as previously seen, it would have been possible to set the *timestep* parameters to *None* so that the model can compute cumulative sum of model whatever the size of their length (using padding).  \n",
    "This could be a good **exercise** if you want to practice."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## One to Many\n",
    "\n",
    "**One-to-many** recurrent neural network take a scalar as an input and return a sequence as an output. \n",
    "\n",
    "There are different ways to define **one-to-many**\n",
    "neural network. \n",
    "\n",
    "* In the example below, the **one-to-many** network can be seen as as a **many-to-many** neural network where the input sequence is build iteratively. (The input of the second timestep is the output of the first timestep).\n",
    "\n",
    "<img src=\"https://github.com/wikistat/AI-Frameworks/blob/master/Text/images/one_to_many.png?raw=true\" alt=\"drawing\" width=\"400\"/>\n",
    "\n",
    "* It would also be possible to only pass an input at the first timestep. Then **one-to-many** network can be seen as as a **many-to-many** neural network where the input sequence is composed of one scalar and `None` entry to fill the sequences. \n",
    "\n",
    "Hence, **one-to-many** networks, can be seen as particular case of **many-to-many** neural networks. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Toy Example\n",
    "\n",
    "Let's take an example where the *input* are scalar and the output is sequence of 3 number composed such that\n",
    "\n",
    "* input = x\n",
    "* output = [x+2, x+4, x+6]\n",
    "\n",
    "Hence the dimensions of the output matrix *Y* will be of size:\n",
    "\n",
    "* N: Number of sequences = 100 (arbitrary values), \n",
    "* Timestep: (Size of sequences) = 3, \n",
    "* Number of features (How many features for each element of the sequences) = 1 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model\n",
    "\n",
    "At **training**  the keras model will be built as a **many-to-many** models. <br>\n",
    "Indeed as you now the sequence output you're expect to get, you now the sequence that will be send as an input you want to learn. IN the example above:\n",
    "\n",
    "* input = [x,x+2,x+4].\n",
    "* output = [x+2,x+4,x+6]\n",
    "\n",
    "**Exercise**: Build the toy dataset and the models that will learn how to predict the output sequences from and input sequences.<br>\n",
    "**nb** Remember that at prediction, the model should be able to take a scalar as an input (i.e. a sequence of one timestep).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load solution/one_to_many_dataset.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load solution/one_to_many_model.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us now train this model!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f93a14ad8d0>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epochs = 1000\n",
    "batch_size=32\n",
    "model.compile(loss=\"mse\", optimizer=\"adam\")\n",
    "model.fit(X, Y, epochs=epochs, batch_size=batch_size, verbose=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise** Once your model is build, write a function that build a the 3 numbers sequences output from a scalar input using the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[506.19867]]], dtype=float32)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test=np.array(x).reshape(1,1,1)\n",
    "y1 = model.predict(x_test)\n",
    "y1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "y1 = model.predict(x_test)\n",
    "y2 = model.predict(np.hstack((x_test,y1)))\n",
    "y3 = model.predict(np.hstack((x_test,y2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input scalar : 10. Output sequences: [11.199, 13.055, 14.557]\n"
     ]
    }
   ],
   "source": [
    "# %load solution/one_to_many_prediction.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All the examples details so far have treated *one-size* features sequences in order to make this tutorial easier. \n",
    "\n",
    "All of these examples can be easily traduced to *several-size* features length. Let's check that with example on the **Cdisocunt** Dataset! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RNN layers\n",
    "\n",
    "Once you know how to manipulate the structure defined above, it is really easy to build more complex or deepest RNN model with keras.\n",
    "\n",
    "* `GRU` and `LSTM` can be used the exact same way than `SimpleRNN`in the example above.\n",
    "* Bi-directional layers can be build using the `Bidirectional` layer on `RNN`layer.\n",
    "* Deep RNN can be build adding `RNN` layer like any other sequential model.\n",
    "\n",
    "***Example***:\n",
    "Here is how to build a model with one *LSTM* layer follow by a bidirectional *GRU* layer. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm (LSTM)                  (None, 3, 10)             480       \n",
      "_________________________________________________________________\n",
      "bidirectional (Bidirectional (None, 3, 20)             1320      \n",
      "_________________________________________________________________\n",
      "time_distributed_2 (TimeDist (None, 3, 1)              21        \n",
      "=================================================================\n",
      "Total params: 1,821\n",
      "Trainable params: 1,821\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = km.Sequential()\n",
    "model.add(kl.LSTM(units=10 ,activation=\"relu\", input_shape=(3, 1), return_sequences=True))\n",
    "model.add(kl.Bidirectional(kl.GRU(units=10 ,activation=\"relu\", return_sequences=True)))\n",
    "model.add(kl.TimeDistributed(kl.Dense(1)))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recap\n",
    "\n",
    "Now, you know how to build all combination of **One/Many to One/many** RNN models using all `Keras` tools:\n",
    "* `return_sequences` RNN layer's parameter : return one output or a sequence output. \n",
    "*  `input_shape` parameter  : with None value has the timestep if we want the model to handle various length sequences.\n",
    "* `TimeDistributed` layer: in order to apply layer such as `Dense` on each entries of a sequence.\n",
    "* `Gru`and `LSTM` as alternative layer of `SimpleRNN`.\n",
    "* `Bidirectional layer`.\n",
    "\n",
    "Let us use this knowledge to handle real use case!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Generation \n",
    "\n",
    "In this part the objective is to generate product description of a product."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset\n",
    "\n",
    "The Level 3 category `COQUE - BUMPER - FACADE TELEPHONE` is the most represented category within the original **Cdiscount**'s dataset with 2.184.671 descriptions. Among them 1.761.637 are composed with 197 characters. \n",
    "\n",
    "We will now use these lines (or sub-samble of these lines according to the computation power of your machine) in order to learn a text generation model that will allow to automatically generate a new text description of this type of product.\n",
    "\n",
    "These lines are contains in the `data/description_coque.npy` file (you have to unzip it).\n",
    "\n",
    "The data used in this section are real data. However it turns out that a lot of these description are very similar. This help the network to build good description but which are not really different from the training set. <br>\n",
    "However, this is a good thing to obtains result in a reasonable amount of time. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of line :100000\n",
      "\n",
      "Three lines example:\n",
      "[\"Pour apple iphone 4 : coque bumper silicone blanc - Cet étui en silicone rigide protège et habille votre APPLE iPhone 4. Parfaitement adapté, il permet l'accès à toutes les fo… Voir la présentation\"\n",
      " \"Pour htc one x : coque noire rigide - Cette coque protège et habille avec sobriété votre HTC ONE X. Parfaitement adaptée, elle permet l'accès à toutes les fonctionnalités de v… Voir la présentation\"\n",
      " \"Pour htc one x : coque blanche rigide - Cette coque protège et habille avec sobriété votre HTC ONE X. Parfaitement adaptée, elle permet l'accès à toutes les fonctionnalités de… Voir la présentation\"]\n",
      "\n",
      "Size of all the sequences : {197}\n"
     ]
    }
   ],
   "source": [
    "N = 100000\n",
    "X = np.load(\"data/description_coque.npy\")[:N]\n",
    "print(\"Number of line :%d\" %X.shape[0])\n",
    "print(\"\\nThree lines example:\")\n",
    "print(X[:3])\n",
    "print(\"\\nSize of all the sequences : %s\" %(str(set([len(x) for x in X]))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Processing\n",
    "\n",
    "The text generation implies to build a **one-To_many** model:\n",
    "\n",
    "<img src=\"https://github.com/wikistat/AI-Frameworks/blob/master/Text/images/one_to_many.png?raw=true\" alt=\"drawing\" width=\"400\"/>\n",
    "\n",
    "Where the prediction $y_t$ will be used as an input at time $t+1$, i.e : $y_t=x_{t+1}$. \n",
    "\n",
    "This model with be trained as a **many-to-many**  model. \n",
    "\n",
    "<img src=\"https://github.com/wikistat/AI-Frameworks/blob/master/Text/images/many_to_many.png?raw=true\" alt=\"drawing\" width=\"400\"/>\n",
    "\n",
    "Where the output y will be the same sequence than input x with 1 offset.\n",
    "\n",
    "When using text, the input can be either a word or a characters. As sequences have fixed length, we will use the characters as inputs of the sequences. <br>\n",
    "These characters will be *one-hot encoded* <br>\n",
    "\n",
    "Hence each description $x$ will be represented as a Matrix of size $N_s \\times N_v$ where\n",
    "\n",
    "* $N_s=197$ is the length of the sequences (timestep)\n",
    "* $N_v$ is the size of the vocabulary (the list of caracters) .\n",
    "\n",
    "Let us fix $N_s$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ns=197"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Characters' list\n",
    "\n",
    "Let's first create a list of all unique characters present in the descriptions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Characters list of size 87 : ['i', 'M', 'à', 'S', 'F', 'B', 'T', 'N', 'p', ':', '5', 'f', 'Q', '&', 'C', 'è', '3', '?', 'l', 'G', \"'\", 'â', 'b', 'n', 'J', 'ê', '9', 'W', 'e', 'u', 'm', '7', '.', '+', '4', 'D', 'ô', ',', 'a', 'd', 'y', '1', 'I', '/', 't', 'K', 'E', 'v', 'O', 'r', 'c', '\\xa0', 'A', 'z', '*', 'U', '\"', 'k', 'X', ')', '-', 'é', 'x', '8', 'Z', 'o', 'h', ' ', 'Y', 'ç', '!', 'L', 'j', 'R', 'P', '%', 's', 'q', '6', '(', '…', 'H', '0', 'w', 'V', 'g', '2']\n"
     ]
    }
   ],
   "source": [
    "chars_set = list(functools.reduce(lambda x,y : x.union(y), [set(x) for x in X], set()))\n",
    "print(\"Characters list of size %d : %s\"  %(len(chars_set), str(chars_set)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will add two elements to these listes allowing to detect the *start* and the *end* of a sequences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total size of the vocabulary : 89\n"
     ]
    }
   ],
   "source": [
    "chars_set.extend([\"START\",\"END\"])\n",
    "Nv = len(chars_set)\n",
    "print(\"Total size of the vocabulary : %d\" %Nv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sequence encoding\n",
    "\n",
    "There are no library (or I do not find it), that enable to *one-hot encode* a string at a character level.\n",
    "\n",
    "The following lines enables to apply it.\n",
    "\n",
    "* First `char_to_int` and `int_to_char` dictionary are created, enabling to retrieve the position of a character in the vocabulary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "int_to_char = {i:c for i,c in enumerate(chars_set)}\n",
    "char_to_int = {c:i for i,c in int_to_char.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following function encode\n",
    "\n",
    "* a  $X\\in \\mathbb{R}^{N \\times N_s}$ matrix composed of *N* text description of size *N_s*   size\n",
    "\n",
    "into\n",
    "\n",
    "* a $X_{vec} \\in \\mathbb{R}^{N \\times N_s +1 \\times N_v}$ matrix composed of *N* sequences of size $N_s+1\\times N_v$ (the encoded text description)\n",
    "and \n",
    "* a $Y_{vec} \\in \\mathbb{R}^{N \\times N_s +1 \\times N_v}$ matrix composed of *N* sequences of size $N_s+1\\times N_v$ (the encoded text description with an offset of one).\n",
    "\n",
    "Note that the length of the sequences in $X_{vec}$ and $Y_{vec}$ are of size $N_s+1$  because we will add an element to each of these sequences\n",
    "\n",
    "* Input sequences will have a *START* element at their beginning.\n",
    "* Output sequences will have a *END* element at their end.\n",
    "\n",
    "\n",
    "**exercise** Let us try to encoded the function that apply these transformation. -> Read the test cell below before to start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_input_output_sequence(x_descriptions, length_sequence, size_vocab, char_to_int_dic):\n",
    "    return x_vec, y_vec\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**test cell**\n",
    "\n",
    "To help you coding this function, here is some test to ensure that you function has the expected behavior:\n",
    "\n",
    "If the function take a single sentence of length 7 (*bonjour*) as en input:\n",
    "\n",
    "* Both X (input of the rnn) and Y (output of the rnn) outputs should be tensor of shape (1 X 8 X 91).\n",
    "* For X, by taking the argmax of each element of the sequence, we should be able to retrieve the original sentence (with START element at the beginning)\n",
    "* For Y, by taking the argmax of each element of the sequence, we should be able to retrieve the original sentence (with END element at the END)\n",
    "\n",
    "**Warning** you do not have to modify this cell! All test have to work if you function is correctly implemented. <br>\n",
    "If a test fail it will throw a `Assertion Error`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:00, 11650.84it/s]\n"
     ]
    }
   ],
   "source": [
    "X_test,Y_test = encode_input_output_sequence(np.array([\"bonjour\"]), 7, Nv, char_to_int)\n",
    "assert X_test.shape == (1, 8, Nv)\n",
    "assert Y_test.shape == (1, 8, Nv)\n",
    "\n",
    "assert [int_to_char[x] for x in np.argmax(X_test[0],axis=1)] == ['START', 'b', 'o', 'n', 'j', 'o', 'u', 'r']\n",
    "assert [int_to_char[x] for x in np.argmax(Y_test[0],axis=1)] == ['b', 'o', 'n', 'j', 'o', 'u', 'r', 'END']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load solution/encode_input_output_sequence.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's apply it on the first N lines of the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100000it [00:16, 6235.82it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(100000, 198, 89)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_vec, Y_vec = encode_input_output_sequence(X[:N], Ns, Nv, char_to_int)\n",
    "X_vec.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training\n",
    "\n",
    "\n",
    "**Exercise**: Define a simple model (only one LSTM layer with 32 hidden units) that will allow to train the text generation model.\n",
    "*Tips*:\n",
    "* Remember that this model will be used for generation.\n",
    "* What are the dimension of the output? What will be the activation layer? The loss function?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load solution/train_model_text_generation.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you have correctly write the model you can observe that it can take a while to obtain convergence when training these kind of model. <br>\n",
    "If you do not have GPU while executing this TP, you do not have to wait for the end of the training. -> Let's download this model, generated with the solution above! <br>\n",
    "Note that you also have to download the corresponding `int_to_char`and `char_to_int` dictionary.\n",
    "And re build the dataset according to these dictionaries;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100000it [00:15, 6613.15it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(100000, 198, 89)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "model = load_model(\"data/generate_model.h5\")\n",
    "int_to_char = pickle.load(open(\"data/int_to_char.pkl\",\"rb\"))\n",
    "char_to_int = pickle.load(open(\"data/char_to_int.pkl\",\"rb\"))\n",
    "X_vec, Y_vec = encode_input_output_sequence(X[:N], Ns, Nv, char_to_int)\n",
    "X_vec.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text Generation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function below, enable to decode en encoded sentence "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Original Sentences:\n",
      "Pour htc one mini : coque sur mesure decor pluie d'etoiles - Cette coque fantaisie protège et habille votre HTC ONE Mini. Parfaitement adaptée, elle permet l'accès à toutes le… Voir la présentation\n",
      "\n",
      "Decoded input vector::\n",
      "STARTPour htc one mini : coque sur mesure decor pluie d'etoiles - Cette coque fantaisie protège et habille votre HTC ONE Mini. Parfaitement adaptée, elle permet l'accès à toutes le… Voir la présentation\n",
      "\n",
      "Decoded output vector::\n",
      "Pour htc one mini : coque sur mesure decor pluie d'etoiles - Cette coque fantaisie protège et habille votre HTC ONE Mini. Parfaitement adaptée, elle permet l'accès à toutes le… Voir la présentationEND\n"
     ]
    }
   ],
   "source": [
    "i_test = 50\n",
    "print(\"\\nOriginal Sentences:\\n%s\"%X[i_test])\n",
    "def decode_sequence(x, int_to_char_dic):\n",
    "    seq = []\n",
    "    for i in np.where(x)[1]:\n",
    "        seq.append(int_to_char_dic[i])\n",
    "    return \"\".join(seq)\n",
    "print(\"\\nDecoded input vector::\\n%s\"%decode_sequence(X_vec[i_test], int_to_char))\n",
    "print(\"\\nDecoded output vector::\\n%s\"%decode_sequence(Y_vec[i_test], int_to_char))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code below enable to predict a sentence by iterativaly predict a character sending a previous character."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0\n",
      "START\n",
      "STARTSamsung Galaxy S5 mini Premiumcoque case matt white - Stars - **Fais une déclaration visuelle!** Notre Hard Case unis un design affiné avec une parfaite protection, sans cacher la belle silho… Voir\n"
     ]
    }
   ],
   "source": [
    "from tensorflow import convert_to_tensor\n",
    "x_pred = np.zeros((1, Ns+1, Nv))\n",
    "print(\"step 0\")\n",
    "x_pred[0,0,char_to_int[\"START\"]] =1\n",
    "x_pred_str = decode_sequence(x_pred[0], int_to_char)\n",
    "print(x_pred_str)\n",
    "\n",
    "for i in range(Ns):\n",
    "    x_tensor = convert_to_tensor(x_pred[:,:i+1,:])\n",
    "    ix = np.argmax(model.predict(x_tensor)[0][-1,:])\n",
    "    x_pred[0,i+1,ix] = 1\n",
    "x_pred_str=decode_sequence(x_pred[0], int_to_char)\n",
    "print(x_pred_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 198, 89)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_pred.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q** How this prediction is done?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercice** Generate a text generation with random first letter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0\n",
      "STARTI\n",
      "STARTISTCOG S ISISIS5 ISS5 Premumche conrate - **Fais une déclaration visuelle!** Notre Hard Case unis un design affiné avec une parfaite protection, sans cacher la belle silho… Voir la présentationEND en\n"
     ]
    }
   ],
   "source": [
    "# %load solution/text_generation_random_first_letter.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercice** Generate a text generation with some randomness. For example, use a multinomial from the model output to generate a characters at each step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0\n",
      "START\n",
      "STARTSamsung Galaxy S2 i9100 Hardcoque case noir - Keecettrilep Fraxely rower h? xu - **Amortisseur pouENDs patr,phècee & bl… Voir la présentationEND & tant … Voir la présentationEND ent… Voir la présentation\r"
     ]
    }
   ],
   "source": [
    "# %load solution/text_generation_multinomial.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text classification\n",
    "\n",
    "In this part the objective is to classify description of `Cdiscount` product as in the two first notebooks of this **Text** session.\n",
    "\n",
    "We will the use a **many-to-one** RNN architecture both at training and prediction.\n",
    "\n",
    "<img src=\"https://github.com/wikistat/AI-Frameworks/blob/master/Text/images/many_to_one.png?raw=true\" alt=\"drawing\" width=\"400\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data\n",
    "\n",
    "Let us first load and clean the data with the function you now know."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 445/100000 [00:00<00:45, 2189.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Clean 100000 lines\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100000/100000 [00:38<00:00, 2624.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The train dataset is composed of 100000 lines\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Categorie1</th>\n",
       "      <th>Categorie2</th>\n",
       "      <th>Categorie3</th>\n",
       "      <th>Description</th>\n",
       "      <th>Libelle</th>\n",
       "      <th>Marque</th>\n",
       "      <th>Description_cleaned</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>INFORMATIQUE</td>\n",
       "      <td>CONNECTIQUE - ALIMENTATION</td>\n",
       "      <td>BATTERIE</td>\n",
       "      <td>Batterie Acer Aspire One 751H-52Yr - Li-Ion 11...</td>\n",
       "      <td>Batterie Acer Aspire One 751H-52Yr</td>\n",
       "      <td>AUCUNE</td>\n",
       "      <td>batter acer aspir one h yr li ion v mah wh noi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TELEPHONIE - GPS</td>\n",
       "      <td>ACCESSOIRE TELEPHONE</td>\n",
       "      <td>COQUE - BUMPER - FACADE TELEPHONE</td>\n",
       "      <td>Coque rigide Bleu lagon pour ALCATEL OT / 6033...</td>\n",
       "      <td>Coque rigide Bleu lagon pour ALCATEL OT / 6033 …</td>\n",
       "      <td>MUZZANO</td>\n",
       "      <td>coqu rigid bleu lagon alcatel ot motif drapeau...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TELEPHONIE - GPS</td>\n",
       "      <td>ACCESSOIRE TELEPHONE</td>\n",
       "      <td>COQUE - BUMPER - FACADE TELEPHONE</td>\n",
       "      <td>Facades et coques CELLULAR LINE SHCKGALS 3 MIN...</td>\n",
       "      <td>Facades et coques CELLULAR LINE SHCKGALS 3 MINIP</td>\n",
       "      <td>CELLULAR LINE</td>\n",
       "      <td>facad coqu cellular lin shckgal minip marqu ag...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TELEPHONIE - GPS</td>\n",
       "      <td>ACCESSOIRE TELEPHONE</td>\n",
       "      <td>COQUE - BUMPER - FACADE TELEPHONE</td>\n",
       "      <td>Coque meteore TPU  LG Nexus 4 / E960</td>\n",
       "      <td>Coque meteore TPU  LG Nexus 4 / E960</td>\n",
       "      <td>AUCUNE</td>\n",
       "      <td>coqu meteor tpu lg nexus e</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TELEPHONIE - GPS</td>\n",
       "      <td>ACCESSOIRE TELEPHONE</td>\n",
       "      <td>COQUE - BUMPER - FACADE TELEPHONE</td>\n",
       "      <td>Coque souple Transparente pour LG G FLEX D959 ...</td>\n",
       "      <td>Coque souple Transparente pour LG G FLEX D959 m…</td>\n",
       "      <td>MUZZANO</td>\n",
       "      <td>coqu soupl transparent lg g flex motif keep ca...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Categorie1                  Categorie2  \\\n",
       "0      INFORMATIQUE  CONNECTIQUE - ALIMENTATION   \n",
       "1  TELEPHONIE - GPS        ACCESSOIRE TELEPHONE   \n",
       "2  TELEPHONIE - GPS        ACCESSOIRE TELEPHONE   \n",
       "3  TELEPHONIE - GPS        ACCESSOIRE TELEPHONE   \n",
       "4  TELEPHONIE - GPS        ACCESSOIRE TELEPHONE   \n",
       "\n",
       "                          Categorie3  \\\n",
       "0                           BATTERIE   \n",
       "1  COQUE - BUMPER - FACADE TELEPHONE   \n",
       "2  COQUE - BUMPER - FACADE TELEPHONE   \n",
       "3  COQUE - BUMPER - FACADE TELEPHONE   \n",
       "4  COQUE - BUMPER - FACADE TELEPHONE   \n",
       "\n",
       "                                         Description  \\\n",
       "0  Batterie Acer Aspire One 751H-52Yr - Li-Ion 11...   \n",
       "1  Coque rigide Bleu lagon pour ALCATEL OT / 6033...   \n",
       "2  Facades et coques CELLULAR LINE SHCKGALS 3 MIN...   \n",
       "3               Coque meteore TPU  LG Nexus 4 / E960   \n",
       "4  Coque souple Transparente pour LG G FLEX D959 ...   \n",
       "\n",
       "                                            Libelle         Marque  \\\n",
       "0                Batterie Acer Aspire One 751H-52Yr         AUCUNE   \n",
       "1  Coque rigide Bleu lagon pour ALCATEL OT / 6033 …        MUZZANO   \n",
       "2  Facades et coques CELLULAR LINE SHCKGALS 3 MINIP  CELLULAR LINE   \n",
       "3              Coque meteore TPU  LG Nexus 4 / E960         AUCUNE   \n",
       "4  Coque souple Transparente pour LG G FLEX D959 m…        MUZZANO   \n",
       "\n",
       "                                 Description_cleaned  \n",
       "0  batter acer aspir one h yr li ion v mah wh noi...  \n",
       "1  coqu rigid bleu lagon alcatel ot motif drapeau...  \n",
       "2  facad coqu cellular lin shckgal minip marqu ag...  \n",
       "3                         coqu meteor tpu lg nexus e  \n",
       "4  coqu soupl transparent lg g flex motif keep ca...  "
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ct = CleanText()\n",
    "data = pd.read_csv(\"data/cdiscount_train.csv.zip\",sep=\",\", nrows=100000)\n",
    "ct.clean_df_column(data, \"Description\", \"Description_cleaned\")\n",
    "print(\"The train dataset is composed of %d lines\" %data.shape[0])\n",
    "data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 248/50000 [00:00<00:20, 2474.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Clean 50000 lines\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50000/50000 [00:18<00:00, 2749.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The train dataset is composed of 50000 lines\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Categorie1</th>\n",
       "      <th>Categorie2</th>\n",
       "      <th>Categorie3</th>\n",
       "      <th>Description</th>\n",
       "      <th>Libelle</th>\n",
       "      <th>Marque</th>\n",
       "      <th>Description_cleaned</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BRICOLAGE - OUTILLAGE - QUINCAILLERIE</td>\n",
       "      <td>ELECTRICITE  DOMOTIQUE</td>\n",
       "      <td>MULTIPRISE - RALLONGE - ENROULEUR</td>\n",
       "      <td>Rallonge CEE avec inverseur de phase 25 m 16 A...</td>\n",
       "      <td>Rallonge CEE avec inverseur de phase 25 m 16 A</td>\n",
       "      <td>AUCUNE</td>\n",
       "      <td>rallong ce inverseur phas rallong ce haut qual...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DECO - LINGE - LUMINAIRE</td>\n",
       "      <td>OBJET DE DECORATION - BIBELOT</td>\n",
       "      <td>BUSTE - MANNEQUIN</td>\n",
       "      <td>Sun d’koh - Buste de Bouddha sur socle - cimen...</td>\n",
       "      <td>Sun d’koh - Buste de Bouddha sur socle - ciment…</td>\n",
       "      <td>SUN D’KOH</td>\n",
       "      <td>sun dkoh bust bouddh socl ciment cm tet bouddh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HYGIENE - BEAUTE - PARFUM</td>\n",
       "      <td>NAIL ART</td>\n",
       "      <td>STICKERS - AUTOCOLLANT - STRASS - PAILLETTES -...</td>\n",
       "      <td>La planche contient 24 motifs Support : ongle ...</td>\n",
       "      <td>STICKERS COLLIER STRASS FLEUR ONGLE ADHESIF</td>\n",
       "      <td>AUCUNE</td>\n",
       "      <td>planch contient motif support ongle naturel ca...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LIBRAIRIE</td>\n",
       "      <td>AUTRES LIVRES</td>\n",
       "      <td>AUTRES LIVRES</td>\n",
       "      <td>De Blodwenn Mauffret aux éditions IBIS ROUGE</td>\n",
       "      <td>LE CARNAVAL DE CAYENNE</td>\n",
       "      <td>AUCUNE</td>\n",
       "      <td>blodwen mauffret edit ibis roug</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>VETEMENTS - LINGERIE</td>\n",
       "      <td>ACCESSOIRE MODE</td>\n",
       "      <td>CHAPEAU - BOB</td>\n",
       "      <td>Chapeau  - Casquette béret Modèle féminin et t...</td>\n",
       "      <td>Chapeau ... TU</td>\n",
       "      <td>AUCUNE</td>\n",
       "      <td>chapeau casquet beret model feminin tendanc mo...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              Categorie1                     Categorie2  \\\n",
       "0  BRICOLAGE - OUTILLAGE - QUINCAILLERIE        ELECTRICITE  DOMOTIQUE   \n",
       "1               DECO - LINGE - LUMINAIRE  OBJET DE DECORATION - BIBELOT   \n",
       "2              HYGIENE - BEAUTE - PARFUM                       NAIL ART   \n",
       "3                              LIBRAIRIE                  AUTRES LIVRES   \n",
       "4                  VETEMENTS - LINGERIE                 ACCESSOIRE MODE   \n",
       "\n",
       "                                          Categorie3  \\\n",
       "0                  MULTIPRISE - RALLONGE - ENROULEUR   \n",
       "1                                  BUSTE - MANNEQUIN   \n",
       "2  STICKERS - AUTOCOLLANT - STRASS - PAILLETTES -...   \n",
       "3                                      AUTRES LIVRES   \n",
       "4                                     CHAPEAU - BOB    \n",
       "\n",
       "                                         Description  \\\n",
       "0  Rallonge CEE avec inverseur de phase 25 m 16 A...   \n",
       "1  Sun d’koh - Buste de Bouddha sur socle - cimen...   \n",
       "2  La planche contient 24 motifs Support : ongle ...   \n",
       "3       De Blodwenn Mauffret aux éditions IBIS ROUGE   \n",
       "4  Chapeau  - Casquette béret Modèle féminin et t...   \n",
       "\n",
       "                                            Libelle     Marque  \\\n",
       "0    Rallonge CEE avec inverseur de phase 25 m 16 A     AUCUNE   \n",
       "1  Sun d’koh - Buste de Bouddha sur socle - ciment…  SUN D’KOH   \n",
       "2       STICKERS COLLIER STRASS FLEUR ONGLE ADHESIF     AUCUNE   \n",
       "3                            LE CARNAVAL DE CAYENNE     AUCUNE   \n",
       "4                                    Chapeau ... TU     AUCUNE   \n",
       "\n",
       "                                 Description_cleaned  \n",
       "0  rallong ce inverseur phas rallong ce haut qual...  \n",
       "1  sun dkoh bust bouddh socl ciment cm tet bouddh...  \n",
       "2  planch contient motif support ongle naturel ca...  \n",
       "3                    blodwen mauffret edit ibis roug  \n",
       "4  chapeau casquet beret model feminin tendanc mo...  "
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_test = pd.read_csv(\"data/cdiscount_test.csv.zip\",sep=\",\")\n",
    "ct.clean_df_column(data_test, \"Description\", \"Description_cleaned\")\n",
    "print(\"The train dataset is composed of %d lines\" %data_test.shape[0])\n",
    "data_test.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now split the data into train and validation dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train, data_valid = sms.train_test_split(data, test_size=0.1, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's get list of words for each line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_array_token = [line.split(\" \") for line in data_train[\"Description_cleaned\"].values]\n",
    "valid_array_token = [line.split(\" \") for line in data_valid[\"Description_cleaned\"].values]\n",
    "test_array_token = [line.split(\" \") for line in data_test[\"Description_cleaned\"].values]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And finally list of array of integer label (keras does not handle string label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_to_int = {k:i for i,k in enumerate(set(data_train.Categorie1.values))}\n",
    "N_label = len(label_to_int)\n",
    "Y_train = np.array([label_to_int[k] for k  in data_train.Categorie1.values])\n",
    "Y_valid = np.array([label_to_int[k] for k in data_valid.Categorie1.values])\n",
    "Y_test = np.array([label_to_int[k] for k in data_test.Categorie1.values])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encoding the data.\n",
    "\n",
    "In this problem sequences of word will be considered (and not sequence of characters). <br>\n",
    "Several possibilities are possible to convert the sentences:\n",
    "\n",
    "* Count Vectorizer or TF-IDF encoding. \n",
    "    * **sklearn** `CountVectorizer` or  `TF-IDF` produce sparse vector that are not handling correctly with `Keras` model.<br>    Hence the solutions to use these encoding would be to create non-sparse matrix. But this implies to create really large matrix (regarding to the size of th vocabulary\n",
    "* Word Embedding vectors.\n",
    "    * With the **Word2Vec** embedding we learn in the previous notebook we can create vector of size 300 from each word. which would produce reasonable sequence size. Moreoever, the *full_model_sg* was the model who gives the best results.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'data/w2v_model/full_model_sg'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-63-d572eba2c087>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgensim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mKeyedVectors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmodel_sg_full\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mKeyedVectors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"data/w2v_model/full_model_sg\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/gensim/models/keyedvectors.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(cls, fname_or_handle, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mclassmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1552\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfname_or_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1553\u001b[0;31m         \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mWordEmbeddingsKeyedVectors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname_or_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1554\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mFastTextKeyedVectors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1555\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'compatible_hash'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/gensim/models/keyedvectors.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(cls, fname_or_handle, **kwargs)\u001b[0m\n\u001b[1;32m    226\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mclassmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfname_or_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 228\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBaseKeyedVectors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname_or_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    229\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    230\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0msimilarity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mentity1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mentity2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/gensim/utils.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(cls, fname, mmap)\u001b[0m\n\u001b[1;32m    433\u001b[0m         \u001b[0mcompress\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSaveLoad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_adapt_by_suffix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    434\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 435\u001b[0;31m         \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0munpickle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    436\u001b[0m         \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_load_specials\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmmap\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompress\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    437\u001b[0m         \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"loaded %s\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/gensim/utils.py\u001b[0m in \u001b[0;36munpickle\u001b[0;34m(fname)\u001b[0m\n\u001b[1;32m   1393\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1394\u001b[0m     \"\"\"\n\u001b[0;32m-> 1395\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1396\u001b[0m         \u001b[0;31m# Because of loading from S3 load can't be used (missing readline in smart_open)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1397\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mversion_info\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/smart_open/smart_open_lib.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(uri, mode, buffering, encoding, errors, newline, closefd, opener, ignore_ext, transport_params)\u001b[0m\n\u001b[1;32m    179\u001b[0m         \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m         \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 181\u001b[0;31m         \u001b[0mnewline\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnewline\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    182\u001b[0m     )\n\u001b[1;32m    183\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfobj\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/smart_open/smart_open_lib.py\u001b[0m in \u001b[0;36m_shortcut_open\u001b[0;34m(uri, mode, ignore_ext, buffering, encoding, errors, newline)\u001b[0m\n\u001b[1;32m    344\u001b[0m         \u001b[0mopen_kwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'errors'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    345\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 346\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_builtin_open\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlocal_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffering\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbuffering\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mopen_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    347\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    348\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'data/w2v_model/full_model_sg'"
     ]
    }
   ],
   "source": [
    "from gensim.models import KeyedVectors\n",
    "model_sg_full = KeyedVectors.load(\"data/w2v_model/full_model_sg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The plot below display the distribution of the length of all the sequences of the train dataset (i.e the number of word).<br>\n",
    "The biggest sequence is composed of 43 words which means that all encoding sequences should have a size of 43   <br>\n",
    "We can see that the 99% percentile of this distribution is 28.\n",
    "Hence we decide to get only the 28 first words of each distribution. and only a very small portion (1%) of the dataset will have cut sentences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/brendanguillouet/anaconda3/lib/python3.7/site-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
      "  import pandas.util.testing as tm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max length sequences: 43\n",
      "Percentiles at 90%: 24, 95%: 26 and 99%: 28\n"
     ]
    }
   ],
   "source": [
    "all_sequences_length = [len(x) for x in train_array_token]\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sb\n",
    "sb.set_style(\"whitegrid\")\n",
    "fig = plt.figure(figsize=(10,10))\n",
    "ax = fig.add_subplot(1,1,1)\n",
    "ax.hist(all_sequences_length, 50, cumulative=True, density=True)\n",
    "\n",
    "print(\"Max length sequences: %d\" %max(all_sequences_length))\n",
    "print(\"Percentiles at 90%%: %d, 95%%: %d and 99%%: %d\" %tuple([x for x in np.percentile(all_sequences_length, q=[90,95,99])]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ns = 28"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise** Build a function that encode an the `array_token` to tensor that will be used for learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokens_to_embedding_sequences(array_token, model):\n",
    "    # Todo\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load solution/token_to_embedding_sequence\n",
    "def tokens_to_embedding_sequences(array_token, model):\n",
    "    array_embedding_sequences = []\n",
    "    for tokens in tqdm(array_token):\n",
    "        embedding_sequence = []\n",
    "        for token in tokens[:Ns]:\n",
    "             embedding_sequence.append(model[token])\n",
    "        array_embedding_sequences.append(embedding_sequence)\n",
    "    X = pad_sequences(array_embedding_sequences)\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model_sg_full' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-68-3206b06f7ecd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mX_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtokens_to_embedding_sequences\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_array_token\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_sg_full\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mX_valid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtokens_to_embedding_sequences\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalid_array_token\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_sg_full\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mX_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtokens_to_embedding_sequences\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_array_token\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_sg_full\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model_sg_full' is not defined"
     ]
    }
   ],
   "source": [
    "X_train = tokens_to_embedding_sequences(train_array_token, model_sg_full)\n",
    "X_valid = tokens_to_embedding_sequences(valid_array_token, model_sg_full)\n",
    "X_test = tokens_to_embedding_sequences(test_array_token, model_sg_full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-69-9c3aa483adca>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32massert\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m90000\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mNs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m300\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32massert\u001b[0m \u001b[0mX_valid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m10000\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mNs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m300\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32massert\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m50000\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mNs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m300\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'X_train' is not defined"
     ]
    }
   ],
   "source": [
    "assert X_train.shape == (90000,Ns,300) \n",
    "assert X_valid.shape == (10000,Ns,300) \n",
    "assert X_test.shape == (50000,Ns,300) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise** Build now a model to learn how to predict the classification from this sequence and train it! <br>\n",
    "The model given as a solution is very simple and has not been studied to produce good results. It's just a working example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load solution/rnn_classifier_model.py\n",
    "model = km.Sequential()\n",
    "model.add(kl.LSTM(units=256 ,activation=\"relu\", input_shape=(28, 300)))\n",
    "model.add(kl.Dense(256))\n",
    "model.add(kl.Activation(\"relu\"))\n",
    "model.add(kl.Dense(N_label))\n",
    "model.add(kl.Activation(\"softmax\"))\n",
    "model.summary()\n",
    "\n",
    "epochs = 500\n",
    "batch_size=256\n",
    "history = model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "model.fit(X_train, Y_train, epochs=epochs, batch_size=batch_size, verbose=1, validation_data=[X_valid, Y_valid])\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
