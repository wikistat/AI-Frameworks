## <a href="http://www.insa-toulouse.fr/" ><img src="http://www.math.univ-toulouse.fr/~besse/Wikistat/Images/Logo_INSAvilletoulouse-RVB.png" style="float:left; max-width: 80px; display: inline" alt="INSA"/> |  [*Mathématiques Appliquées*](http://www.math.insa-toulouse.fr/fr/index.html), [`Science des Données`](http://www.math.insa-toulouse.fr/fr/enseignement.html) 

## [Ateliers: Technologies des Données Massives](https://github.com/wikistat/Ateliers-Big-Data) avec [R](https://cran.r-project.org/), [Python](https://www.python.org/) et / ou [Spark](href="http://spark.apache.org/)

L'objectifs de ces ateliers ou tutoriels sous forme de calepins ([*jupyter notebooks*](http://jupyter.org/)) est d'introduire le **passage à l'échelle Volume** des méthodes d'apprentissage; **processus qui transforme un statisticien en *Data Scientist*.** 


# Reconnaissance d'images: [Cats *vs.* Dogs](https://www.kaggle.com/c/dogs-vs-cats/data)


**Résumé** 
Le transfert d'apprentissage est une stratégie qui vise à réduire les temps considétrables d'apprentissage. Un réseau profond déjà entraîné sur une très grosse base est adapté à un problème spécifique. Ceci est appliqué à la reconnaissance d'images: distinguer chiens et chats, à partir de réseaux dajà appris.


## Tutoriel
[Cats vs. Dogs](https://github.com/wikistat/Ateliers-Big-Data/tree/master/CatsVSDogs) utilisaiton de Keras et tensorflow pour comparer les performances: temps d'apprentissage et précision, d'un réseau original avec un réseau transféré.



