{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [IA Frameworks](https://github.com/wikistat/AI-Frameworks) - Introduction to Deep Reinforcement Learning "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>\n",
    "<a href=\"http://www.insa-toulouse.fr/\" ><img src=\"http://www.math.univ-toulouse.fr/~besse/Wikistat/Images/logo-insa.jpg\" style=\"float:left; max-width: 120px; display: inline\" alt=\"INSA\"/></a> \n",
    "<a href=\"http://wikistat.fr/\" ><img src=\"http://www.math.univ-toulouse.fr/~besse/Wikistat/Images/wikistat.jpg\" width=400, style=\"max-width: 150px; display: inline\"  alt=\"Wikistat\"/></a>\n",
    "<a href=\"http://www.math.univ-toulouse.fr/\" ><img src=\"http://www.math.univ-toulouse.fr/~besse/Wikistat/Images/logo_imt.jpg\" width=400,  style=\"float:right;  display: inline\" alt=\"IMT\"/> </a>\n",
    "    \n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1 : Deep Q-Network\n",
    "The objectives of this noteboks are the following : \n",
    "\n",
    "* Implement DQN on a pacman-like game (gridworld)\n",
    "* Implement D3QN on the same game\n",
    " \n",
    "Source : [https://github.com/ageron/handson-ml](https://github.com/ageron/handson-ml) and https://github.com/breeko/Simple-Reinforcement-Learning-with-Tensorflow/blob/master/Part%202%20-%20Policy-based%20Agents%20with%20Keras.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import librairies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import numpy as np\n",
    "import random\n",
    "import os\n",
    "\n",
    "# to make this notebook's output stable across runs\n",
    "def reset_graph(seed=42):\n",
    "    tf.reset_default_graph()\n",
    "    tf.set_random_seed(seed)\n",
    "    np.random.seed(seed)\n",
    "\n",
    "# To plot figures and animations\n",
    "%matplotlib inline\n",
    "%matplotlib nbagg\n",
    "import matplotlib\n",
    "import matplotlib.animation as animation\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import HTML\n",
    "\n",
    "\n",
    "plt.rcParams['axes.labelsize'] = 14\n",
    "plt.rcParams['xtick.labelsize'] = 12\n",
    "plt.rcParams['ytick.labelsize'] = 12\n",
    "\n",
    "\n",
    "import tensorflow.keras.models as km\n",
    "import tensorflow.keras.layers as kl\n",
    "import tensorflow.keras.initializers as ki\n",
    "import tensorflow.keras.optimizers as ko\n",
    "import tensorflow.keras.losses as klo\n",
    "import tensorflow.keras.backend as K\n",
    "\n",
    "\n",
    "# Gym Librairy\n",
    "import gym\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "def update_scene(num, frames, patch):\n",
    "    patch.set_data(frames[num])\n",
    "    return patch,\n",
    "\n",
    "def plot_animation(frames, repeat=False, interval=400):\n",
    "    plt.close()  # or else nbagg sometimes plots in the previous cell\n",
    "    fig = plt.figure()\n",
    "    patch = plt.imshow(frames[0])\n",
    "    plt.axis('off')\n",
    "    return animation.FuncAnimation(fig, update_scene, fargs=(frames, patch), frames=len(frames), repeat=repeat, interval=interval)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DEEP Q Learning on *Pacman-Like* Game\n",
    "\n",
    "We have seen how to learn an optimal policy on a Markov Decision Process. \n",
    "\n",
    "Let's now try to learn how to play a Video Game Like Pacman. \n",
    "\n",
    "We won't use directly Pacman here (Even if it's available on Gym environment (see below)). The Pacman game requires GPU to be trained and may need some try and parameter optimization to easily converged. \n",
    "\n",
    "Hence, we will start with and simpler environment which looks like Pacman : the [gridworld](https://github.com/awjuliani/DeepRL-Agents/blob/master/gridworld.py) environment.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grid World environment\n",
    "\n",
    "We have a 5x5 blocs where blue, green and red squares. In the environment:\n",
    "* the **agent** controls a *blue* square\n",
    "* the goal is to navigate to the *green* squares (**reward** +1) \n",
    "* and avoiding the *red* squares (**reward** -1).\n",
    "\n",
    "#### Observation\n",
    "\n",
    "The observation is the image itself which is a 84x84x3 images.\n",
    "\n",
    "#### Actions\n",
    "\n",
    "Num | Action\n",
    "--- | ---\n",
    "0 | Go Up\n",
    "1 | Go Down\n",
    "2 | Go Left\n",
    "3 | Go Right\n",
    "\n",
    "\n",
    "#### Reward\n",
    "Reward is 1 for every green square taken and -1 when a red square is taken\n",
    "\n",
    "#### End epsiode\n",
    "There are no condition limit for an episode to finish"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We initiate the environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "/* Put everything inside the global mpl namespace */\n",
       "window.mpl = {};\n",
       "\n",
       "\n",
       "mpl.get_websocket_type = function() {\n",
       "    if (typeof(WebSocket) !== 'undefined') {\n",
       "        return WebSocket;\n",
       "    } else if (typeof(MozWebSocket) !== 'undefined') {\n",
       "        return MozWebSocket;\n",
       "    } else {\n",
       "        alert('Your browser does not have WebSocket support. ' +\n",
       "              'Please try Chrome, Safari or Firefox ≥ 6. ' +\n",
       "              'Firefox 4 and 5 are also supported but you ' +\n",
       "              'have to enable WebSockets in about:config.');\n",
       "    };\n",
       "}\n",
       "\n",
       "mpl.figure = function(figure_id, websocket, ondownload, parent_element) {\n",
       "    this.id = figure_id;\n",
       "\n",
       "    this.ws = websocket;\n",
       "\n",
       "    this.supports_binary = (this.ws.binaryType != undefined);\n",
       "\n",
       "    if (!this.supports_binary) {\n",
       "        var warnings = document.getElementById(\"mpl-warnings\");\n",
       "        if (warnings) {\n",
       "            warnings.style.display = 'block';\n",
       "            warnings.textContent = (\n",
       "                \"This browser does not support binary websocket messages. \" +\n",
       "                    \"Performance may be slow.\");\n",
       "        }\n",
       "    }\n",
       "\n",
       "    this.imageObj = new Image();\n",
       "\n",
       "    this.context = undefined;\n",
       "    this.message = undefined;\n",
       "    this.canvas = undefined;\n",
       "    this.rubberband_canvas = undefined;\n",
       "    this.rubberband_context = undefined;\n",
       "    this.format_dropdown = undefined;\n",
       "\n",
       "    this.image_mode = 'full';\n",
       "\n",
       "    this.root = $('<div/>');\n",
       "    this._root_extra_style(this.root)\n",
       "    this.root.attr('style', 'display: inline-block');\n",
       "\n",
       "    $(parent_element).append(this.root);\n",
       "\n",
       "    this._init_header(this);\n",
       "    this._init_canvas(this);\n",
       "    this._init_toolbar(this);\n",
       "\n",
       "    var fig = this;\n",
       "\n",
       "    this.waiting = false;\n",
       "\n",
       "    this.ws.onopen =  function () {\n",
       "            fig.send_message(\"supports_binary\", {value: fig.supports_binary});\n",
       "            fig.send_message(\"send_image_mode\", {});\n",
       "            if (mpl.ratio != 1) {\n",
       "                fig.send_message(\"set_dpi_ratio\", {'dpi_ratio': mpl.ratio});\n",
       "            }\n",
       "            fig.send_message(\"refresh\", {});\n",
       "        }\n",
       "\n",
       "    this.imageObj.onload = function() {\n",
       "            if (fig.image_mode == 'full') {\n",
       "                // Full images could contain transparency (where diff images\n",
       "                // almost always do), so we need to clear the canvas so that\n",
       "                // there is no ghosting.\n",
       "                fig.context.clearRect(0, 0, fig.canvas.width, fig.canvas.height);\n",
       "            }\n",
       "            fig.context.drawImage(fig.imageObj, 0, 0);\n",
       "        };\n",
       "\n",
       "    this.imageObj.onunload = function() {\n",
       "        fig.ws.close();\n",
       "    }\n",
       "\n",
       "    this.ws.onmessage = this._make_on_message_function(this);\n",
       "\n",
       "    this.ondownload = ondownload;\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._init_header = function() {\n",
       "    var titlebar = $(\n",
       "        '<div class=\"ui-dialog-titlebar ui-widget-header ui-corner-all ' +\n",
       "        'ui-helper-clearfix\"/>');\n",
       "    var titletext = $(\n",
       "        '<div class=\"ui-dialog-title\" style=\"width: 100%; ' +\n",
       "        'text-align: center; padding: 3px;\"/>');\n",
       "    titlebar.append(titletext)\n",
       "    this.root.append(titlebar);\n",
       "    this.header = titletext[0];\n",
       "}\n",
       "\n",
       "\n",
       "\n",
       "mpl.figure.prototype._canvas_extra_style = function(canvas_div) {\n",
       "\n",
       "}\n",
       "\n",
       "\n",
       "mpl.figure.prototype._root_extra_style = function(canvas_div) {\n",
       "\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._init_canvas = function() {\n",
       "    var fig = this;\n",
       "\n",
       "    var canvas_div = $('<div/>');\n",
       "\n",
       "    canvas_div.attr('style', 'position: relative; clear: both; outline: 0');\n",
       "\n",
       "    function canvas_keyboard_event(event) {\n",
       "        return fig.key_event(event, event['data']);\n",
       "    }\n",
       "\n",
       "    canvas_div.keydown('key_press', canvas_keyboard_event);\n",
       "    canvas_div.keyup('key_release', canvas_keyboard_event);\n",
       "    this.canvas_div = canvas_div\n",
       "    this._canvas_extra_style(canvas_div)\n",
       "    this.root.append(canvas_div);\n",
       "\n",
       "    var canvas = $('<canvas/>');\n",
       "    canvas.addClass('mpl-canvas');\n",
       "    canvas.attr('style', \"left: 0; top: 0; z-index: 0; outline: 0\")\n",
       "\n",
       "    this.canvas = canvas[0];\n",
       "    this.context = canvas[0].getContext(\"2d\");\n",
       "\n",
       "    var backingStore = this.context.backingStorePixelRatio ||\n",
       "\tthis.context.webkitBackingStorePixelRatio ||\n",
       "\tthis.context.mozBackingStorePixelRatio ||\n",
       "\tthis.context.msBackingStorePixelRatio ||\n",
       "\tthis.context.oBackingStorePixelRatio ||\n",
       "\tthis.context.backingStorePixelRatio || 1;\n",
       "\n",
       "    mpl.ratio = (window.devicePixelRatio || 1) / backingStore;\n",
       "\n",
       "    var rubberband = $('<canvas/>');\n",
       "    rubberband.attr('style', \"position: absolute; left: 0; top: 0; z-index: 1;\")\n",
       "\n",
       "    var pass_mouse_events = true;\n",
       "\n",
       "    canvas_div.resizable({\n",
       "        start: function(event, ui) {\n",
       "            pass_mouse_events = false;\n",
       "        },\n",
       "        resize: function(event, ui) {\n",
       "            fig.request_resize(ui.size.width, ui.size.height);\n",
       "        },\n",
       "        stop: function(event, ui) {\n",
       "            pass_mouse_events = true;\n",
       "            fig.request_resize(ui.size.width, ui.size.height);\n",
       "        },\n",
       "    });\n",
       "\n",
       "    function mouse_event_fn(event) {\n",
       "        if (pass_mouse_events)\n",
       "            return fig.mouse_event(event, event['data']);\n",
       "    }\n",
       "\n",
       "    rubberband.mousedown('button_press', mouse_event_fn);\n",
       "    rubberband.mouseup('button_release', mouse_event_fn);\n",
       "    // Throttle sequential mouse events to 1 every 20ms.\n",
       "    rubberband.mousemove('motion_notify', mouse_event_fn);\n",
       "\n",
       "    rubberband.mouseenter('figure_enter', mouse_event_fn);\n",
       "    rubberband.mouseleave('figure_leave', mouse_event_fn);\n",
       "\n",
       "    canvas_div.on(\"wheel\", function (event) {\n",
       "        event = event.originalEvent;\n",
       "        event['data'] = 'scroll'\n",
       "        if (event.deltaY < 0) {\n",
       "            event.step = 1;\n",
       "        } else {\n",
       "            event.step = -1;\n",
       "        }\n",
       "        mouse_event_fn(event);\n",
       "    });\n",
       "\n",
       "    canvas_div.append(canvas);\n",
       "    canvas_div.append(rubberband);\n",
       "\n",
       "    this.rubberband = rubberband;\n",
       "    this.rubberband_canvas = rubberband[0];\n",
       "    this.rubberband_context = rubberband[0].getContext(\"2d\");\n",
       "    this.rubberband_context.strokeStyle = \"#000000\";\n",
       "\n",
       "    this._resize_canvas = function(width, height) {\n",
       "        // Keep the size of the canvas, canvas container, and rubber band\n",
       "        // canvas in synch.\n",
       "        canvas_div.css('width', width)\n",
       "        canvas_div.css('height', height)\n",
       "\n",
       "        canvas.attr('width', width * mpl.ratio);\n",
       "        canvas.attr('height', height * mpl.ratio);\n",
       "        canvas.attr('style', 'width: ' + width + 'px; height: ' + height + 'px;');\n",
       "\n",
       "        rubberband.attr('width', width);\n",
       "        rubberband.attr('height', height);\n",
       "    }\n",
       "\n",
       "    // Set the figure to an initial 600x600px, this will subsequently be updated\n",
       "    // upon first draw.\n",
       "    this._resize_canvas(600, 600);\n",
       "\n",
       "    // Disable right mouse context menu.\n",
       "    $(this.rubberband_canvas).bind(\"contextmenu\",function(e){\n",
       "        return false;\n",
       "    });\n",
       "\n",
       "    function set_focus () {\n",
       "        canvas.focus();\n",
       "        canvas_div.focus();\n",
       "    }\n",
       "\n",
       "    window.setTimeout(set_focus, 100);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._init_toolbar = function() {\n",
       "    var fig = this;\n",
       "\n",
       "    var nav_element = $('<div/>');\n",
       "    nav_element.attr('style', 'width: 100%');\n",
       "    this.root.append(nav_element);\n",
       "\n",
       "    // Define a callback function for later on.\n",
       "    function toolbar_event(event) {\n",
       "        return fig.toolbar_button_onclick(event['data']);\n",
       "    }\n",
       "    function toolbar_mouse_event(event) {\n",
       "        return fig.toolbar_button_onmouseover(event['data']);\n",
       "    }\n",
       "\n",
       "    for(var toolbar_ind in mpl.toolbar_items) {\n",
       "        var name = mpl.toolbar_items[toolbar_ind][0];\n",
       "        var tooltip = mpl.toolbar_items[toolbar_ind][1];\n",
       "        var image = mpl.toolbar_items[toolbar_ind][2];\n",
       "        var method_name = mpl.toolbar_items[toolbar_ind][3];\n",
       "\n",
       "        if (!name) {\n",
       "            // put a spacer in here.\n",
       "            continue;\n",
       "        }\n",
       "        var button = $('<button/>');\n",
       "        button.addClass('ui-button ui-widget ui-state-default ui-corner-all ' +\n",
       "                        'ui-button-icon-only');\n",
       "        button.attr('role', 'button');\n",
       "        button.attr('aria-disabled', 'false');\n",
       "        button.click(method_name, toolbar_event);\n",
       "        button.mouseover(tooltip, toolbar_mouse_event);\n",
       "\n",
       "        var icon_img = $('<span/>');\n",
       "        icon_img.addClass('ui-button-icon-primary ui-icon');\n",
       "        icon_img.addClass(image);\n",
       "        icon_img.addClass('ui-corner-all');\n",
       "\n",
       "        var tooltip_span = $('<span/>');\n",
       "        tooltip_span.addClass('ui-button-text');\n",
       "        tooltip_span.html(tooltip);\n",
       "\n",
       "        button.append(icon_img);\n",
       "        button.append(tooltip_span);\n",
       "\n",
       "        nav_element.append(button);\n",
       "    }\n",
       "\n",
       "    var fmt_picker_span = $('<span/>');\n",
       "\n",
       "    var fmt_picker = $('<select/>');\n",
       "    fmt_picker.addClass('mpl-toolbar-option ui-widget ui-widget-content');\n",
       "    fmt_picker_span.append(fmt_picker);\n",
       "    nav_element.append(fmt_picker_span);\n",
       "    this.format_dropdown = fmt_picker[0];\n",
       "\n",
       "    for (var ind in mpl.extensions) {\n",
       "        var fmt = mpl.extensions[ind];\n",
       "        var option = $(\n",
       "            '<option/>', {selected: fmt === mpl.default_extension}).html(fmt);\n",
       "        fmt_picker.append(option);\n",
       "    }\n",
       "\n",
       "    // Add hover states to the ui-buttons\n",
       "    $( \".ui-button\" ).hover(\n",
       "        function() { $(this).addClass(\"ui-state-hover\");},\n",
       "        function() { $(this).removeClass(\"ui-state-hover\");}\n",
       "    );\n",
       "\n",
       "    var status_bar = $('<span class=\"mpl-message\"/>');\n",
       "    nav_element.append(status_bar);\n",
       "    this.message = status_bar[0];\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.request_resize = function(x_pixels, y_pixels) {\n",
       "    // Request matplotlib to resize the figure. Matplotlib will then trigger a resize in the client,\n",
       "    // which will in turn request a refresh of the image.\n",
       "    this.send_message('resize', {'width': x_pixels, 'height': y_pixels});\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.send_message = function(type, properties) {\n",
       "    properties['type'] = type;\n",
       "    properties['figure_id'] = this.id;\n",
       "    this.ws.send(JSON.stringify(properties));\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.send_draw_message = function() {\n",
       "    if (!this.waiting) {\n",
       "        this.waiting = true;\n",
       "        this.ws.send(JSON.stringify({type: \"draw\", figure_id: this.id}));\n",
       "    }\n",
       "}\n",
       "\n",
       "\n",
       "mpl.figure.prototype.handle_save = function(fig, msg) {\n",
       "    var format_dropdown = fig.format_dropdown;\n",
       "    var format = format_dropdown.options[format_dropdown.selectedIndex].value;\n",
       "    fig.ondownload(fig, format);\n",
       "}\n",
       "\n",
       "\n",
       "mpl.figure.prototype.handle_resize = function(fig, msg) {\n",
       "    var size = msg['size'];\n",
       "    if (size[0] != fig.canvas.width || size[1] != fig.canvas.height) {\n",
       "        fig._resize_canvas(size[0], size[1]);\n",
       "        fig.send_message(\"refresh\", {});\n",
       "    };\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_rubberband = function(fig, msg) {\n",
       "    var x0 = msg['x0'] / mpl.ratio;\n",
       "    var y0 = (fig.canvas.height - msg['y0']) / mpl.ratio;\n",
       "    var x1 = msg['x1'] / mpl.ratio;\n",
       "    var y1 = (fig.canvas.height - msg['y1']) / mpl.ratio;\n",
       "    x0 = Math.floor(x0) + 0.5;\n",
       "    y0 = Math.floor(y0) + 0.5;\n",
       "    x1 = Math.floor(x1) + 0.5;\n",
       "    y1 = Math.floor(y1) + 0.5;\n",
       "    var min_x = Math.min(x0, x1);\n",
       "    var min_y = Math.min(y0, y1);\n",
       "    var width = Math.abs(x1 - x0);\n",
       "    var height = Math.abs(y1 - y0);\n",
       "\n",
       "    fig.rubberband_context.clearRect(\n",
       "        0, 0, fig.canvas.width / mpl.ratio, fig.canvas.height / mpl.ratio);\n",
       "\n",
       "    fig.rubberband_context.strokeRect(min_x, min_y, width, height);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_figure_label = function(fig, msg) {\n",
       "    // Updates the figure title.\n",
       "    fig.header.textContent = msg['label'];\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_cursor = function(fig, msg) {\n",
       "    var cursor = msg['cursor'];\n",
       "    switch(cursor)\n",
       "    {\n",
       "    case 0:\n",
       "        cursor = 'pointer';\n",
       "        break;\n",
       "    case 1:\n",
       "        cursor = 'default';\n",
       "        break;\n",
       "    case 2:\n",
       "        cursor = 'crosshair';\n",
       "        break;\n",
       "    case 3:\n",
       "        cursor = 'move';\n",
       "        break;\n",
       "    }\n",
       "    fig.rubberband_canvas.style.cursor = cursor;\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_message = function(fig, msg) {\n",
       "    fig.message.textContent = msg['message'];\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_draw = function(fig, msg) {\n",
       "    // Request the server to send over a new figure.\n",
       "    fig.send_draw_message();\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_image_mode = function(fig, msg) {\n",
       "    fig.image_mode = msg['mode'];\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.updated_canvas_event = function() {\n",
       "    // Called whenever the canvas gets updated.\n",
       "    this.send_message(\"ack\", {});\n",
       "}\n",
       "\n",
       "// A function to construct a web socket function for onmessage handling.\n",
       "// Called in the figure constructor.\n",
       "mpl.figure.prototype._make_on_message_function = function(fig) {\n",
       "    return function socket_on_message(evt) {\n",
       "        if (evt.data instanceof Blob) {\n",
       "            /* FIXME: We get \"Resource interpreted as Image but\n",
       "             * transferred with MIME type text/plain:\" errors on\n",
       "             * Chrome.  But how to set the MIME type?  It doesn't seem\n",
       "             * to be part of the websocket stream */\n",
       "            evt.data.type = \"image/png\";\n",
       "\n",
       "            /* Free the memory for the previous frames */\n",
       "            if (fig.imageObj.src) {\n",
       "                (window.URL || window.webkitURL).revokeObjectURL(\n",
       "                    fig.imageObj.src);\n",
       "            }\n",
       "\n",
       "            fig.imageObj.src = (window.URL || window.webkitURL).createObjectURL(\n",
       "                evt.data);\n",
       "            fig.updated_canvas_event();\n",
       "            fig.waiting = false;\n",
       "            return;\n",
       "        }\n",
       "        else if (typeof evt.data === 'string' && evt.data.slice(0, 21) == \"data:image/png;base64\") {\n",
       "            fig.imageObj.src = evt.data;\n",
       "            fig.updated_canvas_event();\n",
       "            fig.waiting = false;\n",
       "            return;\n",
       "        }\n",
       "\n",
       "        var msg = JSON.parse(evt.data);\n",
       "        var msg_type = msg['type'];\n",
       "\n",
       "        // Call the  \"handle_{type}\" callback, which takes\n",
       "        // the figure and JSON message as its only arguments.\n",
       "        try {\n",
       "            var callback = fig[\"handle_\" + msg_type];\n",
       "        } catch (e) {\n",
       "            console.log(\"No handler for the '\" + msg_type + \"' message type: \", msg);\n",
       "            return;\n",
       "        }\n",
       "\n",
       "        if (callback) {\n",
       "            try {\n",
       "                // console.log(\"Handling '\" + msg_type + \"' message: \", msg);\n",
       "                callback(fig, msg);\n",
       "            } catch (e) {\n",
       "                console.log(\"Exception inside the 'handler_\" + msg_type + \"' callback:\", e, e.stack, msg);\n",
       "            }\n",
       "        }\n",
       "    };\n",
       "}\n",
       "\n",
       "// from http://stackoverflow.com/questions/1114465/getting-mouse-location-in-canvas\n",
       "mpl.findpos = function(e) {\n",
       "    //this section is from http://www.quirksmode.org/js/events_properties.html\n",
       "    var targ;\n",
       "    if (!e)\n",
       "        e = window.event;\n",
       "    if (e.target)\n",
       "        targ = e.target;\n",
       "    else if (e.srcElement)\n",
       "        targ = e.srcElement;\n",
       "    if (targ.nodeType == 3) // defeat Safari bug\n",
       "        targ = targ.parentNode;\n",
       "\n",
       "    // jQuery normalizes the pageX and pageY\n",
       "    // pageX,Y are the mouse positions relative to the document\n",
       "    // offset() returns the position of the element relative to the document\n",
       "    var x = e.pageX - $(targ).offset().left;\n",
       "    var y = e.pageY - $(targ).offset().top;\n",
       "\n",
       "    return {\"x\": x, \"y\": y};\n",
       "};\n",
       "\n",
       "/*\n",
       " * return a copy of an object with only non-object keys\n",
       " * we need this to avoid circular references\n",
       " * http://stackoverflow.com/a/24161582/3208463\n",
       " */\n",
       "function simpleKeys (original) {\n",
       "  return Object.keys(original).reduce(function (obj, key) {\n",
       "    if (typeof original[key] !== 'object')\n",
       "        obj[key] = original[key]\n",
       "    return obj;\n",
       "  }, {});\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.mouse_event = function(event, name) {\n",
       "    var canvas_pos = mpl.findpos(event)\n",
       "\n",
       "    if (name === 'button_press')\n",
       "    {\n",
       "        this.canvas.focus();\n",
       "        this.canvas_div.focus();\n",
       "    }\n",
       "\n",
       "    var x = canvas_pos.x * mpl.ratio;\n",
       "    var y = canvas_pos.y * mpl.ratio;\n",
       "\n",
       "    this.send_message(name, {x: x, y: y, button: event.button,\n",
       "                             step: event.step,\n",
       "                             guiEvent: simpleKeys(event)});\n",
       "\n",
       "    /* This prevents the web browser from automatically changing to\n",
       "     * the text insertion cursor when the button is pressed.  We want\n",
       "     * to control all of the cursor setting manually through the\n",
       "     * 'cursor' event from matplotlib */\n",
       "    event.preventDefault();\n",
       "    return false;\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._key_event_extra = function(event, name) {\n",
       "    // Handle any extra behaviour associated with a key event\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.key_event = function(event, name) {\n",
       "\n",
       "    // Prevent repeat events\n",
       "    if (name == 'key_press')\n",
       "    {\n",
       "        if (event.which === this._key)\n",
       "            return;\n",
       "        else\n",
       "            this._key = event.which;\n",
       "    }\n",
       "    if (name == 'key_release')\n",
       "        this._key = null;\n",
       "\n",
       "    var value = '';\n",
       "    if (event.ctrlKey && event.which != 17)\n",
       "        value += \"ctrl+\";\n",
       "    if (event.altKey && event.which != 18)\n",
       "        value += \"alt+\";\n",
       "    if (event.shiftKey && event.which != 16)\n",
       "        value += \"shift+\";\n",
       "\n",
       "    value += 'k';\n",
       "    value += event.which.toString();\n",
       "\n",
       "    this._key_event_extra(event, name);\n",
       "\n",
       "    this.send_message(name, {key: value,\n",
       "                             guiEvent: simpleKeys(event)});\n",
       "    return false;\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.toolbar_button_onclick = function(name) {\n",
       "    if (name == 'download') {\n",
       "        this.handle_save(this, null);\n",
       "    } else {\n",
       "        this.send_message(\"toolbar_button\", {name: name});\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.toolbar_button_onmouseover = function(tooltip) {\n",
       "    this.message.textContent = tooltip;\n",
       "};\n",
       "mpl.toolbar_items = [[\"Home\", \"Reset original view\", \"fa fa-home icon-home\", \"home\"], [\"Back\", \"Back to previous view\", \"fa fa-arrow-left icon-arrow-left\", \"back\"], [\"Forward\", \"Forward to next view\", \"fa fa-arrow-right icon-arrow-right\", \"forward\"], [\"\", \"\", \"\", \"\"], [\"Pan\", \"Pan axes with left mouse, zoom with right\", \"fa fa-arrows icon-move\", \"pan\"], [\"Zoom\", \"Zoom to rectangle\", \"fa fa-square-o icon-check-empty\", \"zoom\"], [\"\", \"\", \"\", \"\"], [\"Download\", \"Download plot\", \"fa fa-floppy-o icon-save\", \"download\"]];\n",
       "\n",
       "mpl.extensions = [\"eps\", \"jpeg\", \"pdf\", \"png\", \"ps\", \"raw\", \"svg\", \"tif\"];\n",
       "\n",
       "mpl.default_extension = \"png\";var comm_websocket_adapter = function(comm) {\n",
       "    // Create a \"websocket\"-like object which calls the given IPython comm\n",
       "    // object with the appropriate methods. Currently this is a non binary\n",
       "    // socket, so there is still some room for performance tuning.\n",
       "    var ws = {};\n",
       "\n",
       "    ws.close = function() {\n",
       "        comm.close()\n",
       "    };\n",
       "    ws.send = function(m) {\n",
       "        //console.log('sending', m);\n",
       "        comm.send(m);\n",
       "    };\n",
       "    // Register the callback with on_msg.\n",
       "    comm.on_msg(function(msg) {\n",
       "        //console.log('receiving', msg['content']['data'], msg);\n",
       "        // Pass the mpl event to the overridden (by mpl) onmessage function.\n",
       "        ws.onmessage(msg['content']['data'])\n",
       "    });\n",
       "    return ws;\n",
       "}\n",
       "\n",
       "mpl.mpl_figure_comm = function(comm, msg) {\n",
       "    // This is the function which gets called when the mpl process\n",
       "    // starts-up an IPython Comm through the \"matplotlib\" channel.\n",
       "\n",
       "    var id = msg.content.data.id;\n",
       "    // Get hold of the div created by the display call when the Comm\n",
       "    // socket was opened in Python.\n",
       "    var element = $(\"#\" + id);\n",
       "    var ws_proxy = comm_websocket_adapter(comm)\n",
       "\n",
       "    function ondownload(figure, format) {\n",
       "        window.open(figure.imageObj.src);\n",
       "    }\n",
       "\n",
       "    var fig = new mpl.figure(id, ws_proxy,\n",
       "                           ondownload,\n",
       "                           element.get(0));\n",
       "\n",
       "    // Call onopen now - mpl needs it, as it is assuming we've passed it a real\n",
       "    // web socket which is closed, not our websocket->open comm proxy.\n",
       "    ws_proxy.onopen();\n",
       "\n",
       "    fig.parent_element = element.get(0);\n",
       "    fig.cell_info = mpl.find_output_cell(\"<div id='\" + id + \"'></div>\");\n",
       "    if (!fig.cell_info) {\n",
       "        console.error(\"Failed to find cell for figure\", id, fig);\n",
       "        return;\n",
       "    }\n",
       "\n",
       "    var output_index = fig.cell_info[2]\n",
       "    var cell = fig.cell_info[0];\n",
       "\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_close = function(fig, msg) {\n",
       "    var width = fig.canvas.width/mpl.ratio\n",
       "    fig.root.unbind('remove')\n",
       "\n",
       "    // Update the output cell to use the data from the current canvas.\n",
       "    fig.push_to_output();\n",
       "    var dataURL = fig.canvas.toDataURL();\n",
       "    // Re-enable the keyboard manager in IPython - without this line, in FF,\n",
       "    // the notebook keyboard shortcuts fail.\n",
       "    IPython.keyboard_manager.enable()\n",
       "    $(fig.parent_element).html('<img src=\"' + dataURL + '\" width=\"' + width + '\">');\n",
       "    fig.close_ws(fig, msg);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.close_ws = function(fig, msg){\n",
       "    fig.send_message('closing', msg);\n",
       "    // fig.ws.close()\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.push_to_output = function(remove_interactive) {\n",
       "    // Turn the data on the canvas into data in the output cell.\n",
       "    var width = this.canvas.width/mpl.ratio\n",
       "    var dataURL = this.canvas.toDataURL();\n",
       "    this.cell_info[1]['text/html'] = '<img src=\"' + dataURL + '\" width=\"' + width + '\">';\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.updated_canvas_event = function() {\n",
       "    // Tell IPython that the notebook contents must change.\n",
       "    IPython.notebook.set_dirty(true);\n",
       "    this.send_message(\"ack\", {});\n",
       "    var fig = this;\n",
       "    // Wait a second, then push the new image to the DOM so\n",
       "    // that it is saved nicely (might be nice to debounce this).\n",
       "    setTimeout(function () { fig.push_to_output() }, 1000);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._init_toolbar = function() {\n",
       "    var fig = this;\n",
       "\n",
       "    var nav_element = $('<div/>');\n",
       "    nav_element.attr('style', 'width: 100%');\n",
       "    this.root.append(nav_element);\n",
       "\n",
       "    // Define a callback function for later on.\n",
       "    function toolbar_event(event) {\n",
       "        return fig.toolbar_button_onclick(event['data']);\n",
       "    }\n",
       "    function toolbar_mouse_event(event) {\n",
       "        return fig.toolbar_button_onmouseover(event['data']);\n",
       "    }\n",
       "\n",
       "    for(var toolbar_ind in mpl.toolbar_items){\n",
       "        var name = mpl.toolbar_items[toolbar_ind][0];\n",
       "        var tooltip = mpl.toolbar_items[toolbar_ind][1];\n",
       "        var image = mpl.toolbar_items[toolbar_ind][2];\n",
       "        var method_name = mpl.toolbar_items[toolbar_ind][3];\n",
       "\n",
       "        if (!name) { continue; };\n",
       "\n",
       "        var button = $('<button class=\"btn btn-default\" href=\"#\" title=\"' + name + '\"><i class=\"fa ' + image + ' fa-lg\"></i></button>');\n",
       "        button.click(method_name, toolbar_event);\n",
       "        button.mouseover(tooltip, toolbar_mouse_event);\n",
       "        nav_element.append(button);\n",
       "    }\n",
       "\n",
       "    // Add the status bar.\n",
       "    var status_bar = $('<span class=\"mpl-message\" style=\"text-align:right; float: right;\"/>');\n",
       "    nav_element.append(status_bar);\n",
       "    this.message = status_bar[0];\n",
       "\n",
       "    // Add the close button to the window.\n",
       "    var buttongrp = $('<div class=\"btn-group inline pull-right\"></div>');\n",
       "    var button = $('<button class=\"btn btn-mini btn-primary\" href=\"#\" title=\"Stop Interaction\"><i class=\"fa fa-power-off icon-remove icon-large\"></i></button>');\n",
       "    button.click(function (evt) { fig.handle_close(fig, {}); } );\n",
       "    button.mouseover('Stop Interaction', toolbar_mouse_event);\n",
       "    buttongrp.append(button);\n",
       "    var titlebar = this.root.find($('.ui-dialog-titlebar'));\n",
       "    titlebar.prepend(buttongrp);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._root_extra_style = function(el){\n",
       "    var fig = this\n",
       "    el.on(\"remove\", function(){\n",
       "\tfig.close_ws(fig, {});\n",
       "    });\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._canvas_extra_style = function(el){\n",
       "    // this is important to make the div 'focusable\n",
       "    el.attr('tabindex', 0)\n",
       "    // reach out to IPython and tell the keyboard manager to turn it's self\n",
       "    // off when our div gets focus\n",
       "\n",
       "    // location in version 3\n",
       "    if (IPython.notebook.keyboard_manager) {\n",
       "        IPython.notebook.keyboard_manager.register_events(el);\n",
       "    }\n",
       "    else {\n",
       "        // location in version 2\n",
       "        IPython.keyboard_manager.register_events(el);\n",
       "    }\n",
       "\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._key_event_extra = function(event, name) {\n",
       "    var manager = IPython.notebook.keyboard_manager;\n",
       "    if (!manager)\n",
       "        manager = IPython.keyboard_manager;\n",
       "\n",
       "    // Check for shift+enter\n",
       "    if (event.shiftKey && event.which == 13) {\n",
       "        this.canvas_div.blur();\n",
       "        // select the cell after this one\n",
       "        var index = IPython.notebook.find_cell_index(this.cell_info[0]);\n",
       "        IPython.notebook.select(index + 1);\n",
       "    }\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_save = function(fig, msg) {\n",
       "    fig.ondownload(fig, null);\n",
       "}\n",
       "\n",
       "\n",
       "mpl.find_output_cell = function(html_output) {\n",
       "    // Return the cell and output element which can be found *uniquely* in the notebook.\n",
       "    // Note - this is a bit hacky, but it is done because the \"notebook_saving.Notebook\"\n",
       "    // IPython event is triggered only after the cells have been serialised, which for\n",
       "    // our purposes (turning an active figure into a static one), is too late.\n",
       "    var cells = IPython.notebook.get_cells();\n",
       "    var ncells = cells.length;\n",
       "    for (var i=0; i<ncells; i++) {\n",
       "        var cell = cells[i];\n",
       "        if (cell.cell_type === 'code'){\n",
       "            for (var j=0; j<cell.output_area.outputs.length; j++) {\n",
       "                var data = cell.output_area.outputs[j];\n",
       "                if (data.data) {\n",
       "                    // IPython >= 3 moved mimebundle to data attribute of output\n",
       "                    data = data.data;\n",
       "                }\n",
       "                if (data['text/html'] == html_output) {\n",
       "                    return [cell, data, j];\n",
       "                }\n",
       "            }\n",
       "        }\n",
       "    }\n",
       "}\n",
       "\n",
       "// Register the function which deals with the matplotlib target/channel.\n",
       "// The kernel may be null if the page has been refreshed.\n",
       "if (IPython.notebook.kernel != null) {\n",
       "    IPython.notebook.kernel.comm_manager.register_target('matplotlib', mpl.mpl_figure_comm);\n",
       "}\n"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<img src=\"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAbAAAAEgCAYAAADVKCZpAAAUHElEQVR4Xu3Y0Y5tN25F0ar//+gboF+SAEF6yS1eclPDr6ZEnrk2a1r+/fEPAggggAACHyTw+8GZjYwAAggggMAPgfkIEEAAAQQ+SYDAPhmboRFAAAEECMw3gAACCCDwSQIE9snYDI0AAgggQGC+AQQQQACBTxIgsE/GZmgEEEAAAQLzDSCAAAIIfJIAgX0yNkMjgAACCBCYbwABBBBA4JMECOyTsRkaAQQQQIDAfAMIIIAAAp8kQGCfjM3QCCCAAAIE5htAAAEEEPgkAQL7ZGyGRgABBBAgMN8AAggggMAnCRDYJ2MzNAIIIIAAgfkGEEAAAQQ+SYDAPhmboRFAAAEECMw3gAACCCDwSQIE9snYDI0AAgggQGC+AQQQQACBTxIgsE/GZmgEEEAAAQLzDSCAAAIIfJIAgX0yNkMjgAACCBCYbwABBBBA4JMECOyTsRkaAQQQQIDAfAMIIIAAAp8kQGCfjM3QCCCAAAIE5htAAAEEEPgkAQL7ZGyGRgABBBAgMN8AAggggMAnCRDYJ2MzNAIIIIAAgfkGEEAAAQQ+SYDAPhnb/x76z58/fxb8DD8BgdEEfn9//b0clpBAhgXyT8YhsH9CzRkEzggQ2Bmvv1FNYH+DcnEPAisG7HoEfn5+CGzeZ0Bg8zI5nojAjpE5gMAxAQI7RlZ+gMDKEdc3ILB6xjogQGDzvgECm5fJ8UQEdozMAQSOCRDYMbLyAwRWjri+AYHVM9YBAQKb9w0Q2LxMjicisGNkDiBwTIDAjpGVHyCwcsT1DQisnrEOCBDYvG+AwOZlcjwRgR0jcwCBYwIEdoys/ACBlSOub0Bg9Yx1QIDA5n0DBDYvk+OJCOwYmQMIHBMgsGNk5QcIrBxxfQMCq2esAwIENu8bILB5mRxPRGDHyBxA4JgAgR0jKz9AYOWI6xsQWD1jHRAgsHnfAIHNy+R4IgI7RuYAAscECOwYWfkBAitHXN+AwOoZ64AAgc37BghsXibHExHYMTIHEDgmQGDHyMoPEFg54voGBFbPWAcECGzeN0Bg8zI5nojAjpE5gMAxAQI7RlZ+gMDKEdc3ILB6xjogQGDzvgECm5fJ8UQEdozMAQSOCRDYMbLyAwRWjri+AYHVM9YBAQKb9w0Q2LxMjicisGNkDiBwTIDAjpGVHyCwcsT1DQisnrEOCBDYvG+AwOZlcjwRgR0jcwCBYwIEdoys/ACBlSOub0Bg9Yx1QIDA5n0DBDYvk+OJCOwYmQMIHBMgsGNk5QcIrBxxfQMCq2esAwIENu8bILB5mRxPRGDHyBxA4JgAgR0jKz9AYOWI6xt0Cuz399FP6E99rv9fhz+N2Btb//z50weewHq/+f+re+e3OI/GRycisIbg+v6O/uvHEtjfz5zA/j7zf9eRwP4doQ/8ewJrCInAGqD/eIG1UJ/blMDmZhNPRmAxqnuFBHaP5cFN/hfiAawHSglsQcgE1hAigTVA9wJrgT64KYENDicdjcBSUhfrCOwizPwqL7Cc1QuVBLYgZQJrCJHAGqB7gbVAH9yUwAaHk45GYCmpi3UEdhFmfpUXWM7qhUoCW5AygTWESGAN0L3AWqAPbkpgg8NJRyOwlNTFOgK7CDO/ygssZ/VCJYEtSJnAGkIksAboXmAt0Ac3JbDB4aSjEVhK6mIdgV2EmV/lBZazeqGSwBakTGANIRJYA3QvsBbog5sS2OBw0tEILCV1sY7ALsLMr/ICy1m9UElgC1ImsIYQCawBuhdYC/TBTQlscDjpaASWkrpYR2AXYeZXeYHlrF6oJLAFKRNYQ4gE1gDdC6wF+uCmBDY4nHQ0AktJXawjsIsw86u8wHJWL1QS2IKUCawhRAJrgO4F1gJ9cFMCGxxOOhqBpaQu1hHYRZj5VV5gOasXKglsQcoE1hAigTVA9wJrgT64KYENDicdjcBSUhfrCOwizPwqL7Cc1QuVBLYgZQJrCJHAGqB7gbVAH9yUwAaHk45GYCmpi3UEdhFmfpUXWM7qhUoCW5AygTWESGAN0L3AWqAPbkpgg8NJRyOwlNTFOgK7CDO/ygssZ/VCJYEtSJnAGkIksAboXmAt0Ac3JbDB4aSjEVhK6mIdgV2EmV/lBZazeqGSwBakTGANIRJYA3QvsBbog5sS2OBw0tEILCV1sY7ALsLMr/ICy1m9UElgC1ImsIYQCawBuhdYC/TBTQlscDjpaM8KrFMiNif9PK/WeYFdxfn5y6zh5yP813+Vtv0p//1t/ITafvXPz0/jz17wyf7jn9D4qf/8tn7s/xjZ6oPWcEG8BNYQos1pgO5/IbZAH9zUGg4OJx2NwFJSF+tszkWY+VVeYDmrFyqt4YKUCawhRJvTAN0LrAX64KbWcHA46WgElpK6WGdzLsLMr/ICy1m9UGkNF6RMYA0h2pwG6F5gLdAHN7WGg8NJRyOwlNTFOptzEWZ+lRdYzuqFSmu4IGUCawjR5jRA9wJrgT64qTUcHE46GoGlpC7W2ZyLMPOrvMByVi9UWsMFKRNYQ4g2pwG6F1gL9MFNreHgcNLRCCwldbHO5lyEmV/lBZazeqHSGi5ImcAaQrQ5DdC9wFqgD25qDQeHk45GYCmpi3U25yLM/CovsJzVC5XWcEHKBNYQos1pgO4F1gJ9cFNrODicdDQCS0ldrLM5F2HmV3mB5axeqLSGC1ImsIYQbU4DdC+wFuiDm1rDweGkoxFYSupinc25CDO/ygssZ/VCpTVckDKBNYRocxqge4G1QB/c1BoODicdjcBSUhfrbM5FmPlVXmA5qxcqreGClAmsIUSb0wDdC6wF+uCm1nBwOOloBJaSulhncy7CzK/yAstZvVBpDRekTGANIdqcBuheYC3QBze1hoPDSUcjsJTUxTqbcxFmfpUXWM7qhUpruCBlAmsI0eY0QPcCa4E+uKk1HBxOOhqBpaQu1tmcizDzq7zAclYvVFrDBSkTWEOINqcBuhdYC/TBTa3h4HDS0QgsJXWxzuZchJlf5QWWs3qh0houSJnAGkK0OQ3QvcBaoA9uag0Hh5OORmApqYt1NucizPwqL7Cc1QuV1nBBygTWEKLNaYDuBdYCfXBTazg4nHS0ZwWWAlK3hoAX2Joor/wQAruCsfcSAuvlr/vfI0Bgf4/1FzoR2BdS+jczEtiCEP2EiACBRZieKSKwBVET2IIQ/YSIAIFFmJ4pIrAFURPYghD9hIgAgUWYnikisAVRE9iCEP2EiACBRZieKSKwBVET2IIQ/YSIAIFFmJ4pIrAFURPYghD9hIgAgUWYnikisAVRE9iCEP2EiACBRZieKSKwBVET2IIQ/YSIAIFFmJ4pIrAFURPYghD9hIgAgUWYnikisAVRE9iCEP2EiACBRZieKSKwBVET2IIQ/YSIAIFFmJ4pIrAFURPYghD9hIgAgUWYnikisAVRE9iCEP2EiACBRZieKSKwBVET2IIQ/YSIAIFFmJ4pIrAFURPYghD9hIgAgUWYnikisAVRE9iCEP2EiACBRZieKSKwBVET2IIQ/YSIAIFFmJ4pIrAFURPYghD9hIgAgUWYnikisAVRE9iCEP2EiACBRZieKSKwBVET2IIQ/YSIAIFFmJ4pIrAFURPYghD9hIgAgUWYnikisAVRE9iCEP2EiACBRZieKSKwBVET2IIQ/YSIAIFFmJ4pIrAFURPYghD9hIgAgUWYnikisAVRE9iCEP2EiACBRZieKSKwBVET2IIQ/YSIAIFFmJ4pIrAFURPYghD9hIgAgUWYnikisAVRE9iCEP2EiACBRZieKSKwBVET2IIQ/YSIAIFFmJ4pIrAFURPYghD9hIgAgUWYnikisAVRvyuwP43pWZ0O+ATWQX1uT1s4N5t4MgKLUV0stDoXYcZXEViM6olCW7ggZgLrCNHqdFAnsA7qc3vawrnZxJMRWIzqYqHVuQgzvorAYlRPFNrCBTETWEeIVqeDOoF1UJ/b0xbOzSaejMBiVBcLrc5FmPFVBBajeqLQFi6ImcA6QrQ6HdQJrIP63J62cG428WQEFqO6WGh1LsKMryKwGNUThbZwQcwE1hGi1emgTmAd1Of2tIVzs4knI7AY1cVCq3MRZnwVgcWonii0hQtiJrCOEK1OB3UC66A+t6ctnJtNPBmBxaguFlqdizDjqwgsRvVEoS1cEDOBdYRodTqoE1gH9bk9beHcbOLJCCxGdbHQ6lyEGV9FYDGqJwpt4YKYCawjRKvTQZ3AOqjP7WkL52YTT0ZgMaqLhVbnIsz4KgKLUT1RaAsXxExgHSFanQ7qBNZBfW5PWzg3m3gyAotRXSy0OhdhxlcRWIzqiUJbuCBmAusI0ep0UCewDupze9rCudnEkxFYjOpiodW5CDO+isBiVE8U2sIFMRNYR4hWp4M6gXVQn9vTFs7NJp6MwGJUFwutzkWY8VUEFqN6otAWLoiZwDpCtDod1Amsg/rcnrZwbjbxZAQWo7pYaHUuwoyvIrAY1ROFtnBBzATWEaLV6aBOYB3U5/a0hXOziScjsBjVxUKrcxFmfBWBxaieKLSFC2ImsI4QrU4HdQLroD63py2cm008GYHFqC4WWp2LMOOrCCxG9UShLVwQM4F1hGh1OqgTWAf1uT1t4dxs4skILEZ1sdDqXIQZX0VgMaonCm3hgpgJrCNEq9NBncA6qM/taQvnZhNP1imwn9++T6iv88/Pz584nn2FjeAJbN/n9J/8osZP8T8Z29n/SYDAGr4HAmuA/vNDYC3YxzYlsLHR5IMRWM7qWiWBXUN5chGBndDaX0tgCzImsIYQCawBuhdYC/TBTQlscDjpaASWkrpYR2AXYeZXeYHlrF6oJLAFKRNYQ4gE1gDdC6wF+uCmBDY4nHQ0AktJXawjsIsw86u8wHJWL1QS2IKUCawhRAJrgO4F1gJ9cFMCGxxOOhqBpaQu1hHYRZj5VV5gOasXKglsQcoE1hAigTVA9wJrgT64KYENDicdjcBSUhfrCOwizPwqL7Cc1QuVBLYgZQJrCJHAGqB7gbVAH9yUwAaHk45GYCmpi3UEdhFmfpUXWM7qhUoCW5AygTWESGAN0L3AWqAPbkpgg8NJRyOwlNTFOgK7CDO/ygssZ/VCJYEtSJnAGkIksAboXmAt0Ac3JbDB4aSjEVhK6mIdgV2EmV/lBZazeqGSwBakTGANIRJYA3QvsBbog5sS2OBw0tEILCV1sY7ALsLMr/ICy1m9UElgC1ImsIYQCawBuhdYC/TBTQlscDjpaASWkrpYR2AXYeZXeYHlrF6oJLAFKRNYQ4gE1gDdC6wF+uCmBDY4nHQ0AktJXawjsIsw86u8wHJWL1QS2IKUCawhRAJrgO4F1gJ9cFMCGxxOOhqBpaQu1hHYRZj5VV5gOasXKglsQcoE1hAigTVA9wJrgT64KYENDicdjcBSUhfrCOwizPwqL7Cc1QuVBLYgZQJrCJHAGqB7gbVAH9yUwAaHk45GYCmpi3UEdhFmfpUXWM7qhUoCW5AygTWESGAN0L3AWqAPbkpgg8NJRyOwlNTFOgK7CDO/ygssZ/VCJYEtSLlVYAv4+QkIJAR+f3/9vUxA/cUagfxF2FWtCKyKrHsR+G8CBDbvayCweZkcT0Rgx8gcQOCYAIEdIys/QGDliOsbEFg9Yx0QILB53wCBzcvkeCICO0bmAALHBAjsGFn5AQIrR1zfgMDqGeuAAIHN+wYIbF4mxxMR2DEyBxA4JkBgx8jKDxBYOeL6BgRWz1gHBAhs3jdAYPMyOZ6IwI6ROYDAMQECO0ZWfoDAyhHXNyCwesY6IEBg874BApuXyfFEBHaMzAEEjgkQ2DGy8gMEVo64vgGB1TPWAQECm/cNENi8TI4nIrBjZA4gcEyAwI6RlR8gsHLE9Q0IrJ6xDggQ2LxvgMDmZXI8EYEdI3MAgWMCBHaMrPwAgZUjrm9AYPWMdUCAwOZ9AwQ2L5PjiQjsGJkDCBwTILBjZOUHCKwccX0DAqtnrAMCBDbvGyCweZkcT0Rgx8gcQOCYAIEdIys/QGDliOsbEFg9Yx0QILB53wCBzcvkeCICO0bmAALHBAjsGFn5AQIrR1zfgMDqGeuAAIHN+wYIbF4mxxMR2DEyBxA4JkBgx8jKDxBYOeL6BgRWz1gHBAhs3jdAYPMyOZ6IwI6ROYDAMQECO0ZWfoDAyhHXNyCwesY6IEBg874BApuXyfFEBHaMzAEEjgkQ2DGy8gMEVo64vgGB1TPWAQECm/cNENi8TI4nIrBjZA4gcEyAwI6RlR8gsHLE9Q0IrJ6xDggQ2LxvgMDmZXI8EYEdI3MAgWMCBHaMrPwAgZUj1gABBBBAoIIAgVVQdScCCCCAQDkBAitHrAECCCCAQAUBAqug6k4EEEAAgXICBFaOWAMEEEAAgQoCBFZB1Z0IIIAAAuUECKwcsQYIIIAAAhUECKyCqjsRQAABBMoJEFg5Yg0QQAABBCoIEFgFVXcigAACCJQTILByxBoggAACCFQQILAKqu5EAAEEECgnQGDliDVAAAEEEKggQGAVVN2JAAIIIFBOgMDKEWuAAAIIIFBBgMAqqLoTAQQQQKCcAIGVI9YAAQQQQKCCAIFVUHUnAggggEA5AQIrR6wBAggggEAFAQKroOpOBBBAAIFyAgRWjlgDBBBAAIEKAgRWQdWdCCCAAALlBAisHLEGCCCAAAIVBAisgqo7EUAAAQTKCRBYOWINEEAAAQQqCBBYBVV3IoAAAgiUEyCwcsQaIIAAAghUECCwCqruRAABBBAoJ0Bg5Yg1QAABBBCoIEBgFVTdiQACCCBQToDAyhFrgAACCCBQQYDAKqi6EwEEEECgnACBlSPWAAEEEECgggCBVVB1JwIIIIBAOQECK0esAQIIIIBABQECq6DqTgQQQACBcgL/BVSb1GyovEeKAAAAAElFTkSuQmCC\" width=\"432\">"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from gridworld import gameEnv\n",
    "env = gameEnv(partial=False, size=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise**: Let's play a game manually to understand how it works. Fill the actions_list with step in order to win points according to the intialised environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "/* Put everything inside the global mpl namespace */\n",
       "window.mpl = {};\n",
       "\n",
       "\n",
       "mpl.get_websocket_type = function() {\n",
       "    if (typeof(WebSocket) !== 'undefined') {\n",
       "        return WebSocket;\n",
       "    } else if (typeof(MozWebSocket) !== 'undefined') {\n",
       "        return MozWebSocket;\n",
       "    } else {\n",
       "        alert('Your browser does not have WebSocket support. ' +\n",
       "              'Please try Chrome, Safari or Firefox ≥ 6. ' +\n",
       "              'Firefox 4 and 5 are also supported but you ' +\n",
       "              'have to enable WebSockets in about:config.');\n",
       "    };\n",
       "}\n",
       "\n",
       "mpl.figure = function(figure_id, websocket, ondownload, parent_element) {\n",
       "    this.id = figure_id;\n",
       "\n",
       "    this.ws = websocket;\n",
       "\n",
       "    this.supports_binary = (this.ws.binaryType != undefined);\n",
       "\n",
       "    if (!this.supports_binary) {\n",
       "        var warnings = document.getElementById(\"mpl-warnings\");\n",
       "        if (warnings) {\n",
       "            warnings.style.display = 'block';\n",
       "            warnings.textContent = (\n",
       "                \"This browser does not support binary websocket messages. \" +\n",
       "                    \"Performance may be slow.\");\n",
       "        }\n",
       "    }\n",
       "\n",
       "    this.imageObj = new Image();\n",
       "\n",
       "    this.context = undefined;\n",
       "    this.message = undefined;\n",
       "    this.canvas = undefined;\n",
       "    this.rubberband_canvas = undefined;\n",
       "    this.rubberband_context = undefined;\n",
       "    this.format_dropdown = undefined;\n",
       "\n",
       "    this.image_mode = 'full';\n",
       "\n",
       "    this.root = $('<div/>');\n",
       "    this._root_extra_style(this.root)\n",
       "    this.root.attr('style', 'display: inline-block');\n",
       "\n",
       "    $(parent_element).append(this.root);\n",
       "\n",
       "    this._init_header(this);\n",
       "    this._init_canvas(this);\n",
       "    this._init_toolbar(this);\n",
       "\n",
       "    var fig = this;\n",
       "\n",
       "    this.waiting = false;\n",
       "\n",
       "    this.ws.onopen =  function () {\n",
       "            fig.send_message(\"supports_binary\", {value: fig.supports_binary});\n",
       "            fig.send_message(\"send_image_mode\", {});\n",
       "            if (mpl.ratio != 1) {\n",
       "                fig.send_message(\"set_dpi_ratio\", {'dpi_ratio': mpl.ratio});\n",
       "            }\n",
       "            fig.send_message(\"refresh\", {});\n",
       "        }\n",
       "\n",
       "    this.imageObj.onload = function() {\n",
       "            if (fig.image_mode == 'full') {\n",
       "                // Full images could contain transparency (where diff images\n",
       "                // almost always do), so we need to clear the canvas so that\n",
       "                // there is no ghosting.\n",
       "                fig.context.clearRect(0, 0, fig.canvas.width, fig.canvas.height);\n",
       "            }\n",
       "            fig.context.drawImage(fig.imageObj, 0, 0);\n",
       "        };\n",
       "\n",
       "    this.imageObj.onunload = function() {\n",
       "        fig.ws.close();\n",
       "    }\n",
       "\n",
       "    this.ws.onmessage = this._make_on_message_function(this);\n",
       "\n",
       "    this.ondownload = ondownload;\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._init_header = function() {\n",
       "    var titlebar = $(\n",
       "        '<div class=\"ui-dialog-titlebar ui-widget-header ui-corner-all ' +\n",
       "        'ui-helper-clearfix\"/>');\n",
       "    var titletext = $(\n",
       "        '<div class=\"ui-dialog-title\" style=\"width: 100%; ' +\n",
       "        'text-align: center; padding: 3px;\"/>');\n",
       "    titlebar.append(titletext)\n",
       "    this.root.append(titlebar);\n",
       "    this.header = titletext[0];\n",
       "}\n",
       "\n",
       "\n",
       "\n",
       "mpl.figure.prototype._canvas_extra_style = function(canvas_div) {\n",
       "\n",
       "}\n",
       "\n",
       "\n",
       "mpl.figure.prototype._root_extra_style = function(canvas_div) {\n",
       "\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._init_canvas = function() {\n",
       "    var fig = this;\n",
       "\n",
       "    var canvas_div = $('<div/>');\n",
       "\n",
       "    canvas_div.attr('style', 'position: relative; clear: both; outline: 0');\n",
       "\n",
       "    function canvas_keyboard_event(event) {\n",
       "        return fig.key_event(event, event['data']);\n",
       "    }\n",
       "\n",
       "    canvas_div.keydown('key_press', canvas_keyboard_event);\n",
       "    canvas_div.keyup('key_release', canvas_keyboard_event);\n",
       "    this.canvas_div = canvas_div\n",
       "    this._canvas_extra_style(canvas_div)\n",
       "    this.root.append(canvas_div);\n",
       "\n",
       "    var canvas = $('<canvas/>');\n",
       "    canvas.addClass('mpl-canvas');\n",
       "    canvas.attr('style', \"left: 0; top: 0; z-index: 0; outline: 0\")\n",
       "\n",
       "    this.canvas = canvas[0];\n",
       "    this.context = canvas[0].getContext(\"2d\");\n",
       "\n",
       "    var backingStore = this.context.backingStorePixelRatio ||\n",
       "\tthis.context.webkitBackingStorePixelRatio ||\n",
       "\tthis.context.mozBackingStorePixelRatio ||\n",
       "\tthis.context.msBackingStorePixelRatio ||\n",
       "\tthis.context.oBackingStorePixelRatio ||\n",
       "\tthis.context.backingStorePixelRatio || 1;\n",
       "\n",
       "    mpl.ratio = (window.devicePixelRatio || 1) / backingStore;\n",
       "\n",
       "    var rubberband = $('<canvas/>');\n",
       "    rubberband.attr('style', \"position: absolute; left: 0; top: 0; z-index: 1;\")\n",
       "\n",
       "    var pass_mouse_events = true;\n",
       "\n",
       "    canvas_div.resizable({\n",
       "        start: function(event, ui) {\n",
       "            pass_mouse_events = false;\n",
       "        },\n",
       "        resize: function(event, ui) {\n",
       "            fig.request_resize(ui.size.width, ui.size.height);\n",
       "        },\n",
       "        stop: function(event, ui) {\n",
       "            pass_mouse_events = true;\n",
       "            fig.request_resize(ui.size.width, ui.size.height);\n",
       "        },\n",
       "    });\n",
       "\n",
       "    function mouse_event_fn(event) {\n",
       "        if (pass_mouse_events)\n",
       "            return fig.mouse_event(event, event['data']);\n",
       "    }\n",
       "\n",
       "    rubberband.mousedown('button_press', mouse_event_fn);\n",
       "    rubberband.mouseup('button_release', mouse_event_fn);\n",
       "    // Throttle sequential mouse events to 1 every 20ms.\n",
       "    rubberband.mousemove('motion_notify', mouse_event_fn);\n",
       "\n",
       "    rubberband.mouseenter('figure_enter', mouse_event_fn);\n",
       "    rubberband.mouseleave('figure_leave', mouse_event_fn);\n",
       "\n",
       "    canvas_div.on(\"wheel\", function (event) {\n",
       "        event = event.originalEvent;\n",
       "        event['data'] = 'scroll'\n",
       "        if (event.deltaY < 0) {\n",
       "            event.step = 1;\n",
       "        } else {\n",
       "            event.step = -1;\n",
       "        }\n",
       "        mouse_event_fn(event);\n",
       "    });\n",
       "\n",
       "    canvas_div.append(canvas);\n",
       "    canvas_div.append(rubberband);\n",
       "\n",
       "    this.rubberband = rubberband;\n",
       "    this.rubberband_canvas = rubberband[0];\n",
       "    this.rubberband_context = rubberband[0].getContext(\"2d\");\n",
       "    this.rubberband_context.strokeStyle = \"#000000\";\n",
       "\n",
       "    this._resize_canvas = function(width, height) {\n",
       "        // Keep the size of the canvas, canvas container, and rubber band\n",
       "        // canvas in synch.\n",
       "        canvas_div.css('width', width)\n",
       "        canvas_div.css('height', height)\n",
       "\n",
       "        canvas.attr('width', width * mpl.ratio);\n",
       "        canvas.attr('height', height * mpl.ratio);\n",
       "        canvas.attr('style', 'width: ' + width + 'px; height: ' + height + 'px;');\n",
       "\n",
       "        rubberband.attr('width', width);\n",
       "        rubberband.attr('height', height);\n",
       "    }\n",
       "\n",
       "    // Set the figure to an initial 600x600px, this will subsequently be updated\n",
       "    // upon first draw.\n",
       "    this._resize_canvas(600, 600);\n",
       "\n",
       "    // Disable right mouse context menu.\n",
       "    $(this.rubberband_canvas).bind(\"contextmenu\",function(e){\n",
       "        return false;\n",
       "    });\n",
       "\n",
       "    function set_focus () {\n",
       "        canvas.focus();\n",
       "        canvas_div.focus();\n",
       "    }\n",
       "\n",
       "    window.setTimeout(set_focus, 100);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._init_toolbar = function() {\n",
       "    var fig = this;\n",
       "\n",
       "    var nav_element = $('<div/>');\n",
       "    nav_element.attr('style', 'width: 100%');\n",
       "    this.root.append(nav_element);\n",
       "\n",
       "    // Define a callback function for later on.\n",
       "    function toolbar_event(event) {\n",
       "        return fig.toolbar_button_onclick(event['data']);\n",
       "    }\n",
       "    function toolbar_mouse_event(event) {\n",
       "        return fig.toolbar_button_onmouseover(event['data']);\n",
       "    }\n",
       "\n",
       "    for(var toolbar_ind in mpl.toolbar_items) {\n",
       "        var name = mpl.toolbar_items[toolbar_ind][0];\n",
       "        var tooltip = mpl.toolbar_items[toolbar_ind][1];\n",
       "        var image = mpl.toolbar_items[toolbar_ind][2];\n",
       "        var method_name = mpl.toolbar_items[toolbar_ind][3];\n",
       "\n",
       "        if (!name) {\n",
       "            // put a spacer in here.\n",
       "            continue;\n",
       "        }\n",
       "        var button = $('<button/>');\n",
       "        button.addClass('ui-button ui-widget ui-state-default ui-corner-all ' +\n",
       "                        'ui-button-icon-only');\n",
       "        button.attr('role', 'button');\n",
       "        button.attr('aria-disabled', 'false');\n",
       "        button.click(method_name, toolbar_event);\n",
       "        button.mouseover(tooltip, toolbar_mouse_event);\n",
       "\n",
       "        var icon_img = $('<span/>');\n",
       "        icon_img.addClass('ui-button-icon-primary ui-icon');\n",
       "        icon_img.addClass(image);\n",
       "        icon_img.addClass('ui-corner-all');\n",
       "\n",
       "        var tooltip_span = $('<span/>');\n",
       "        tooltip_span.addClass('ui-button-text');\n",
       "        tooltip_span.html(tooltip);\n",
       "\n",
       "        button.append(icon_img);\n",
       "        button.append(tooltip_span);\n",
       "\n",
       "        nav_element.append(button);\n",
       "    }\n",
       "\n",
       "    var fmt_picker_span = $('<span/>');\n",
       "\n",
       "    var fmt_picker = $('<select/>');\n",
       "    fmt_picker.addClass('mpl-toolbar-option ui-widget ui-widget-content');\n",
       "    fmt_picker_span.append(fmt_picker);\n",
       "    nav_element.append(fmt_picker_span);\n",
       "    this.format_dropdown = fmt_picker[0];\n",
       "\n",
       "    for (var ind in mpl.extensions) {\n",
       "        var fmt = mpl.extensions[ind];\n",
       "        var option = $(\n",
       "            '<option/>', {selected: fmt === mpl.default_extension}).html(fmt);\n",
       "        fmt_picker.append(option);\n",
       "    }\n",
       "\n",
       "    // Add hover states to the ui-buttons\n",
       "    $( \".ui-button\" ).hover(\n",
       "        function() { $(this).addClass(\"ui-state-hover\");},\n",
       "        function() { $(this).removeClass(\"ui-state-hover\");}\n",
       "    );\n",
       "\n",
       "    var status_bar = $('<span class=\"mpl-message\"/>');\n",
       "    nav_element.append(status_bar);\n",
       "    this.message = status_bar[0];\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.request_resize = function(x_pixels, y_pixels) {\n",
       "    // Request matplotlib to resize the figure. Matplotlib will then trigger a resize in the client,\n",
       "    // which will in turn request a refresh of the image.\n",
       "    this.send_message('resize', {'width': x_pixels, 'height': y_pixels});\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.send_message = function(type, properties) {\n",
       "    properties['type'] = type;\n",
       "    properties['figure_id'] = this.id;\n",
       "    this.ws.send(JSON.stringify(properties));\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.send_draw_message = function() {\n",
       "    if (!this.waiting) {\n",
       "        this.waiting = true;\n",
       "        this.ws.send(JSON.stringify({type: \"draw\", figure_id: this.id}));\n",
       "    }\n",
       "}\n",
       "\n",
       "\n",
       "mpl.figure.prototype.handle_save = function(fig, msg) {\n",
       "    var format_dropdown = fig.format_dropdown;\n",
       "    var format = format_dropdown.options[format_dropdown.selectedIndex].value;\n",
       "    fig.ondownload(fig, format);\n",
       "}\n",
       "\n",
       "\n",
       "mpl.figure.prototype.handle_resize = function(fig, msg) {\n",
       "    var size = msg['size'];\n",
       "    if (size[0] != fig.canvas.width || size[1] != fig.canvas.height) {\n",
       "        fig._resize_canvas(size[0], size[1]);\n",
       "        fig.send_message(\"refresh\", {});\n",
       "    };\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_rubberband = function(fig, msg) {\n",
       "    var x0 = msg['x0'] / mpl.ratio;\n",
       "    var y0 = (fig.canvas.height - msg['y0']) / mpl.ratio;\n",
       "    var x1 = msg['x1'] / mpl.ratio;\n",
       "    var y1 = (fig.canvas.height - msg['y1']) / mpl.ratio;\n",
       "    x0 = Math.floor(x0) + 0.5;\n",
       "    y0 = Math.floor(y0) + 0.5;\n",
       "    x1 = Math.floor(x1) + 0.5;\n",
       "    y1 = Math.floor(y1) + 0.5;\n",
       "    var min_x = Math.min(x0, x1);\n",
       "    var min_y = Math.min(y0, y1);\n",
       "    var width = Math.abs(x1 - x0);\n",
       "    var height = Math.abs(y1 - y0);\n",
       "\n",
       "    fig.rubberband_context.clearRect(\n",
       "        0, 0, fig.canvas.width / mpl.ratio, fig.canvas.height / mpl.ratio);\n",
       "\n",
       "    fig.rubberband_context.strokeRect(min_x, min_y, width, height);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_figure_label = function(fig, msg) {\n",
       "    // Updates the figure title.\n",
       "    fig.header.textContent = msg['label'];\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_cursor = function(fig, msg) {\n",
       "    var cursor = msg['cursor'];\n",
       "    switch(cursor)\n",
       "    {\n",
       "    case 0:\n",
       "        cursor = 'pointer';\n",
       "        break;\n",
       "    case 1:\n",
       "        cursor = 'default';\n",
       "        break;\n",
       "    case 2:\n",
       "        cursor = 'crosshair';\n",
       "        break;\n",
       "    case 3:\n",
       "        cursor = 'move';\n",
       "        break;\n",
       "    }\n",
       "    fig.rubberband_canvas.style.cursor = cursor;\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_message = function(fig, msg) {\n",
       "    fig.message.textContent = msg['message'];\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_draw = function(fig, msg) {\n",
       "    // Request the server to send over a new figure.\n",
       "    fig.send_draw_message();\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_image_mode = function(fig, msg) {\n",
       "    fig.image_mode = msg['mode'];\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.updated_canvas_event = function() {\n",
       "    // Called whenever the canvas gets updated.\n",
       "    this.send_message(\"ack\", {});\n",
       "}\n",
       "\n",
       "// A function to construct a web socket function for onmessage handling.\n",
       "// Called in the figure constructor.\n",
       "mpl.figure.prototype._make_on_message_function = function(fig) {\n",
       "    return function socket_on_message(evt) {\n",
       "        if (evt.data instanceof Blob) {\n",
       "            /* FIXME: We get \"Resource interpreted as Image but\n",
       "             * transferred with MIME type text/plain:\" errors on\n",
       "             * Chrome.  But how to set the MIME type?  It doesn't seem\n",
       "             * to be part of the websocket stream */\n",
       "            evt.data.type = \"image/png\";\n",
       "\n",
       "            /* Free the memory for the previous frames */\n",
       "            if (fig.imageObj.src) {\n",
       "                (window.URL || window.webkitURL).revokeObjectURL(\n",
       "                    fig.imageObj.src);\n",
       "            }\n",
       "\n",
       "            fig.imageObj.src = (window.URL || window.webkitURL).createObjectURL(\n",
       "                evt.data);\n",
       "            fig.updated_canvas_event();\n",
       "            fig.waiting = false;\n",
       "            return;\n",
       "        }\n",
       "        else if (typeof evt.data === 'string' && evt.data.slice(0, 21) == \"data:image/png;base64\") {\n",
       "            fig.imageObj.src = evt.data;\n",
       "            fig.updated_canvas_event();\n",
       "            fig.waiting = false;\n",
       "            return;\n",
       "        }\n",
       "\n",
       "        var msg = JSON.parse(evt.data);\n",
       "        var msg_type = msg['type'];\n",
       "\n",
       "        // Call the  \"handle_{type}\" callback, which takes\n",
       "        // the figure and JSON message as its only arguments.\n",
       "        try {\n",
       "            var callback = fig[\"handle_\" + msg_type];\n",
       "        } catch (e) {\n",
       "            console.log(\"No handler for the '\" + msg_type + \"' message type: \", msg);\n",
       "            return;\n",
       "        }\n",
       "\n",
       "        if (callback) {\n",
       "            try {\n",
       "                // console.log(\"Handling '\" + msg_type + \"' message: \", msg);\n",
       "                callback(fig, msg);\n",
       "            } catch (e) {\n",
       "                console.log(\"Exception inside the 'handler_\" + msg_type + \"' callback:\", e, e.stack, msg);\n",
       "            }\n",
       "        }\n",
       "    };\n",
       "}\n",
       "\n",
       "// from http://stackoverflow.com/questions/1114465/getting-mouse-location-in-canvas\n",
       "mpl.findpos = function(e) {\n",
       "    //this section is from http://www.quirksmode.org/js/events_properties.html\n",
       "    var targ;\n",
       "    if (!e)\n",
       "        e = window.event;\n",
       "    if (e.target)\n",
       "        targ = e.target;\n",
       "    else if (e.srcElement)\n",
       "        targ = e.srcElement;\n",
       "    if (targ.nodeType == 3) // defeat Safari bug\n",
       "        targ = targ.parentNode;\n",
       "\n",
       "    // jQuery normalizes the pageX and pageY\n",
       "    // pageX,Y are the mouse positions relative to the document\n",
       "    // offset() returns the position of the element relative to the document\n",
       "    var x = e.pageX - $(targ).offset().left;\n",
       "    var y = e.pageY - $(targ).offset().top;\n",
       "\n",
       "    return {\"x\": x, \"y\": y};\n",
       "};\n",
       "\n",
       "/*\n",
       " * return a copy of an object with only non-object keys\n",
       " * we need this to avoid circular references\n",
       " * http://stackoverflow.com/a/24161582/3208463\n",
       " */\n",
       "function simpleKeys (original) {\n",
       "  return Object.keys(original).reduce(function (obj, key) {\n",
       "    if (typeof original[key] !== 'object')\n",
       "        obj[key] = original[key]\n",
       "    return obj;\n",
       "  }, {});\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.mouse_event = function(event, name) {\n",
       "    var canvas_pos = mpl.findpos(event)\n",
       "\n",
       "    if (name === 'button_press')\n",
       "    {\n",
       "        this.canvas.focus();\n",
       "        this.canvas_div.focus();\n",
       "    }\n",
       "\n",
       "    var x = canvas_pos.x * mpl.ratio;\n",
       "    var y = canvas_pos.y * mpl.ratio;\n",
       "\n",
       "    this.send_message(name, {x: x, y: y, button: event.button,\n",
       "                             step: event.step,\n",
       "                             guiEvent: simpleKeys(event)});\n",
       "\n",
       "    /* This prevents the web browser from automatically changing to\n",
       "     * the text insertion cursor when the button is pressed.  We want\n",
       "     * to control all of the cursor setting manually through the\n",
       "     * 'cursor' event from matplotlib */\n",
       "    event.preventDefault();\n",
       "    return false;\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._key_event_extra = function(event, name) {\n",
       "    // Handle any extra behaviour associated with a key event\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.key_event = function(event, name) {\n",
       "\n",
       "    // Prevent repeat events\n",
       "    if (name == 'key_press')\n",
       "    {\n",
       "        if (event.which === this._key)\n",
       "            return;\n",
       "        else\n",
       "            this._key = event.which;\n",
       "    }\n",
       "    if (name == 'key_release')\n",
       "        this._key = null;\n",
       "\n",
       "    var value = '';\n",
       "    if (event.ctrlKey && event.which != 17)\n",
       "        value += \"ctrl+\";\n",
       "    if (event.altKey && event.which != 18)\n",
       "        value += \"alt+\";\n",
       "    if (event.shiftKey && event.which != 16)\n",
       "        value += \"shift+\";\n",
       "\n",
       "    value += 'k';\n",
       "    value += event.which.toString();\n",
       "\n",
       "    this._key_event_extra(event, name);\n",
       "\n",
       "    this.send_message(name, {key: value,\n",
       "                             guiEvent: simpleKeys(event)});\n",
       "    return false;\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.toolbar_button_onclick = function(name) {\n",
       "    if (name == 'download') {\n",
       "        this.handle_save(this, null);\n",
       "    } else {\n",
       "        this.send_message(\"toolbar_button\", {name: name});\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.toolbar_button_onmouseover = function(tooltip) {\n",
       "    this.message.textContent = tooltip;\n",
       "};\n",
       "mpl.toolbar_items = [[\"Home\", \"Reset original view\", \"fa fa-home icon-home\", \"home\"], [\"Back\", \"Back to previous view\", \"fa fa-arrow-left icon-arrow-left\", \"back\"], [\"Forward\", \"Forward to next view\", \"fa fa-arrow-right icon-arrow-right\", \"forward\"], [\"\", \"\", \"\", \"\"], [\"Pan\", \"Pan axes with left mouse, zoom with right\", \"fa fa-arrows icon-move\", \"pan\"], [\"Zoom\", \"Zoom to rectangle\", \"fa fa-square-o icon-check-empty\", \"zoom\"], [\"\", \"\", \"\", \"\"], [\"Download\", \"Download plot\", \"fa fa-floppy-o icon-save\", \"download\"]];\n",
       "\n",
       "mpl.extensions = [\"eps\", \"jpeg\", \"pdf\", \"png\", \"ps\", \"raw\", \"svg\", \"tif\"];\n",
       "\n",
       "mpl.default_extension = \"png\";var comm_websocket_adapter = function(comm) {\n",
       "    // Create a \"websocket\"-like object which calls the given IPython comm\n",
       "    // object with the appropriate methods. Currently this is a non binary\n",
       "    // socket, so there is still some room for performance tuning.\n",
       "    var ws = {};\n",
       "\n",
       "    ws.close = function() {\n",
       "        comm.close()\n",
       "    };\n",
       "    ws.send = function(m) {\n",
       "        //console.log('sending', m);\n",
       "        comm.send(m);\n",
       "    };\n",
       "    // Register the callback with on_msg.\n",
       "    comm.on_msg(function(msg) {\n",
       "        //console.log('receiving', msg['content']['data'], msg);\n",
       "        // Pass the mpl event to the overridden (by mpl) onmessage function.\n",
       "        ws.onmessage(msg['content']['data'])\n",
       "    });\n",
       "    return ws;\n",
       "}\n",
       "\n",
       "mpl.mpl_figure_comm = function(comm, msg) {\n",
       "    // This is the function which gets called when the mpl process\n",
       "    // starts-up an IPython Comm through the \"matplotlib\" channel.\n",
       "\n",
       "    var id = msg.content.data.id;\n",
       "    // Get hold of the div created by the display call when the Comm\n",
       "    // socket was opened in Python.\n",
       "    var element = $(\"#\" + id);\n",
       "    var ws_proxy = comm_websocket_adapter(comm)\n",
       "\n",
       "    function ondownload(figure, format) {\n",
       "        window.open(figure.imageObj.src);\n",
       "    }\n",
       "\n",
       "    var fig = new mpl.figure(id, ws_proxy,\n",
       "                           ondownload,\n",
       "                           element.get(0));\n",
       "\n",
       "    // Call onopen now - mpl needs it, as it is assuming we've passed it a real\n",
       "    // web socket which is closed, not our websocket->open comm proxy.\n",
       "    ws_proxy.onopen();\n",
       "\n",
       "    fig.parent_element = element.get(0);\n",
       "    fig.cell_info = mpl.find_output_cell(\"<div id='\" + id + \"'></div>\");\n",
       "    if (!fig.cell_info) {\n",
       "        console.error(\"Failed to find cell for figure\", id, fig);\n",
       "        return;\n",
       "    }\n",
       "\n",
       "    var output_index = fig.cell_info[2]\n",
       "    var cell = fig.cell_info[0];\n",
       "\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_close = function(fig, msg) {\n",
       "    var width = fig.canvas.width/mpl.ratio\n",
       "    fig.root.unbind('remove')\n",
       "\n",
       "    // Update the output cell to use the data from the current canvas.\n",
       "    fig.push_to_output();\n",
       "    var dataURL = fig.canvas.toDataURL();\n",
       "    // Re-enable the keyboard manager in IPython - without this line, in FF,\n",
       "    // the notebook keyboard shortcuts fail.\n",
       "    IPython.keyboard_manager.enable()\n",
       "    $(fig.parent_element).html('<img src=\"' + dataURL + '\" width=\"' + width + '\">');\n",
       "    fig.close_ws(fig, msg);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.close_ws = function(fig, msg){\n",
       "    fig.send_message('closing', msg);\n",
       "    // fig.ws.close()\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.push_to_output = function(remove_interactive) {\n",
       "    // Turn the data on the canvas into data in the output cell.\n",
       "    var width = this.canvas.width/mpl.ratio\n",
       "    var dataURL = this.canvas.toDataURL();\n",
       "    this.cell_info[1]['text/html'] = '<img src=\"' + dataURL + '\" width=\"' + width + '\">';\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.updated_canvas_event = function() {\n",
       "    // Tell IPython that the notebook contents must change.\n",
       "    IPython.notebook.set_dirty(true);\n",
       "    this.send_message(\"ack\", {});\n",
       "    var fig = this;\n",
       "    // Wait a second, then push the new image to the DOM so\n",
       "    // that it is saved nicely (might be nice to debounce this).\n",
       "    setTimeout(function () { fig.push_to_output() }, 1000);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._init_toolbar = function() {\n",
       "    var fig = this;\n",
       "\n",
       "    var nav_element = $('<div/>');\n",
       "    nav_element.attr('style', 'width: 100%');\n",
       "    this.root.append(nav_element);\n",
       "\n",
       "    // Define a callback function for later on.\n",
       "    function toolbar_event(event) {\n",
       "        return fig.toolbar_button_onclick(event['data']);\n",
       "    }\n",
       "    function toolbar_mouse_event(event) {\n",
       "        return fig.toolbar_button_onmouseover(event['data']);\n",
       "    }\n",
       "\n",
       "    for(var toolbar_ind in mpl.toolbar_items){\n",
       "        var name = mpl.toolbar_items[toolbar_ind][0];\n",
       "        var tooltip = mpl.toolbar_items[toolbar_ind][1];\n",
       "        var image = mpl.toolbar_items[toolbar_ind][2];\n",
       "        var method_name = mpl.toolbar_items[toolbar_ind][3];\n",
       "\n",
       "        if (!name) { continue; };\n",
       "\n",
       "        var button = $('<button class=\"btn btn-default\" href=\"#\" title=\"' + name + '\"><i class=\"fa ' + image + ' fa-lg\"></i></button>');\n",
       "        button.click(method_name, toolbar_event);\n",
       "        button.mouseover(tooltip, toolbar_mouse_event);\n",
       "        nav_element.append(button);\n",
       "    }\n",
       "\n",
       "    // Add the status bar.\n",
       "    var status_bar = $('<span class=\"mpl-message\" style=\"text-align:right; float: right;\"/>');\n",
       "    nav_element.append(status_bar);\n",
       "    this.message = status_bar[0];\n",
       "\n",
       "    // Add the close button to the window.\n",
       "    var buttongrp = $('<div class=\"btn-group inline pull-right\"></div>');\n",
       "    var button = $('<button class=\"btn btn-mini btn-primary\" href=\"#\" title=\"Stop Interaction\"><i class=\"fa fa-power-off icon-remove icon-large\"></i></button>');\n",
       "    button.click(function (evt) { fig.handle_close(fig, {}); } );\n",
       "    button.mouseover('Stop Interaction', toolbar_mouse_event);\n",
       "    buttongrp.append(button);\n",
       "    var titlebar = this.root.find($('.ui-dialog-titlebar'));\n",
       "    titlebar.prepend(buttongrp);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._root_extra_style = function(el){\n",
       "    var fig = this\n",
       "    el.on(\"remove\", function(){\n",
       "\tfig.close_ws(fig, {});\n",
       "    });\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._canvas_extra_style = function(el){\n",
       "    // this is important to make the div 'focusable\n",
       "    el.attr('tabindex', 0)\n",
       "    // reach out to IPython and tell the keyboard manager to turn it's self\n",
       "    // off when our div gets focus\n",
       "\n",
       "    // location in version 3\n",
       "    if (IPython.notebook.keyboard_manager) {\n",
       "        IPython.notebook.keyboard_manager.register_events(el);\n",
       "    }\n",
       "    else {\n",
       "        // location in version 2\n",
       "        IPython.keyboard_manager.register_events(el);\n",
       "    }\n",
       "\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._key_event_extra = function(event, name) {\n",
       "    var manager = IPython.notebook.keyboard_manager;\n",
       "    if (!manager)\n",
       "        manager = IPython.keyboard_manager;\n",
       "\n",
       "    // Check for shift+enter\n",
       "    if (event.shiftKey && event.which == 13) {\n",
       "        this.canvas_div.blur();\n",
       "        // select the cell after this one\n",
       "        var index = IPython.notebook.find_cell_index(this.cell_info[0]);\n",
       "        IPython.notebook.select(index + 1);\n",
       "    }\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_save = function(fig, msg) {\n",
       "    fig.ondownload(fig, null);\n",
       "}\n",
       "\n",
       "\n",
       "mpl.find_output_cell = function(html_output) {\n",
       "    // Return the cell and output element which can be found *uniquely* in the notebook.\n",
       "    // Note - this is a bit hacky, but it is done because the \"notebook_saving.Notebook\"\n",
       "    // IPython event is triggered only after the cells have been serialised, which for\n",
       "    // our purposes (turning an active figure into a static one), is too late.\n",
       "    var cells = IPython.notebook.get_cells();\n",
       "    var ncells = cells.length;\n",
       "    for (var i=0; i<ncells; i++) {\n",
       "        var cell = cells[i];\n",
       "        if (cell.cell_type === 'code'){\n",
       "            for (var j=0; j<cell.output_area.outputs.length; j++) {\n",
       "                var data = cell.output_area.outputs[j];\n",
       "                if (data.data) {\n",
       "                    // IPython >= 3 moved mimebundle to data attribute of output\n",
       "                    data = data.data;\n",
       "                }\n",
       "                if (data['text/html'] == html_output) {\n",
       "                    return [cell, data, j];\n",
       "                }\n",
       "            }\n",
       "        }\n",
       "    }\n",
       "}\n",
       "\n",
       "// Register the function which deals with the matplotlib target/channel.\n",
       "// The kernel may be null if the page has been refreshed.\n",
       "if (IPython.notebook.kernel != null) {\n",
       "    IPython.notebook.kernel.comm_manager.register_target('matplotlib', mpl.mpl_figure_comm);\n",
       "}\n"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<img src=\"data:image/png;base64,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\" width=\"432\">"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<video width=\"432\" height=\"288\" controls autoplay>\n",
       "  <source type=\"video/mp4\" src=\"data:video/mp4;base64,AAAAIGZ0eXBNNFYgAAACAE00ViBpc29taXNvMmF2YzEAAAAIZnJlZQAAEKhtZGF0AAACrQYF//+p\n",
       "3EXpvebZSLeWLNgg2SPu73gyNjQgLSBjb3JlIDE2MCByMzAxMSBjZGU5YTkzIC0gSC4yNjQvTVBF\n",
       "Ry00IEFWQyBjb2RlYyAtIENvcHlsZWZ0IDIwMDMtMjAyMCAtIGh0dHA6Ly93d3cudmlkZW9sYW4u\n",
       "b3JnL3gyNjQuaHRtbCAtIG9wdGlvbnM6IGNhYmFjPTEgcmVmPTMgZGVibG9jaz0xOjA6MCBhbmFs\n",
       "eXNlPTB4MzoweDExMyBtZT1oZXggc3VibWU9NyBwc3k9MSBwc3lfcmQ9MS4wMDowLjAwIG1peGVk\n",
       "X3JlZj0xIG1lX3JhbmdlPTE2IGNocm9tYV9tZT0xIHRyZWxsaXM9MSA4eDhkY3Q9MSBjcW09MCBk\n",
       "ZWFkem9uZT0yMSwxMSBmYXN0X3Bza2lwPTEgY2hyb21hX3FwX29mZnNldD0tMiB0aHJlYWRzPTkg\n",
       "bG9va2FoZWFkX3RocmVhZHM9MSBzbGljZWRfdGhyZWFkcz0wIG5yPTAgZGVjaW1hdGU9MSBpbnRl\n",
       "cmxhY2VkPTAgYmx1cmF5X2NvbXBhdD0wIGNvbnN0cmFpbmVkX2ludHJhPTAgYmZyYW1lcz0zIGJf\n",
       "cHlyYW1pZD0yIGJfYWRhcHQ9MSBiX2JpYXM9MCBkaXJlY3Q9MSB3ZWlnaHRiPTEgb3Blbl9nb3A9\n",
       "MCB3ZWlnaHRwPTIga2V5aW50PTI1MCBrZXlpbnRfbWluPTIgc2NlbmVjdXQ9NDAgaW50cmFfcmVm\n",
       "cmVzaD0wIHJjX2xvb2thaGVhZD00MCByYz1jcmYgbWJ0cmVlPTEgY3JmPTIzLjAgcWNvbXA9MC42\n",
       "MCBxcG1pbj0wIHFwbWF4PTY5IHFwc3RlcD00IGlwX3JhdGlvPTEuNDAgYXE9MToxLjAwAIAAAAT6\n",
       "ZYiEABT//vfHT8Cm6Plmy51FPSEwitj6SCi9WOzQMnUAAAMAAETAxxFtXcuPAeYAAGEAAJcz493q\n",
       "rw8Zc+mz3QlIunjWEcI0ZfILID0tGcCtEp1qYPdCUpbf3xNhztBOr5wyzfeMyRMpgLo//TC2e/hI\n",
       "Lypyhi0p4fSE1JZACy+/5gcUlJURqAG5tWioRsNNKXa8+jgtblVxBZ0Y9Kctos2H75RcnwzKcpAT\n",
       "bn7LAHXhvot+jdx9eOrU2/+uojir5dDD42sbuNZufmXLA5PfFqVGgVObOLfXdOkPTWIFJHpXuvIx\n",
       "PviuO9vDOYC/3gypP5VVbvos11Z5gc5DLhCqWPJ1J0TdbJr49cTeZ/f6uLGYq0XCXkiGhYCadoRS\n",
       "KqwyBLi4ENm97UAv0JsuCQFp4tUT7H4vH/IXFBBCGscDXWdi1hSdcE7rN4wPJPR34IDR7Xg7jtc6\n",
       "z7E2h1umApko2hJpe6a+H2rcEHLafhhqvsBhKn96LWw48bbXQm84VSTisxIS2fD4Tx1W49a2lGod\n",
       "f37bXJcbVf0oEzNI53oblDW3/ujdU8wCE0aBzZuD+EP6LtryL14wku1v1RMZt2PayafopcecyFFp\n",
       "d9KqSrDnMCbIlG1JiXczH3DDoA2y+rAgWKhv2vYKHjrdfZGDYNxA8zeasmNvwtWmN8KvSX5odVe0\n",
       "dzwEJMUsHfnYiJcP6hYK0ub/z8l4Nn8VW0d0bzFe+85oDJIp/dnxq1FhD0yjqdNkJ2xzS1DGMcfV\n",
       "H1D6xtD18faDyC+2Rs8WYUfGqI//ti+RKFpHXNdtZR/r/7R5vFUWoV4bO79284Tz+TaePXNr6js5\n",
       "Bq3yISOA5wc4eI8Z9sEjf9jLt05WEIzvM2NC7lmMCInjBa7+gi0oUXO4RSrIyUCkXOoMGuWnusa1\n",
       "WgHMibnWcY4Wqxc22IGaFjZ81RxjzNfNB8X5eKjVlDdpkEUImX0aB1p9au89NR1GpgsDwMcZw/GJ\n",
       "nIyKYYmkrs55eJbW3wRdeXQfJcR8TznMXNgAZyzQUShPCo7eFaswBhSy3wVqEG5eWNWvkMRKhGfk\n",
       "/3xsl0MdHEvmIuES/IocjYcjY1CImd89rxvO3R1zum4EFgO6jrzZuEQLiZmJ8ofGPiOTxG/+EabZ\n",
       "BEKrgz6e5vKfUclzj3zEoRGfNOenmO2KSwHWsGNzlKAc2WOAgVLxYPyyWjPrPzz0FR/DzOTy4v8M\n",
       "+ByckTv5PBRqIn/0XPQSshW7MALpcoaPj1tBiiPH7Jtk9DWL/CIzlLRPForsZ/hyP/3sU/M5RiGo\n",
       "LJepKHcCuwJ07BfPpM/lgeffMfqQJVeq0ZL4FfUwn6q1LMWkjLTIsUdzyjW3DEvstx3zAcN+Mvj+\n",
       "f/tMUVH0Me2mkuwVDz/qNO0UJqzeJvDbd+838x9TgDhnsN25l3+TA7bTxZaVWPXSisvYMh5TuLgm\n",
       "XRZWIgtgKS5CyyQE2KOPuys4hCqgNA8NL2aYL7DPTgsObC1tYbSaoHFhCdwPuaXsgi4IEBm+2pJ7\n",
       "z+dwFf4ecgUMdVTEPtTU+MaqEW5hY/2cD4w4LmW+WLp9WUWBgy58CMR9MZkDILTZsTFhfQ9zAIHv\n",
       "VjVjZcn/P/KpyU/Lv3bqeq1cDQadbNElDuIkWaHucbHQhE3rVuNPNQtGLTrIVnRxYxscRo17r9iY\n",
       "NvpSUd6wA2xnv4xi6wCFjwAATUEAAAF0QZohbEFf/talUAAwK4ILW7+XCf9MRO0AWJTawqzQHHgS\n",
       "KPkTSXTqvLlf1G0p0oRtPqQlaAG35shXyNS1r8M5+1BuVoXuyGe8BbzlvGsCOZpY/+7ozNLxo7+I\n",
       "a8hpPq0KGO8NCiJzPbKUHQWnRIQb0jkh4aI1ZPvDk0WCAOQhxN5Jm61tQq0VnTM3EHtv8UtLl+Sk\n",
       "FKCSfPudOWY915w+9LoSBuolhLhdbOYMk2R4IMhmd+cV0oehAvqq9kM64khvK/KHbv20xv1UNbJp\n",
       "V4uGLEP4jxtNJAZbIENywn3gzrkY6URz42Jjo3ZXJAGqk8cNqc4wzASVr05IbEl5IinujV90kNjU\n",
       "ISC8YT9P56gKQmy7hudL1u59xZ9INWzWquDlJMfY1WkFw0y4X53lDI4iAu0rZ6ysJx9MyKxbU9rx\n",
       "hI1Wp9c+DaHq5EVsn5CmgtWBALKt9fX5flkv7kCCBqnnSLtyyj8e+1c8JUlh/uaY7a1E6b1oAAAC\n",
       "CkGaQzwhkymEFP/+1oywAFBLpKojJ5RQfGspi/ABGTEmZVK1dy6f/EJ2oeZX8BkoKQxWL7avNEYX\n",
       "gWirruVq4yGYPsaJHAa7quXbXifJajeBI4D08rKNZLYZIYam+wvtZ3dPTv8L4RHXFjHl70kX498A\n",
       "63cXR+YqQCMBPMjeYWOi8wtY6iZ3KPgt7UKtyeNFhzhNJmwZtmwh9WoGLgEZfFW934Pj5bSEKDam\n",
       "06hGC63r5GFuf9TVeS640Rhq1BRTxE1v6IOgEfR69s7A8I1G91LHw/2Y0RXnRRu3Qk4iO98b2ZZZ\n",
       "jKTCBd+zUzZWIJ5TeReUU9HCygOnp2myF8/wVw0P8rY/Mnx+gpwyX1i+s91OpCgZEm6CyAU2jZ9O\n",
       "aV0/Oiz/p2TDQZfS1SlLs77fQhI/OTv3w7sj4q6PCULCvDYkHnp9wB+8NaqMlys7DPE0OpiKobfd\n",
       "s8ZOiXc6eaoeLqMq4DH5ZHCettdOZZAZBeBVpXDFlpIpiCIQmakgMw0A7J/pr0vF8X1THdbfMb1r\n",
       "7/gBBvrZWaSGpRiAz2LMtm4f7oYpkszXBNL9EhJgjTWpG9xBBuX7iF0sfctjDel7IJkOJZs1TITH\n",
       "KWHaAvgdGySPPdGC4ijzvKXI+nQwQHxWyNOxDB0F+gQDfPFPLWWoTnIBpA0VVnKhETYd/jXXw2q/\n",
       "ElGazfVB+7dwsQAAAHYBnmJqQS8AAJqGDbu5pkpeYwnHRFLAi6MbJzaoAqz4sdGcJDU4q7AcfeoV\n",
       "fyGmt5669g9fjDdHAre0eq9LVifq3wIQFq6sjm1VlxhnvfoR/OS6PJjZaFgK7l74J6WlZ2yPF32T\n",
       "Hfjsbp4V+L2k7FFOsHie6rLYAAABJUGaZEnhDyZTAgp//taMsAAspZd4AoO9Aszmpt7kkWNyMYpq\n",
       "5xRL/VY5hSHH7gTY24F/6SNGD/pmwjD6NWCF7jyGqyAM+7IGeAmSaBkvPmFm0ZoRpfpbAIzPHXv7\n",
       "XWXbQczE89JxxLL9WP6jyGWXP3v+v8+fckSt1C1aPpbzC6X6YdyQxF6pgvE3mJfZojn0pf1yktgP\n",
       "Lw2t8imuir39ryMsMxA3p5dQCQVAECAilRjBP06csB8/1JAzPFNh22RuXWdbKWtaz241i3O8yYxd\n",
       "rp6ROz47az8wL+7Vz8dk9oXipcKBavyGkIG6H2Oh78HpacBcMVjzK/UcNHAknMn7t2kF0pyF2Ayr\n",
       "J7+udFUHeXXkMlTLRBZ/ZEqwJjo4Jn2oOO+457V9AAABfkGaiEnhDyZTAgl//rUqgAoX90qT4Ax+\n",
       "5JhzR8lc6NTtenyV8SguFIunPFbfA27D8KsqpaQUyNYONHz2dt6Hk7pA5PsNYIMXEiX19fzGrtNy\n",
       "r5xktb7SFGwOgKsz6tNzEdp0j0cBz1QFYfCM71RopfAujf7YacUsUmtYR0pfqqVKFHKRtQdrFbeh\n",
       "YcNRKWSzdM816hOF5TNJF7FbgE3/gcSTKnPZoqC8PgNaoihmT7roYR53VGhp4frGAy/eUNdur+kY\n",
       "CafhQwa9v/31gncGxugymfIUPvuRgb7jCslR/sVDcOgY0KEV7bK94878UvEwDUancKAN7jl1snKY\n",
       "PPD15oBaCd0jCShf4G402UkRQxdxDz5KoUUy2aOm2T/ge8GrMi7xysD6uXIY+jzRcV6lRGC/v/bg\n",
       "YJm36ajvSkVa7FS3se58EnXo/XoiXqmw/gEQCxlBimmagEjffyKeLapwLCCJ1JapsDGcVZ98Fadn\n",
       "5kW5JxKJu5xjT036UABJ+gkAAADvQZ6mRRE8E/8AA1CaBmCsbJ4CVz0xFJ9VnpxBVxa2bVowDP/X\n",
       "wRD0tPArYn5C3DCgiF237OB9OI4LlqGn5cUyqJ7gPbIURK0+YL7Voi2g/kamBJ+t9gNsobbOq6AI\n",
       "BNQ8TjqOCFyqImEcpML9O/Ox893nLLVJaItBzaILnQ/0MW/OfLNOs4MKJaaUe9kAmzy27yoQGFq8\n",
       "8Oe7zvGcFVmrXlcDsEAwTnXiT1qtpSbJpN9bHTZQEHN1xkqAzt/+AxmwAzyKlXUVT4A5nhfDMLcb\n",
       "hS7dZnbHAUdt2ptWZdnXfR+tkGakrIgUQXeY54YAzoEAAAC1AZ7FdEEvAAFh2+Y3aAeFBE9RIuU8\n",
       "1UAeVaYqQVcpMR+t7fV4FBW7nmq/AhRoIJ5DVvEp9CFunOwhV8wgNSI1LqW5SmFNQdbYPSyHIi4E\n",
       "7p+WXfMdpFaNYOWEVJ7BI/3jthzgTH5i+w0vmxglNj42ESLpKX1c7TzGmzC5ISVSJZ0tpRjowgff\n",
       "S13v//sd3FlKoQjjJHyxzOViuQJXMIj85L9P5yq7EVOABvrQkJ9CIH91JriSDwAAAJYBnsdqQS8A\n",
       "BNSfuh/tYGKrzAQW4mCeo9UEQJYXS07w8DHP48YZp/QH/VYrYNYQJbsS8B/I+nzMzELbBm6x/PB6\n",
       "07DeEASchFsO8/4G/IP/v2AaRVKqR/+WMH+lnMi8Lytc6F+9RYG/vuzJnqzFeF3CvP1y3Wsq2qiM\n",
       "giWFVA5f39+cSlaccCoIG0AMft99rzw6K6JJhoAAAAOWbW9vdgAAAGxtdmhkAAAAAAAAAAAAAAAA\n",
       "AAAD6AAADhAAAQAAAQAAAAAAAAAAAAAAAAEAAAAAAAAAAAAAAAAAAAABAAAAAAAAAAAAAAAAAABA\n",
       "AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAgAAAsB0cmFrAAAAXHRraGQAAAADAAAAAAAA\n",
       "AAAAAAABAAAAAAAADhAAAAAAAAAAAAAAAAAAAAAAAAEAAAAAAAAAAAAAAAAAAAABAAAAAAAAAAAA\n",
       "AAAAAABAAAAAAbAAAAEgAAAAAAAkZWR0cwAAABxlbHN0AAAAAAAAAAEAAA4QAAAgAAABAAAAAAI4\n",
       "bWRpYQAAACBtZGhkAAAAAAAAAAAAAAAAAAAoAAAAkABVxAAAAAAALWhkbHIAAAAAAAAAAHZpZGUA\n",
       "AAAAAAAAAAAAAABWaWRlb0hhbmRsZXIAAAAB421pbmYAAAAUdm1oZAAAAAEAAAAAAAAAAAAAACRk\n",
       "aW5mAAAAHGRyZWYAAAAAAAAAAQAAAAx1cmwgAAAAAQAAAaNzdGJsAAAAt3N0c2QAAAAAAAAAAQAA\n",
       "AKdhdmMxAAAAAAAAAAEAAAAAAAAAAAAAAAAAAAAAAbABIABIAAAASAAAAAAAAAABAAAAAAAAAAAA\n",
       "AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAGP//AAAANWF2Y0MBZAAV/+EAGGdkABWs2UGwloQAAAMA\n",
       "CAAAAwAoPFi2WAEABmjr48siwP34+AAAAAAcdXVpZGtoQPJfJE/FujmlG88DI/MAAAAAAAAAGHN0\n",
       "dHMAAAAAAAAAAQAAAAkAABAAAAAAFHN0c3MAAAAAAAAAAQAAAAEAAABQY3R0cwAAAAAAAAAIAAAA\n",
       "AgAAIAAAAAABAAAwAAAAAAEAABAAAAAAAQAAIAAAAAABAABQAAAAAAEAACAAAAAAAQAAAAAAAAAB\n",
       "AAAQAAAAABxzdHNjAAAAAAAAAAEAAAABAAAACQAAAAEAAAA4c3RzegAAAAAAAAAAAAAACQAAB68A\n",
       "AAF4AAACDgAAAHoAAAEpAAABggAAAPMAAAC5AAAAmgAAABRzdGNvAAAAAAAAAAEAAAAwAAAAYnVk\n",
       "dGEAAABabWV0YQAAAAAAAAAhaGRscgAAAAAAAAAAbWRpcmFwcGwAAAAAAAAAAAAAAAAtaWxzdAAA\n",
       "ACWpdG9vAAAAHWRhdGEAAAABAAAAAExhdmY1OC40NS4xMDA=\n",
       "\">\n",
       "  Your browser does not support the video tag.\n",
       "</video>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frames = []\n",
    "cum_reward=0\n",
    "actions_list=[1,3,3,0,0,0,2,2,2]\n",
    "for step in actions_list:\n",
    "    state, reward , end = env.step(step)\n",
    "    frames.append(state)\n",
    "    cum_reward+=reward\n",
    "cum_reward\n",
    "HTML(plot_animation(frames).to_html5_video())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experience Replay Buffer\n",
    "\n",
    "To make DQNs work you need an **Experience Replay Buffer**. The basic idea is that by storing an agent’s experiences, and then randomly drawing batches of them to train the network, we can more robustly learn to perform well in the task. The Experience Replay buffer stores a fixed number of recent memories, and as new ones come in, old ones are removed. When the time comes to train, we simply draw a uniform batch of random memories from the buffer, and train our network with them. For our DQN, we will build a simple class that handles storing and retrieving memories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ExperienceReplay:\n",
    "    def __init__(self, buffer_size=50000):\n",
    "        \"\"\" Data structure used to hold game experiences \"\"\"\n",
    "        # Buffer will contain [state,action,reward,next_state,done]\n",
    "        self.buffer = []\n",
    "        self.buffer_size = buffer_size\n",
    "\n",
    "    def add(self, experience):\n",
    "        \"\"\" Adds list of experiences to the buffer \"\"\"\n",
    "        # Extend the stored experiences\n",
    "        self.buffer.extend(experience)\n",
    "        # Keep the last buffer_size number of experiences\n",
    "        self.buffer = self.buffer[-self.buffer_size:]\n",
    "\n",
    "    def sample(self, size):\n",
    "        \"\"\" Returns a sample of experiences from the buffer \"\"\"\n",
    "        sample_idxs = np.random.randint(len(self.buffer), size=size)\n",
    "        sample_output = [self.buffer[idx] for idx in sample_idxs]\n",
    "        sample_output = np.reshape(sample_output, (size, -1))\n",
    "        return sample_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[90, 91, 92, 93, 94, 95, 96, 97, 98, 99]\n",
      "[[93]\n",
      " [99]\n",
      " [98]\n",
      " [91]\n",
      " [97]]\n"
     ]
    }
   ],
   "source": [
    "experience_replay = ExperienceReplay(buffer_size=10)\n",
    "experience_replay.add(list(range(100)))\n",
    "print(experience_replay.buffer)\n",
    "sample = experience_replay.sample(5)\n",
    "print(sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Architecture and loss of network\n",
    "\n",
    "\n",
    "#### Q-Learning\n",
    "Here are the Q-learning formula used above\n",
    "\n",
    "$$target = R(s,a,s')+\\gamma \\max\\limits_{a'}Q_k(s',a')$$\n",
    "$$Q_{k+1}(s,a)\\leftarrow(1-a)Q_k(s,a)+\\alpha[target]$$\n",
    "\n",
    "if the combinations of states and actions are too large, the memory and the computation requirement for Q will be too high.\n",
    "\n",
    "#### Deep Q-learning\n",
    "\n",
    "To address that, we switch to a deep network Q (DQN) to approximate Q(s, a). The learning algorithm is called Deep Q-learning. With the new approach, we generalize the approximation of the Q-value function rather than remembering the solutions.\n",
    "\n",
    "$$target = R(s,a,s')+\\gamma \\max\\limits_{a'}Q_k(s',a')$$\n",
    "$$\\theta_{k+1} \\leftarrow \\theta_k - \\alpha\\nabla_{\\theta}\\mathbb{E}_{s\\sim'P(s'|s,a)} [(Q_{\\theta}(s,a)-target(s'))^2]_{\\theta=\\theta_k} $$\n",
    "\n",
    "We define below a convolutional network. \n",
    "\n",
    "**Exercise** Complete the code of the convolutional network below with the input and output shape in order to make it work with our problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-8-77ed2f1993a8>, line 5)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-8-77ed2f1993a8>\"\u001b[0;36m, line \u001b[0;32m5\u001b[0m\n\u001b[0;31m    self.model = kl.Conv2D(\u001b[0m\n\u001b[0m               ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "class Qnetwork():\n",
    "    def __init__(self):\n",
    "        self.inputs = kl.Input(shape=#COMPLETE, name=\"main_input\")\n",
    "\n",
    "        self.model = kl.Conv2D(\n",
    "            filters=32,\n",
    "            kernel_size=[8, 8],\n",
    "            strides=[4, 4],\n",
    "            activation=\"relu\",\n",
    "            padding=\"valid\",\n",
    "            name=\"conv1\")(self.inputs)\n",
    "        self.model = kl.Conv2D(\n",
    "            filters=64,\n",
    "            kernel_size=[4, 4],\n",
    "            strides=[2, 2],\n",
    "            activation=\"relu\",\n",
    "            padding=\"valid\",\n",
    "            name=\"conv2\")(self.model)\n",
    "        self.model = kl.Conv2D(\n",
    "            filters=64,\n",
    "            kernel_size=[3, 3],\n",
    "            strides=[1, 1],\n",
    "            activation=\"relu\",\n",
    "            padding=\"valid\",\n",
    "            name=\"conv3\")(self.model)\n",
    "        self.model = kl.Conv2D(\n",
    "            filters=512,\n",
    "            kernel_size=[7, 7],\n",
    "            strides=[1, 1],\n",
    "            activation=\"relu\",\n",
    "            padding=\"valid\",\n",
    "            name=\"conv4\")(self.model)\n",
    "\n",
    "        self.model = kl.Flatten()(self.model)\n",
    "        self.model = kl.Dense(256, activation=\"relu\")(self.model)\n",
    "        self.model = kl.Dense(#COMPLETE, activation = \"linear\")(self.model)\n",
    "        self.model = km.Model(self.inputs, self.model)\n",
    "        self.model.compile(\"adam\", \"mse\")\n",
    "        self.model.optimizer.lr = 0.0001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load solutions/exercise_2_3.py\n",
    "class Qnetwork():\n",
    "    def __init__(self):\n",
    "        self.inputs = kl.Input(shape=[84, 84, 3], name=\"main_input\")\n",
    "\n",
    "        self.model = kl.Conv2D(\n",
    "            filters=32,\n",
    "            kernel_size=[8, 8],\n",
    "            strides=[4, 4],\n",
    "            activation=\"relu\",\n",
    "            padding=\"valid\",\n",
    "            name=\"conv1\")(self.inputs)\n",
    "        self.model = kl.Conv2D(\n",
    "            filters=64,\n",
    "            kernel_size=[4, 4],\n",
    "            strides=[2, 2],\n",
    "            activation=\"relu\",\n",
    "            padding=\"valid\",\n",
    "            name=\"conv2\")(self.model)\n",
    "        self.model = kl.Conv2D(\n",
    "            filters=64,\n",
    "            kernel_size=[3, 3],\n",
    "            strides=[1, 1],\n",
    "            activation=\"relu\",\n",
    "            padding=\"valid\",\n",
    "            name=\"conv3\")(self.model)\n",
    "        self.model = kl.Conv2D(\n",
    "            filters=512,\n",
    "            kernel_size=[7, 7],\n",
    "            strides=[1, 1],\n",
    "            activation=\"relu\",\n",
    "            padding=\"valid\",\n",
    "            name=\"conv4\")(self.model)\n",
    "\n",
    "        self.model = kl.Flatten()(self.model)\n",
    "        self.model = kl.Dense(256, activation=\"relu\")(self.model)\n",
    "        self.model = kl.Dense(4, activation = \"linear\")(self.model)\n",
    "        self.model = km.Model(self.inputs, self.model)\n",
    "        self.model.compile(\"adam\", \"mse\")\n",
    "        self.model.optimizer.lr = 0.0001"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Init a model in order to display it's summary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "main_input (InputLayer)      [(None, 84, 84, 3)]       0         \n",
      "_________________________________________________________________\n",
      "conv1 (Conv2D)               (None, 20, 20, 32)        6176      \n",
      "_________________________________________________________________\n",
      "conv2 (Conv2D)               (None, 9, 9, 64)          32832     \n",
      "_________________________________________________________________\n",
      "conv3 (Conv2D)               (None, 7, 7, 64)          36928     \n",
      "_________________________________________________________________\n",
      "conv4 (Conv2D)               (None, 1, 1, 512)         1606144   \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 4)                 1028      \n",
      "=================================================================\n",
      "Total params: 1,814,436\n",
      "Trainable params: 1,814,436\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "main_qn = Qnetwork()\n",
    "main_qn.model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DQN Class\n",
    "\n",
    "#### Separated Target network\n",
    "Here is how the target is supposed to be computed in order to train or Deep-Q network.\n",
    "\n",
    "$$target = R(s,a,s')+\\gamma \\max\\limits_{a'}Q_k(s',a';\\theta) $$\n",
    "\n",
    "\n",
    "We build a deep network to learn the values of Q but its target values are changing as we know things better. As shown below, the target values for Q depends on Q itself, we are chasing a non-stationary target. So we use a different network to generate the target, that will be updated from time to time\n",
    "\n",
    "\n",
    "$$target = R(s,a,s')+\\gamma \\max\\limits_{a'}Q_k(s',a';\\theta_{target}) $$\n",
    "\n",
    "\n",
    "**Exercise**  Complete the class below to train a DQN network\n",
    "\n",
    "1. Pay attention to all the parameters define in the init and make sure you understand its.\n",
    "2. Look at the train function that allow to run the pseudo code described below.\n",
    "3. Go inside all other function and complete the code where you'll find a TODO mark.\n",
    "\n",
    "\n",
    "#### Pseudo Code\n",
    "* while num_episode < self.num_episodes:\n",
    "\n",
    "    1. Run one complete episode:\n",
    "        * If less than *pre_train_episode* has been played:\n",
    "            * Play randomly\n",
    "        * Else\n",
    "            * play randomly with probability *prob_random* (Exploration) else play with the *main_q* network (Exploitation).\n",
    "        * Store the episode in the *ReplayBuffer*\n",
    "    2. If more than *pre_train_episode* has been played\n",
    "                * Decrease the probability of playing randomly (in order to use more Exploitation than Exploration (e-greedy policy).\n",
    "                * Every 5 episodes played:\n",
    "                    * Train the episode using episode from the *ReplayBuffer* and using the target build from the *target_q network*\n",
    "                    * Update the *target_q* weight with *main_q* weight."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "expected an indented block (<ipython-input-15-12395a30913c>, line 28)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-15-12395a30913c>\"\u001b[0;36m, line \u001b[0;32m28\u001b[0m\n\u001b[0;31m    def run_one_episode(self, num_episode, prob_random):\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m expected an indented block\n"
     ]
    }
   ],
   "source": [
    "class DQN:\n",
    "    def __init__(self):\n",
    "        self.batch_size = 64  # How many experiences to use for each training step\n",
    "        self.num_epochs = 20  # How many epochs to train\n",
    "        self.update_freq = 5  # How often you update the network\n",
    "        self.y = 0.99  # Discount factor\n",
    "        self.prob_random_start = 0.6  # Starting chance of random action\n",
    "        self.prob_random_end = 0.1  # Ending chance of random action\n",
    "        self.annealing_steps = 1000.  # Steps of training to reduce from start_e -> end_e\n",
    "        self.max_num_episodes = 10000  # How many episodes of game environment to train\n",
    "        self.pre_train_episodes = 100  # Number of episodes of random actions\n",
    "        self.max_num_step = 50  # Maximum allowed episode length\n",
    "        self. goal = 15\n",
    "\n",
    "        # Reset everything\n",
    "        K.clear_session()\n",
    "\n",
    "        #TODO: Setup both the main and the target network.\n",
    "        \n",
    "\n",
    "        #TODO Setup our experience replay\n",
    "        self.experience_replay = ExperienceReplay()\n",
    "\n",
    "    def update_target_graph(self):\n",
    "        # TODO : This function will be called every  self.update_freq train step, in order to copy all the weight of the main Q network to the target Q network\n",
    "\n",
    "\n",
    "    def run_one_episode(self, num_episode, prob_random):\n",
    "        # Create an experience replay for the current episode\n",
    "        episode_buffer = ExperienceReplay()\n",
    "\n",
    "        # Get the game state from the environment\n",
    "        state = env.reset()\n",
    "\n",
    "        done = False  # Game is complete\n",
    "        sum_rewards = 0  # Running sum of rewards in episode\n",
    "        cur_step = 0  # Running sum of number of steps taken in episode\n",
    "\n",
    "        while cur_step < self.max_num_step and not done:\n",
    "            cur_step += 1\n",
    "            \n",
    "            # TODO while that we haven't reach the  self.pre_train_episodes number of pre train episod, the action for the given state is choosen randomly. \n",
    "            # WHen self.pre_train_episode is reached, choose randomly tha ction with a 'prob_random' probability else use the main Q network\n",
    "            \n",
    "\n",
    "            # TODO Use action and retrieve the next state, reward and done\n",
    "\n",
    "            # Setup the episode to be stored in the episode buffer\n",
    "            episode = np.array([[state], action, reward, [next_state], done])\n",
    "            episode = episode.reshape(1, -1)\n",
    "\n",
    "            # Store the experience in the episode buffer\n",
    "            episode_buffer.add(episode)\n",
    "\n",
    "            # Update the running rewards\n",
    "            sum_rewards += reward\n",
    "\n",
    "            # Update the state\n",
    "            state = next_state\n",
    "\n",
    "        return episode_buffer, sum_rewards, cur_step\n",
    "\n",
    "    def train_one_step(self):\n",
    "        # TODO  Sample a batch from the self.experience_replay class\n",
    "        train_batch = self.experience_replay.sample(self.batch_size)\n",
    "\n",
    "        # Separate the batch into its components\n",
    "        train_state, train_action, train_reward, \\\n",
    "        train_next_state, train_done = train_batch.T\n",
    "\n",
    "        # Convert the action array into an array of ints so they can be used for indexing\n",
    "        train_action = train_action.astype(np.int)\n",
    "\n",
    "        # Stack the train_state and train_next_state for learning\n",
    "        train_state = np.vstack(train_state)\n",
    "        train_next_state = np.vstack(train_next_state)\n",
    "\n",
    "        #TODO Build the target in order to use them to build our network\n",
    "\n",
    "\n",
    "        # Train the main model\n",
    "        loss = self.main_qn.model.train_on_batch(train_state, target_q)\n",
    "        return loss\n",
    "\n",
    "\n",
    "    def train(self):\n",
    "\n",
    "        # Make the networks equal\n",
    "        self.update_target_graph()\n",
    "\n",
    "        # We'll begin by acting complete randomly. As we gain experience and improve,\n",
    "        # we will begin reducing the probability of acting randomly, and instead\n",
    "        # take the actions that our Q network suggests\n",
    "        prob_random = self.prob_random_start\n",
    "        prob_random_drop = (self.prob_random_start - self.prob_random_end) / self.annealing_steps\n",
    "\n",
    "        num_steps = []  # Tracks number of steps per episode\n",
    "        rewards = []  # Tracks rewards per episode\n",
    "        print_every = 50  # How often to print status\n",
    "        losses = [0]  # Tracking training losses\n",
    "        num_episode = 0\n",
    "\n",
    "        while num_episode < self.max_num_episodes:\n",
    "\n",
    "            episode_buffer, sum_rewards, cur_step = self.run_one_episode(num_episode, prob_random)\n",
    "\n",
    "            if num_episode > self.pre_train_episodes:\n",
    "                # Training the network\n",
    "\n",
    "                if prob_random > self.prob_random_end:\n",
    "                    # Drop the probability of a random action\n",
    "                    prob_random -= prob_random_drop\n",
    "\n",
    "                if num_episode % self.update_freq == 0:\n",
    "                    for num_epoch in range(self.num_epochs):\n",
    "                        loss = self.train_one_step()\n",
    "                        losses.append(loss)\n",
    "\n",
    "                    # Update the target model with values from the main model\n",
    "                    self.update_target_graph()\n",
    "\n",
    "            # Increment the episode\n",
    "            num_episode += 1\n",
    "\n",
    "            self.experience_replay.add(episode_buffer.buffer)\n",
    "            num_steps.append(cur_step)\n",
    "            rewards.append(sum_rewards)\n",
    "\n",
    "            if num_episode % print_every == 0:\n",
    "                # Print progress\n",
    "                mean_loss = np.mean(losses[-(print_every * self.num_epochs):])\n",
    "\n",
    "                print(\"Num episode: {} Mean reward: {:0.4f} Prob random: {:0.4f}, Loss: {:0.04f}\".format(\n",
    "                    num_episode, np.mean(rewards[-print_every:]), prob_random, mean_loss))\n",
    "                if np.mean(rewards[-print_every:]) >= self.goal:\n",
    "                    print(\"Training complete!\")\n",
    "                    break\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load solutions/exercise_2_4.py\n",
    "class DQN:\n",
    "    def __init__(self):\n",
    "        self.batch_size = 64  # How many experiences to use for each training step\n",
    "        self.num_epochs = 20  # How many epochs to train\n",
    "        self.train_frequency = 5  # How often you update the network\n",
    "        self.y = 0.99  # Discount factor\n",
    "        self.prob_random_start = 0.6  # Starting chance of random action\n",
    "        self.prob_random_end = 0.1  # Ending chance of random action\n",
    "        self.annealing_steps = 1000.  # Steps of training to reduce from start_e -> end_e\n",
    "        self.max_num_episodes = 10000  # How many episodes of game environment to train\n",
    "        self.min_pre_train_episodes = 100  # Number of episodes of random actions\n",
    "        self.max_num_step = 50  # Maximum allowed episode length\n",
    "        self. goal = 15\n",
    "\n",
    "        # Reset everything\n",
    "        K.clear_session()\n",
    "\n",
    "        # Setup our Q-networks\n",
    "        self.main_qn = Qnetwork()\n",
    "        self.target_qn = Qnetwork()\n",
    "\n",
    "        # Setup our experience replay\n",
    "        self.experience_replay = ExperienceReplay()\n",
    "\n",
    "    def update_target_graph(self):\n",
    "        updated_weights = np.array(self.main_qn.model.get_weights())\n",
    "        self.target_qn.model.set_weights(updated_weights)\n",
    "\n",
    "\n",
    "    def run_one_episode(self, num_episode, prob_random):\n",
    "        # Create an experience replay for the current episode\n",
    "        episode_buffer = ExperienceReplay()\n",
    "\n",
    "        # Get the game state from the environment\n",
    "        state = env.reset()\n",
    "\n",
    "        done = False  # Game is complete\n",
    "        sum_rewards = 0  # Running sum of rewards in episode\n",
    "        cur_step = 0  # Running sum of number of steps taken in episode\n",
    "\n",
    "        while cur_step < self.max_num_step and not done:\n",
    "            cur_step += 1\n",
    "            if np.random.rand() < prob_random or \\\n",
    "                    num_episode < self.min_pre_train_episodes:\n",
    "                # Act randomly based on prob_random or if we\n",
    "                # have not accumulated enough pre_train episodes\n",
    "                action = np.random.randint(env.actions)\n",
    "            else:\n",
    "                # Decide what action to take from the Q network\n",
    "                action = np.argmax(self.main_qn.model.predict(np.array([state])))\n",
    "\n",
    "            # Take the action and retrieve the next state, reward and done\n",
    "            next_state, reward, done = env.step(action)\n",
    "\n",
    "            # Setup the episode to be stored in the episode buffer\n",
    "            episode = np.array([[state], action, reward, [next_state], done])\n",
    "            episode = episode.reshape(1, -1)\n",
    "\n",
    "            # Store the experience in the episode buffer\n",
    "            episode_buffer.add(episode)\n",
    "\n",
    "            # Update the running rewards\n",
    "            sum_rewards += reward\n",
    "\n",
    "            # Update the state\n",
    "            state = next_state\n",
    "\n",
    "        return episode_buffer, sum_rewards, cur_step\n",
    "\n",
    "    def train_one_step(self):\n",
    "        # Train batch is [[state,action,reward,next_state,done],...]\n",
    "        train_batch = self.experience_replay.sample(self.batch_size)\n",
    "\n",
    "        # Separate the batch into its components\n",
    "        train_state, train_action, train_reward, \\\n",
    "        train_next_state, train_done = train_batch.T\n",
    "\n",
    "        # Convert the action array into an array of ints so they can be used for indexing\n",
    "        train_action = train_action.astype(np.int)\n",
    "\n",
    "        # Stack the train_state and train_next_state for learning\n",
    "        train_state = np.vstack(train_state)\n",
    "        train_next_state = np.vstack(train_next_state)\n",
    "\n",
    "        # Our predictions (actions to take) from the main Q network\n",
    "        target_q = self.main_qn.model.predict(train_state)\n",
    "\n",
    "        # Tells us whether game over or not\n",
    "        # We will multiply our rewards by this value\n",
    "        # to ensure we don't train on the last move\n",
    "        train_gameover = train_done == 0\n",
    "\n",
    "        # Q value of the next state based on action\n",
    "        target_q_next_state = self.target_qn.model.predict(train_next_state)\n",
    "        train_next_state_values = np.max(target_q_next_state[range(self.batch_size)], axis=1)\n",
    "\n",
    "        # Reward from the action chosen in the train batch\n",
    "        actual_reward = train_reward + (self.y * train_next_state_values * train_gameover)\n",
    "        target_q[range(self.batch_size), train_action] = actual_reward\n",
    "\n",
    "        # Train the main model\n",
    "        loss = self.main_qn.model.train_on_batch(train_state, target_q)\n",
    "        return loss\n",
    "\n",
    "\n",
    "    def train(self):\n",
    "\n",
    "        # Make the networks equal\n",
    "        self.update_target_graph()\n",
    "\n",
    "        # We'll begin by acting complete randomly. As we gain experience and improve,\n",
    "        # we will begin reducing the probability of acting randomly, and instead\n",
    "        # take the actions that our Q network suggests\n",
    "        prob_random = self.prob_random_start\n",
    "        prob_random_drop = (self.prob_random_start - self.prob_random_end) / self.annealing_steps\n",
    "\n",
    "        num_steps = []  # Tracks number of steps per episode\n",
    "        rewards = []  # Tracks rewards per episode\n",
    "        print_every = 50  # How often to print status\n",
    "        losses = [0]  # Tracking training losses\n",
    "        num_episode = 0\n",
    "\n",
    "        while num_episode < self.max_num_episodes:\n",
    "\n",
    "            episode_buffer, sum_rewards, cur_step = self.run_one_episode(num_episode, prob_random)\n",
    "            self.experience_replay.add(episode_buffer.buffer)\n",
    "\n",
    "            if num_episode > self.min_pre_train_episodes:\n",
    "                # Training the network\n",
    "\n",
    "                if prob_random > self.prob_random_end:\n",
    "                    # Drop the probability of a random action\n",
    "                    prob_random -= prob_random_drop\n",
    "\n",
    "                if num_episode % self.train_frequency == 0:\n",
    "                    for num_epoch in range(self.num_epochs):\n",
    "                        loss = self.train_one_step()\n",
    "                        losses.append(loss)\n",
    "\n",
    "                    # Update the target model with values from the main model\n",
    "                    self.update_target_graph()\n",
    "\n",
    "            # Increment the episode\n",
    "            num_episode += 1\n",
    "            num_steps.append(cur_step)\n",
    "            rewards.append(sum_rewards)\n",
    "\n",
    "            if num_episode % print_every == 0:\n",
    "                # Print progress\n",
    "                mean_loss = np.mean(losses[-(print_every * self.num_epochs):])\n",
    "\n",
    "                print(\"Num episode: {} Mean reward: {:0.4f} Prob random: {:0.4f}, Loss: {:0.04f}\".format(\n",
    "                    num_episode, np.mean(rewards[-print_every:]), prob_random, mean_loss))\n",
    "                if np.mean(rewards[-print_every:]) >= self.goal:\n",
    "                    print(\"Training complete!\")\n",
    "                    break\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num episode: 50 Mean reward: 1.6400 Prob random: 0.6000, Loss: 0.0000\n",
      "Num episode: 100 Mean reward: 2.0400 Prob random: 0.6000, Loss: 0.0000\n",
      "Num episode: 150 Mean reward: 1.4200 Prob random: 0.5755, Loss: 0.7006\n",
      "Num episode: 200 Mean reward: 0.9000 Prob random: 0.5505, Loss: 0.3659\n",
      "Num episode: 250 Mean reward: 1.7800 Prob random: 0.5255, Loss: 0.2573\n",
      "Num episode: 300 Mean reward: 2.1400 Prob random: 0.5005, Loss: 0.2046\n",
      "Num episode: 350 Mean reward: 2.8200 Prob random: 0.4755, Loss: 0.1739\n",
      "Num episode: 400 Mean reward: 2.1600 Prob random: 0.4505, Loss: 0.0555\n",
      "Num episode: 450 Mean reward: 2.6200 Prob random: 0.4255, Loss: 0.0539\n",
      "Num episode: 500 Mean reward: 4.7800 Prob random: 0.4005, Loss: 0.0548\n",
      "Num episode: 550 Mean reward: 3.9200 Prob random: 0.3755, Loss: 0.0558\n",
      "Num episode: 600 Mean reward: 4.8400 Prob random: 0.3505, Loss: 0.0557\n",
      "Num episode: 650 Mean reward: 5.7000 Prob random: 0.3255, Loss: 0.0540\n",
      "Num episode: 700 Mean reward: 5.5800 Prob random: 0.3005, Loss: 0.0542\n",
      "Num episode: 750 Mean reward: 7.0200 Prob random: 0.2755, Loss: 0.0530\n",
      "Num episode: 800 Mean reward: 5.7200 Prob random: 0.2505, Loss: 0.0550\n",
      "Num episode: 850 Mean reward: 4.8400 Prob random: 0.2255, Loss: 0.0577\n",
      "Num episode: 900 Mean reward: 7.0600 Prob random: 0.2005, Loss: 0.0582\n",
      "Num episode: 950 Mean reward: 7.7600 Prob random: 0.1755, Loss: 0.0581\n",
      "Num episode: 1000 Mean reward: 5.8000 Prob random: 0.1505, Loss: 0.0625\n",
      "Num episode: 1050 Mean reward: 5.9400 Prob random: 0.1255, Loss: 0.0666\n",
      "Num episode: 1100 Mean reward: 8.6800 Prob random: 0.1005, Loss: 0.0648\n",
      "Num episode: 1150 Mean reward: 7.5800 Prob random: 0.0995, Loss: 0.0653\n",
      "Num episode: 1200 Mean reward: 7.4400 Prob random: 0.0995, Loss: 0.0679\n",
      "Num episode: 1250 Mean reward: 9.6400 Prob random: 0.0995, Loss: 0.0669\n",
      "Num episode: 1300 Mean reward: 12.4600 Prob random: 0.0995, Loss: 0.0599\n",
      "Num episode: 1350 Mean reward: 7.7800 Prob random: 0.0995, Loss: 0.0613\n",
      "Num episode: 1400 Mean reward: 8.7800 Prob random: 0.0995, Loss: 0.0643\n",
      "Num episode: 1450 Mean reward: 9.7600 Prob random: 0.0995, Loss: 0.0626\n",
      "Num episode: 1500 Mean reward: 8.4800 Prob random: 0.0995, Loss: 0.0646\n",
      "Num episode: 1550 Mean reward: 10.3400 Prob random: 0.0995, Loss: 0.0663\n",
      "Num episode: 1600 Mean reward: 11.9200 Prob random: 0.0995, Loss: 0.0641\n",
      "Num episode: 1650 Mean reward: 13.8200 Prob random: 0.0995, Loss: 0.0653\n",
      "Num episode: 1700 Mean reward: 12.1000 Prob random: 0.0995, Loss: 0.0658\n",
      "Num episode: 1750 Mean reward: 15.0600 Prob random: 0.0995, Loss: 0.0631\n",
      "Training complete!\n"
     ]
    }
   ],
   "source": [
    "dqn = DQN()\n",
    "dqn.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise** Play a pacman game and display the result of a game in video."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load solutions/exercise_2_5.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DQN Improvement\n",
    "\n",
    "DQN has  been improved recently by using two different tricks (among others):\n",
    "\n",
    "* Dueling\n",
    "* Double DQN\n",
    "\n",
    "Implement these two solutions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dueling\n",
    "\n",
    "See the dueling architecture : \n",
    "\n",
    "\n",
    "In order to explain the reasoning behind the architecture changes that Dueling DQN makes, we need to first explain some a few additional reinforcement learning terms. The Q-values that we have been discussing so far correspond to how good it is to take a certain action given a certain state. This can be written as Q(s,a). This action given state can actually be decomposed into two more fundamental notions of value. The first is the value function V(s), which says simple how good it is to be in any given state. The second is the advantage function A(a), which tells how much better taking a certain action would be compared to the others. We can then think of Q as being the combination of V and A. More formally:\n",
    "$$Q(s,a) =V(s) + A(a)$$\n",
    "The goal of Dueling DQN is to have a network that separately computes the advantage and value functions, and combines them back into a single Q-function only at the final layer. It may seem somewhat pointless to do this at first glance. Why decompose a function that we will just put back together? The key to realizing the benefit is to appreciate that our reinforcement learning agent may not need to care about both value and advantage at any given time. For example: imagine sitting outside in a park watching the sunset. It is beautiful, and highly rewarding to be sitting there. No action needs to be taken, and it doesn’t really make sense to think of the value of sitting there as being conditioned on anything beyond the environmental state you are in. We can achieve more robust estimates of state value by decoupling it from the necessity of being attached to specific actions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load solutions/exercise_2_6.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_qn = Qnetwork()\n",
    "main_qn.model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Double DQN\n",
    "\n",
    "\n",
    "This lead to often overestimates the Q-values of the potential actions to take in a given state. While this would be fine if all actions were always overestimates equally, there was reason to believe this wasn’t the case. You can easily imagine that if certain suboptimal actions regularly were given higher Q-values than optimal actions, the agent would have a hard time ever learning the ideal policy. In order to correct for this, the authors of DDQN paper propose a simple trick: instead of taking the max over Q-values when computing the target-Q value for our training step, we use our primary network to chose an action, and our target network to generate the target Q-value for that action. By decoupling the action choice from the target Q-value generation, we are able to substantially reduce the overestimation, and train faster and more reliably. Below is the new DDQN equation for updating the target value.\n",
    "\n",
    "\n",
    "$$target = R(s,a,s')+\\gamma Q_k(s',argmax_aQ(s',a;\\theta);\\theta_{target}) $$\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load solutions/exercise_2_7.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dqn = DQN()\n",
    "dqn.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Real Pacman!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating the MsPacman environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(210, 160, 3)"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env = gym.make(\"MsPacman-v0\")\n",
    "obs = env.reset()\n",
    "obs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Discrete(9)"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.action_space"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preprocessing the images is optional but greatly speeds up training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mspacman_color = 210 + 164 + 74\n",
    "\n",
    "def preprocess_observation(obs):\n",
    "    img = obs[1:176:2, ::2] # crop and downsize\n",
    "    img = img.sum(axis=2) # to greyscale\n",
    "    img[img==mspacman_color] = 0 # Improve contrast\n",
    "    img = (img // 3 - 128).astype(np.int8) # normalize from -128 to 127\n",
    "    return img.reshape(88, 80, 1)/128\n",
    "\n",
    "img = preprocess_observation(obs)\n",
    "img.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: the `preprocess_observation()` function is slightly different from the one in the book: instead of representing pixels as 64-bit floats from -1.0 to 1.0, it represents them as signed bytes (from -128 to 127). The benefit is that the replay memory will take up roughly 8 times less RAM (about 6.5 GB instead of 52 GB). The reduced precision has no visible impact on training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(11, 7))\n",
    "plt.subplot(121)\n",
    "plt.title(\"Original observation (160×210 RGB)\")\n",
    "plt.imshow(obs)\n",
    "plt.axis(\"off\")\n",
    "plt.subplot(122)\n",
    "plt.title(\"Preprocessed observation (88×80 greyscale)\")\n",
    "plt.imshow(img.reshape(88, 80), interpolation=\"nearest\", cmap=\"gray\")\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
