{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AI-Frameworks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>\n",
    "<a href=\"http://www.insa-toulouse.fr/\" ><img src=\"http://www.math.univ-toulouse.fr/~besse/Wikistat/Images/logo-insa.jpg\" style=\"float:left; max-width: 120px; display: inline\" alt=\"INSA\"/></a> \n",
    "<a href=\"http://wikistat.fr/\" ><img src=\"http://www.math.univ-toulouse.fr/~besse/Wikistat/Images/wikistat.jpg\" width=400, style=\"max-width: 150px; display: inline\"  alt=\"Wikistat\"/></a>\n",
    "<a href=\"http://www.math.univ-toulouse.fr/\" ><img src=\"http://www.math.univ-toulouse.fr/~besse/Wikistat/Images/logo_imt.jpg\" width=400,  style=\"float:right;  display: inline\" alt=\"IMT\"/> </a>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LAB 5 Introduction to Recommendation System with Collaborative Filtering  -  Part 2 : Latent Vector-Based Methods with `nmf` and `softImpute` R Library.\n",
    "\n",
    "The objectives of this notebook are the following : \n",
    "\n",
    "* Discover `nmf` and `softImpute`  R library.\n",
    "* Discover Latent-Based methods to apply recommendation system.\n",
    "    * Latent-Based methods enable to decompose the X rating matrices into sub matrices that enable to represen to represent user and item in a smaller space and enable to represent interaction between them.\n",
    "\n",
    "* Use different factorization algorithms to learn decomposition of rating's matrices.\n",
    "* [Singular value decomposition](http://wikistat.fr/pdf/st-m-explo-alglin.pdf) (**SVD**) and [*Non Negativ Matrix Factorization*](http://wikistat.fr/pdf/st-m-explo-nmf.pdf) (**NMF**).\n",
    "* Use softImpute to performe matrices rating's completion.\n",
    "* Use results of algorithm to apply recommendation. \n",
    "\n",
    "\n",
    "**NB** : When data are rates, \"0\" usually mean that the value is not here. In this case, NMF or SVD are not suitable. However most of the implementation allow to use those algorithms and consider \"0\" as a \"0\" rate.  This is the case of `scikit-learn` and `surprise` NMF and SVD implementation.\n",
    "In this situation we should prefer completion algorithm."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Toy Dataset\n",
    "\n",
    "To understand well how factorization algorithm works, we will used  a toy dataset called 'recom-jouet.dat'. \n",
    "It contains information on how much products have been bought (or notation on the product) by a user. You can change its value if you want."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jouet=read.table(\"recom-jouet.dat\")\n",
    "jouet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "options(repr.plot.width=6, repr.plot.height=3)\n",
    "boxplot(jouet)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data are sparse. The variable have very different variances.\n",
    "We might want to normalize the data as user can have different scale of notation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recommandation par NMF\n",
    "The R package `NMF` contains various NMF algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#install.packages(\"NMF\")\n",
    "library(\"NMF\")\n",
    "nmfAlgorithm()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select the best algorithm\n",
    "\n",
    "We will look for the best NMF algorithm among these four algorithms. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nmfAlgorithm(\"brunet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nmfAlgorithm(\"lee\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nmfAlgorithm(\"snmf/l\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nmfAlgorithm(\"snmf/r\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q** What are the loss function associated to those four algorithm? Do they use regularization?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now compare the four methods on toy dataset, using  rank 5. \n",
    "We perform 10 runs for each of them as results depends of the initialization. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res.multi.method=nmf(jouet, 5,nrun=10, list(\"brunet\",\"lee\",\"snmf/l\",\"snmf/r\"), \n",
    "                     seed = 111, .options =\"t\")\n",
    "compare(res.multi.method)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `NMF` package proposes a lot of tools to visualize results and help you understand them. \n",
    "The *consensusmap* allow to display, for each method, different information such that:\n",
    "\n",
    "* the heatmap of the consensus matrix,\n",
    "* the *basis*  that show for each column, the dominant basis component in the best fit\n",
    "* The *consensus* which is the result of the consensus matrix.\n",
    "\n",
    "\n",
    "The **consensus matrix** is the ratio between the sum of connectivity matrix of all run and the number of run. \n",
    "\n",
    "THe **connectivity matrix** is a binary matrix build over the result of one run of nmf algorithm. The entry (i,j) is equal to one if column i and j belong to the same cluster. 0 otherwise.  An entry i and j belong to the same cluster if they have the same dominant basis. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "options(repr.plot.width=6, repr.plot.height=6)\n",
    "consensusmap(res.multi.method,hclustfun=\"ward\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q** What represent those different plot? \n",
    "**Q** Which method is the best?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select the rank"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now perform the NMF algorithm with the best methods. And we run this method according to various rank (from 2 to 6). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estim.r=nmf(jouet,2:6,method=\"snmf/l\", nrun=10,seed=111)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now look at various indicators to look at the performance of the different run and choose the best rank."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(estim.r)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q** what do these different metrics represent? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "options(repr.plot.width=8, repr.plot.height=5)\n",
    "consensusmap(estim.r) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q** According to the different metric, which rank seems the better?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explore results \n",
    "Now we have choosen a method and a rank, let's iterate several time to get the best run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nmf.jouet=nmf(jouet,4,method=\"snmf/l\",nrun=30,seed=111)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now extract the **W** and **H** matrix in order to visualize the data and explore it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w=basis(nmf.jouet)\n",
    "h=coef(nmf.jouet)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's now possible to construct the `basis matrix`. \n",
    "In this matrix, each entry (i,j) represent the ratio of the number of time a user i had j as a dominant basis component over the number of run. \n",
    "\n",
    "The `basismap` enables to display the heatmap of the basis matrix as well as the result of a hierarchical clustering on this matrix. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "options(repr.plot.width=4, repr.plot.height=3)\n",
    "basismap(nmf.jouet,hclustfun=\"ward\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `coefmap` is the equivalent of `basismap` for the items "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "options(repr.plot.width=5, repr.plot.height=3)\n",
    "coefmap(nmf.jouet,hclustfun=\"ward\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We perform now hierarchical clustering directly on the embedding representation the users.\n",
    "The distance use to compute the clustering is the euclidean distances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distmod.h=dist(scale(t(h)), method=\"eucl\")\n",
    "hclusmod.h=hclust(distmod.h,method=\"ward.D\")\n",
    "options(repr.plot.width=5, repr.plot.height=4)\n",
    "plot(hclusmod.h)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We apply now a MDS on the distance matrix in order to represent the user in a 2D plot. It could be done on PCA to."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dN.h=dimnames(h)[[2]]\n",
    "hclasmod.h = cutree(hclusmod.h,k=4)\n",
    "mdjouet= cmdscale(distmod.h, k=2)\n",
    "plot(mdjouet, type=\"n\", xlab=\"\", ylab=\"\",main=\"\")\n",
    "text(mdjouet,dN.h,col=hclasmod.h)\n",
    "abline(v=0,h=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We perform now hierarchical clustering directly on the embedding representation the items."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distmod.v=dist(scale(w), method=\"eucl\")\n",
    "mdjouet= cmdscale(distmod.v, k=2)\n",
    "hclusmod.v=hclust(distmod.v,method=\"ward.D\")\n",
    "plot(hclusmod.v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hclasmod.v = cutree(hclusmod.v,k=2)\n",
    "dN.v=dimnames(w)[[1]]\n",
    "plot(mdjouet, type=\"n\", xlab=\"\", ylab=\"\",main=\"\")\n",
    "text(mdjouet,dN.v,col=hclasmod.v)\n",
    "abline(v=0,h=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now want to display information on both user and items on the same graph. This can be done with the `aheatmap` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# intégration des deux classifications\n",
    "aheatmap(jouet,Rowv=hclusmod.v, Colv=hclusmod.h,annRow=as.factor(hclasmod.v),\n",
    "         annCol=as.factor(hclasmod.h))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also display both user items on their same graph according to axis of their embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(t(h)[,2:3]/max(h), type=\"n\", xlab=\"\", ylab=\"\",main=\"\", xlim=c(-0.2,1.2))\n",
    "text(t(h)[,2:3]/max(h),dN.h)\n",
    "abline(v=0,h=0)\n",
    "points(w[,2:3]/max(w), type=\"n\", xlab=\"\", ylab=\"\",main=\"\")\n",
    "text(w[,2:3]/max(w),dN.v, col=\"red\")\n",
    "abline(v=0,h=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recommandation\n",
    "\n",
    "The NMF package does not contains method to directy perform recommendation.\n",
    "However this can easily be done by computing the estimation \n",
    "$\\hat{x}=w*h$ of the $x$ origin matrix.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Matrice reconstruite\n",
    "xchap=w%*%h"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can know apply the recommendation by detecting the higher reconstruct score of the matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prod=apply(xchap-10*jouet,1,function(x) which.max(x))\n",
    "cbind(dN.v,dN.h[prod])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Par SVD\n",
    "\n",
    "SVD decomposition generate a factorization **X**=**UL V'** which has better properties than the one produces by the NMF as the unique solution for a given rank.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Recommandation\n",
    "Approximation de rang 2 par SVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res=svd(jouet)\n",
    "# Matrice reconstruite\n",
    "xchap=res$u[,1:2]%*%diag(res$d[1:2])%*%t(res$v[,1:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prod=apply(xchap-10*jouet,1,function(x) which.max(x))\n",
    "cbind(dN.v,dN.h[prod])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q** Compare this recommendation with the one perform by NMF. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Matrix Completion \n",
    "\n",
    "\n",
    "We now consider \"0\" as a missing value. The problem is know a completion matrix problem.\n",
    "The `SoftImpute` library enables to apply softumpute algorithm (see lectures slide.), which can be compared to a thresholded SVD.\n",
    "\n",
    "We first replace 0 by \"NA\" value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jouet.na=jouet\n",
    "jouet.na[jouet==0]=NA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The recommendation can then be applied the same way than with the SVD."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "install.packages(\"softImpute\")\n",
    "library(softImpute)\n",
    "res=softImpute(jouet.na,rank.max=2,type=\"svd\",lambda=1)\n",
    "# Matrice reconstruite\n",
    "xchap=res$u%*%diag(res$d)%*%t(res$v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prod=apply(xchap-10*jouet,1,function(x) which.max(x))\n",
    "cbind(dN.v,dN.h[prod])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q** Compare the results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This study is only a introduction to collaborative filtering with latent vectors-based methods.\n",
    "\n",
    "A lot of questions hasn't been discussed such has *cold start* problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Movielens\n",
    "\n",
    "See the notebook `1-Python-Neighborhood-MovieLens.ipynb` for an introduction to these data.\n",
    "\n",
    "We start by studying the small dataset composed f 100k rows.  \n",
    "We download the updated ratings filed build in the previous notebook in order to compare results on same test/train dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings=read.csv(\"movielens_small/ratings_updated.csv\")\n",
    "head(ratings, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We download the test_id produced in first notebook in order to reproduce the same train test partition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test=ratings[ratings$test_train==\"test\",1:3]\n",
    "train=ratings[ratings$test_train==\"train\",1:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NMF\n",
    "\n",
    "In order to perform NMF algorithms on the movielens dataset, we need to build a dense matrix from the ratings data, as the `nmf` package does not take sparse matrix into account. \n",
    "This is a strong limitation that does not allow you to perform factorization on the dataset in a reasonable amount of time for this lab (even in the small dataset!).\n",
    "We won't perform factorizaton on this dataset. \n",
    "\n",
    "You can easily perform this factorization with **python** with either `scikit-learn` or `surprise` library. \n",
    "Surprise provide a benchmark of the performance of various algorithm on this dataset (http://surpriselib.com/#benchmarks). \n",
    "However their are only on implementation of the NMF and it doesn't not handle missing data. This is why we won't cover this implementation in this course."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SoftImpute\n",
    "\n",
    "On the contrary, `SoftImpute`package allow to easily perform  *softImpute* algorithm on sparse data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#install.packages(\"softImpute\")\n",
    "library(softImpute)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mise au format d'une matrice creuse\n",
    "trainSparse=Incomplete(train$userId,train$movieId,train$rating)\n",
    "# appel de la fonction\n",
    "res=softImpute(trainSparse,rank.max=4,type=\"als\",lambda=1,maxit=200)\n",
    "# complétion\n",
    "recom=impute(res,test[,1],test[,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcul de l'erreur (RMSE)\n",
    "sqrt(mean((test[,3]-recom)**2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The error is quite bad compare to the ones obtained with neighborhood methods.  However, the advantage of this method is that it can be used in a reasonable amount of time on bigger dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Complete dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lecture de la matrice\n",
    "dBrut=read.csv(\"ml-25/ratings.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extraction de l'échantillon test\n",
    "dTestInd=sample(nrow(dBrut),nrow(dBrut)/10,replace=FALSE)\n",
    "dTest=dBrut[dTestInd,1:3]\n",
    "nrow(dTest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sous-échantillonage de l'échantillon d'apprentissage\n",
    "dInter=dBrut[-dTestInd,1:3]\n",
    "taux=0.1\n",
    "dTrainInd=sample(nrow(dInter),nrow(dInter)*taux,replace=FALSE)\n",
    "dTrain=dInter[dTrainInd,1:3]\n",
    "# Matrice d'échantillonnage sparse\n",
    "dTrainSparse=Incomplete(dTrain$userId,dTrain$movieId,dTrain$rating)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Factorisation\n",
    "t1=Sys.time()\n",
    "res=softImpute(dTrainSparse,rank.max=10,type=\"als\",lambda=20,maxit=200)\n",
    "t2=Sys.time()\n",
    "# Reconstruction\n",
    "recom=impute(res,dTest[,1],dTest[,2])\n",
    "#RMSE\n",
    "sqrt(mean((dTest[,3]-recom)**2))\n",
    "difftime(t2,t1) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apprentissage avec fichier complet (taux=1): 20M de notes\n",
    "\n",
    "rang | lambda | temps (') | rmse \n",
    "----|---------|-------|-----\n",
    " 4  |  1       |  5.6 |  1.07   \n",
    " 10 |  10  |  12.6 |  1.02  \n",
    " 10 |  20  |  12.2 |  1.033 \n",
    " 15 |  10  |  19.4 |  1.016\n",
    " 20 |   1  |  26.9  | 1.02 \n",
    " 20 |  10  |  26.1  | 1.016 \n",
    " 20 |  15  |  24.4 |  1.018\n",
    " 20 |  20  |  27.0  | 1.016 \n",
    " 30 |  20  |  40.1 |  1.02\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
