{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [Ateliers: Technologies de l'intelligence Artificielle](https://github.com/wikistat/AI-Frameworks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>\n",
    "<a href=\"http://www.insa-toulouse.fr/\" ><img src=\"http://www.math.univ-toulouse.fr/~besse/Wikistat/Images/logo-insa.jpg\" style=\"float:left; max-width: 120px; display: inline\" alt=\"INSA\"/></a> \n",
    "<a href=\"http://wikistat.fr/\" ><img src=\"http://www.math.univ-toulouse.fr/~besse/Wikistat/Images/wikistat.jpg\" width=400, style=\"max-width: 150px; display: inline\"  alt=\"Wikistat\"/></a>\n",
    "<a href=\"http://www.math.univ-toulouse.fr/\" ><img src=\"http://www.math.univ-toulouse.fr/~besse/Wikistat/Images/logo_imt.jpg\" width=400,  style=\"float:right;  display: inline\" alt=\"IMT\"/> </a>\n",
    "    \n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Traitement Naturel du Langage (NLP) : Génération de Texte avec des Réseaux Récurrent. \n",
    "\n",
    "Au cours de ce calepin, nous allons voir comment générer des description de produits à l'aide de Réseaux Récurents et notamment grace aux structure LSTM (Long-Short Term Memory). \n",
    "\n",
    "L'intérêt de cette application est limité. Les descriptions de textes de ce document sont trop pauvres syntaxiquement pour pouvoir juger réellement de la qualité du texte généré. L'intérêt réel de ce calepin est de voir comment les données doivent être mis en forme pour être utilisé dans un réseau recurrent dans un but de génération de texte."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Librairies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/brendanguillouet/anaconda3/envs/INSA/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/Users/brendanguillouet/anaconda3/envs/INSA/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/Users/brendanguillouet/anaconda3/envs/INSA/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/Users/brendanguillouet/anaconda3/envs/INSA/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/Users/brendanguillouet/anaconda3/envs/INSA/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/Users/brendanguillouet/anaconda3/envs/INSA/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "#Importation des librairies utilisées\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import functools\n",
    "from tqdm import tqdm\n",
    "\n",
    "import tensorflow.keras.models as km\n",
    "import tensorflow.keras.layers as kl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Téléchargement des données\n",
    "\n",
    "La Catégorie de Niveau 3 `COQUE - BUMPER - FACADE TELEPHONE` est la catégorie le plus représenté du jeu de données originale **Cdiscount** avec  2.184.671 déscriptions présentent.  Parmis ces descriptions, 1.761.637 sont composés d'exactement 197 caractères. \n",
    "\n",
    "Nous allons nous servir de ces lignes (ou un sous ensemble de ces lignes, en fonction de la puissance de calcul disponible sur votre machine) pour apprendre un modèle de génération de texte qui permettra de généré automatiquement une nouvelle description de ce type de produit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100000,)\n",
      "[\"Pour apple iphone 4 : coque bumper silicone blanc - Cet étui en silicone rigide protège et habille votre APPLE iPhone 4. Parfaitement adapté, il permet l'accès à toutes les fo… Voir la présentation\"\n",
      " \"Pour htc one x : coque noire rigide - Cette coque protège et habille avec sobriété votre HTC ONE X. Parfaitement adaptée, elle permet l'accès à toutes les fonctionnalités de v… Voir la présentation\"\n",
      " \"Pour htc one x : coque blanche rigide - Cette coque protège et habille avec sobriété votre HTC ONE X. Parfaitement adaptée, elle permet l'accès à toutes les fonctionnalités de… Voir la présentation\"]\n"
     ]
    }
   ],
   "source": [
    "N = 100000\n",
    "DATA_DIR = \"\"\n",
    "X = np.load(DATA_DIR+\"data/description_coque.npy\")[:N]\n",
    "print(X.shape)\n",
    "print(X[:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercice** Vérifiez que toutes les séquences sont bien de tailles 197."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "Nd=197"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mise en forme  des données\n",
    "\n",
    "La génération de texte implique de constuire un réseau `Many-To-One` :\n",
    "\n",
    "<img src=\"https://raw.githubusercontent.com/wikistat/AI-Frameworks/master/slides/OneToMany.png\" alt=\"drawing\" width=\"400\"/>\n",
    "\n",
    "Ou la prédiction $y_t$ servira d'entrée au réseau au temps $t+1$, i.e : $y_t=x_{t+1}$. \n",
    "\n",
    "Chaque $x_t$ représente ici un caractère de la déscription encodé en One-Hot encoding. Ainsi une description $x$ composé de $N_d$ caractères sera modélisé par une matrice de taille $(N_v\\times N_d)$  $x=[x_1,x_2,...,x_{N_d}]$  ou $x_i \\in \\mathbb{R}^{N_v}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Création de la liste des caractères\n",
    "\n",
    "Afin d'encoder les description sous format 'One-Hot encoding'  nous devons dans un premier temps retrouver la taille $Nv$ de notre vocabulaire constitué de tout les caractères présent dans la description."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulaire : ['M', 'k', ':', '+', 'f', '3', 'T', 's', 'y', 'â', 'v', 'h', 'é', ',', 'E', '%', '7', '/', 'q', '!', '(', 'J', '9', 'ô', 'j', 'Z', 'a', 'I', 'z', 't', '0', '&', '?', 'b', 'B', 'g', '\"', 'K', 'i', ' ', 'd', 'l', 'm', 'P', 'p', 'x', 'u', 'o', 'H', ')', 'è', 'V', 'R', '8', 'n', '\\xa0', \"'\", 'Q', 'ç', 'ê', '…', 'F', 'à', '5', '6', 'X', 'e', 'G', 'c', 'w', 'A', '-', 'U', '.', 'O', '4', '*', 'L', 'D', 'r', '2', 'Y', 'N', '1', 'C', 'S', 'W']\n"
     ]
    }
   ],
   "source": [
    "chars = list(functools.reduce(lambda x,y : x.union(y), [set(x) for x in X], set()))\n",
    "print(\"Vocabulaire : \" +  str(chars))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous ajoutons à ce vocabulaire deux indicateur permettant de localiser le début et la fin de chaque description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chars.extend([\"start\",\"end\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Taille du vocabulaire : 89\n"
     ]
    }
   ],
   "source": [
    "Nv = len(chars)\n",
    "print(\"Taille du vocabulaire : %d\" %Nv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Création des dictionnaires\n",
    "\n",
    "Les dictionnaires `char_to_int` et `int_to_char` permettent respectivement d'encoder une description texte et de décoder un encodage `One-Hot``"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "int_to_char = {i:c for i,c in enumerate(chars)}\n",
    "char_to_int = {c:i for i,c in int_to_char.items()}\n",
    "I_START = char_to_int[\"start\"]\n",
    "I_END = char_to_int[\"end\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encodage des Descriptions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La fonction suivante, permet d'encoder une matrice $X\\in \\mathbb{R}^{N \\times N_d}$ constitués de *N* descriptions en une matrice $X_{vec} \\in \\mathbb{R}^{N \\times N_d \\times N_v}$ contenant les description encodées."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_input_output_sequence(x, length_sequence, size_vocab, char_to_int_dic, i_start, i_end):\n",
    "    n = x.shape[0]\n",
    "    x_vec = np.zeros((n,length_sequence, size_vocab))\n",
    "    y_vec = np.zeros((n,length_sequence, size_vocab))\n",
    "    x_vec[:,0,i_start] = 1\n",
    "    y_vec[:,-1,i_end] = 1\n",
    "    for ix,x in tqdm(enumerate(x)):\n",
    "        for ic,c in enumerate(x):\n",
    "            c_int = char_to_int_dic[c]\n",
    "            x_vec[ix,ic+1,c_int]=1\n",
    "    y_vec[:,:-1,:] = x_vec[:,1:,:] \n",
    "    return x_vec, y_vec\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100000it [00:08, 11186.37it/s]\n"
     ]
    }
   ],
   "source": [
    "X_vec, Y_vec = encode_input_output_sequence(X[:N], Nd+1, Nv, char_to_int,I_START,I_END)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100000, 198, 89)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_vec.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercice** Retrouvez la phrase originale de la phrase test affiché ci-dessous à partir de la phrase encodé. Vérifiez que x et y sont bien les mêmes descriptions seulement décalées d'un index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load solution/3_1.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apprentissage\n",
    "\n",
    "Nous allons maintenant définir notre modèle récurrent afin de générer notre modèle de prédiction. \n",
    "\n",
    "Prenez le temps de bien comprendre toutes les fonctions et arguments utilisés pour construire ce modèle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/brendanguillouet/anaconda3/envs/INSA/lib/python3.6/site-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm (LSTM)                  (None, None, 32)          15616     \n",
      "_________________________________________________________________\n",
      "time_distributed (TimeDistri (None, None, 89)          2937      \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, None, 89)          0         \n",
      "=================================================================\n",
      "Total params: 18,553\n",
      "Trainable params: 18,553\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "nb_hidden = 32\n",
    "epochs = 20\n",
    "batch_size= 128\n",
    "\n",
    "model = km.Sequential()\n",
    "model.add(kl.LSTM(nb_hidden, input_shape=(None, Nv), return_sequences=True))\n",
    "model.add(kl.TimeDistributed(kl.Dense(Nv)))\n",
    "model.add(kl.Activation('softmax'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/brendanguillouet/anaconda3/envs/INSA/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "WARNING:tensorflow:From /Users/brendanguillouet/anaconda3/envs/INSA/lib/python3.6/site-packages/tensorflow/python/ops/math_grad.py:102: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Deprecated in favor of operator or tf.math.divide.\n",
      "Epoch 1/20\n",
      "100000/100000 [==============================] - 188s 2ms/sample - loss: 2.6827\n",
      "Epoch 2/20\n",
      "100000/100000 [==============================] - 170s 2ms/sample - loss: 1.3799\n",
      "Epoch 3/20\n",
      " 94848/100000 [===========================>..] - ETA: 8s - loss: 0.8067"
     ]
    }
   ],
   "source": [
    "model.compile(loss=\"categorical_crossentropy\", optimizer=\"rmsprop\")\n",
    "model.fit(X_vec, Y_vec, epochs=epochs, batch_size=batch_size)\n",
    "model.save(\"data/generate_model.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q** Pourquoi est-ce la `categorical_crossentropy` qui est utilisée comme fonction de perte?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Génération de Texte"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La celulle suivante permet de générer une description produit :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_pred = np.zeros((1, Nd+1, Nv))\n",
    "print(\"step 0\")\n",
    "x_pred[0,0,I_START] =1\n",
    "x_pred_str = decode_sequence(x_pred[0], int_to_char)\n",
    "print(x_pred_str)\n",
    "\n",
    "for i in range(Nd):\n",
    "    ix = np.argmax(model.predict(x_pred[:,:i+1,:])[0][-1,:])\n",
    "    x_pred[0,i+1,ix] = 1\n",
    "x_pred_str=decode_sequence(x_pred[0], int_to_char)\n",
    "print(x_pred_str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q** Comment cette génération est-elle produite? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercice** Effectuez une génération en choissisant la ou les premières lettres qui seront générées."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%load solution/3_2.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercice** Effectuez une génération en ajoutant de l'aléa. Vous pouvez par exemple faire en sorte que chaque lettre soit séléctionnée selon une loi multinomiale."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%load solution/3_3.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
